{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"AS2_QB_FR_D.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uT-lrh1Xe3ry","executionInfo":{"status":"ok","timestamp":1615719814055,"user_tz":-480,"elapsed":22060,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"1964a567-e5f9-4c98-fb8c-4f02b86c4186"},"source":["import sys,os\r\n","if 'google.colab' in sys.modules:\r\n","  from google.colab import drive\r\n","  drive.mount('/content/gdrive')\r\n","  path_to_file = '/content/gdrive/My Drive/AI Sem II/NLP/A2'\r\n","  print(path_to_file)\r\n","  os.chdir(path_to_file)\r\n","  !pwd"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/AI Sem II/NLP/A2\n","/content/gdrive/My Drive/AI Sem II/NLP/A2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sUm8xUsPjECA","executionInfo":{"status":"ok","timestamp":1615719816652,"user_tz":-480,"elapsed":24655,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["from __future__ import unicode_literals, print_function, division\r\n","from io import open\r\n","import unicodedata\r\n","import string\r\n","import re\r\n","import random\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","from torch import optim\r\n","import torch.nn.functional as F\r\n","\r\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjR9yaPeIEDs","executionInfo":{"status":"ok","timestamp":1615719818246,"user_tz":-480,"elapsed":26243,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"f8fd8244-76f6-41c6-ceb6-27914a9ce833"},"source":["data_fr = 'data/training/news-commentary-v9.fr-en.fr'\r\n","data_en = 'data/training/news-commentary-v9.fr-en.en'\r\n","\r\n","with open(data_fr, 'rb') as fr: \r\n","  sents_fr = [line.decode(\"utf-8\") for line in fr]      \r\n"," # sents_cs = [value for value in sents_cs if value != '']   \r\n","with open(data_en, 'rb') as en: \r\n","  sents_en = [line.decode(\"utf-8\") for line in en]\r\n"," # sents_en = [value for value in sents_en if value != '']\r\n","len(sents_en), len(sents_fr)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(183251, 183251)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08DjJdxvxuAW","executionInfo":{"status":"ok","timestamp":1615719818740,"user_tz":-480,"elapsed":26731,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"a01d3480-2554-4cee-adff-2cc7279377a8"},"source":["#max length of string \r\n","length_fr = [len(i.split()) for i in sents_fr]\r\n","max(length_fr)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["223"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrrJEeffxuEB","executionInfo":{"status":"ok","timestamp":1615719818741,"user_tz":-480,"elapsed":26726,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"20607990-0ebb-411e-cafd-58ad6b248f10"},"source":["length_en = [len(i.split()) for i in sents_en]\r\n","max(length_en)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["171"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"lXnu1aePaT6s","executionInfo":{"status":"ok","timestamp":1615719819147,"user_tz":-480,"elapsed":27131,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["SOS_token = 0\r\n","EOS_token = 1\r\n","\r\n","class Lang:\r\n","  def __init__(self, name):\r\n","    self.name = name\r\n","    self.word2index = {}\r\n","    self.word2count = {}\r\n","    self.index2word = {0: \"SOS\", 1: \"EOS\"}\r\n","    self.n_words = 2\r\n","\r\n","  def addSentence(self, sentence):\r\n","    \r\n","    for word in sentence.split(' '):\r\n","      self.addWord(word)\r\n","  \r\n","  def addWord(self, word):\r\n","    if word not in self.word2index:\r\n","      self.word2index[word] = self.n_words\r\n","      self.word2count[word] = 1\r\n","      self.index2word[self.n_words] = word \r\n","      self.n_words += 1\r\n","    else:\r\n","      self.word2count[word] += 1\r\n","\r\n","# Turn a Unicode string to plain ASCII, thanks to\r\n","# https://stackoverflow.com/a/518232/2809427\r\n","def unicodeToAscii(s):\r\n","    return ''.join(\r\n","        c for c in unicodedata.normalize('NFD', s)\r\n","        if unicodedata.category(c) != 'Mn'\r\n","    )\r\n","\r\n","# Lowercase, trim, and remove non-letter characters\r\n","\r\n","\r\n","def normalizeString(s):\r\n","    s = unicodeToAscii(s.lower().strip())\r\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\r\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\r\n","    return s"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaTNz04wdqKa","executionInfo":{"status":"ok","timestamp":1615719819148,"user_tz":-480,"elapsed":27130,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["def sent_pairs(lang1=sents_fr, lang2=sents_en):\r\n","  pairs = []\r\n","  for i, (cs_sent, en_sent) in enumerate(zip(lang1, lang2)):\r\n","    #if i < 100:\r\n","      pairs.append([cs_sent, en_sent])\r\n","   # print(i)\r\n","  pairs = [[normalizeString(s) for s in line] for line in pairs]\r\n","  input_lang1 = Lang('fr')\r\n","  output_lang1 = Lang('en')\r\n","\r\n","  input_lang2 = Lang('fr')\r\n","  output_lang2 = Lang('en')\r\n","\r\n","  input_lang3 = Lang('fr')\r\n","  output_lang3 = Lang('en')\r\n","\r\n","  input_lang4 = Lang('fr')\r\n","  output_lang4 = Lang('en')\r\n","\r\n","  input_lang5 = Lang('fr')\r\n","  output_lang5 = Lang('en')\r\n","\r\n","     \r\n","  return input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs\r\n"," "],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TvQxz_O6IMm8"},"source":["The full process for preparing the data is:\r\n","\r\n","-  Read text file and split into lines, split lines into pairs\r\n","-  Normalize text, filter by length and content\r\n","-  Make word lists from sentences in pairs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ll3A_tPrdF8","executionInfo":{"status":"ok","timestamp":1615719859778,"user_tz":-480,"elapsed":67755,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"1d15a65a-f7c0-465c-87d3-066808ccc67a"},"source":["\r\n","def prepareData(lang1=sents_fr, lang2=sents_en):\r\n","    input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs = sent_pairs(lang1, lang2)\r\n","    print(\"Read %s sentence pairs\" % len(pairs))\r\n","\r\n","    #Assumption: as the dataset is news commentary on different topics, there is highly unlikely exactly the same sentences \r\n","    # collect test pairs\r\n","    num_test = int(len(pairs)*0.2)\r\n","    print(\"Number of test pairs:\", num_test)\r\n","    random.seed(3)\r\n","    random.shuffle(pairs)\r\n","    \r\n","    #fold 1\r\n","    test_pairs1 = pairs[:num_test]\r\n","     # collect train pairs\r\n","    train_pairs1 = pairs[num_test:]\r\n","    print(\"Number of train pairs:\", len(train_pairs1))\r\n","    print(\"Counting words...\")\r\n","\r\n","    for pair in train_pairs1:      \r\n","      input_lang1.addSentence(pair[0])\r\n","      output_lang1.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang1.name, input_lang1.n_words)\r\n","    print(output_lang1.name, output_lang1.n_words)\r\n","\r\n","    #fold 2\r\n","    test_pairs2 = pairs[num_test:num_test*2]\r\n","     # collect train pairs\r\n","    train_pairs2 = pairs[:num_test]\r\n","    for x in pairs[num_test*2:]:\r\n","      train_pairs2.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs2))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs2:      \r\n","      input_lang2.addSentence(pair[0])\r\n","      output_lang2.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang2.name, input_lang2.n_words)\r\n","    print(output_lang2.name, output_lang2.n_words)\r\n","\r\n","    #fold 3\r\n","    test_pairs3 = pairs[num_test*2:num_test*3]\r\n","     # collect train pairs\r\n","    train_pairs3 = pairs[:num_test*2]\r\n","    for x in pairs[num_test*3:]:\r\n","      train_pairs3.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs3))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs3:      \r\n","      input_lang3.addSentence(pair[0])\r\n","      output_lang3.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang3.name, input_lang3.n_words)\r\n","    print(output_lang3.name, output_lang3.n_words)\r\n","\r\n","\r\n","    #fold 4\r\n","    test_pairs4 = pairs[num_test*3:num_test*4]\r\n","     # collect train pairs\r\n","    train_pairs4 = pairs[:num_test*3]\r\n","    for x in pairs[num_test*4:]:\r\n","      train_pairs4.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs4))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs4:      \r\n","      input_lang4.addSentence(pair[0])\r\n","      output_lang4.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang4.name, input_lang4.n_words)\r\n","    print(output_lang4.name, output_lang4.n_words)\r\n","\r\n","    #fold 5\r\n","    test_pairs5 = pairs[num_test*4:]\r\n","     # collect train pairs\r\n","    train_pairs5 = pairs[:num_test*4]\r\n","    print(\"Number of train pairs:\", len(train_pairs5))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs5:      \r\n","      input_lang5.addSentence(pair[0])\r\n","      output_lang5.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang5.name, input_lang5.n_words)\r\n","    print(output_lang5.name, output_lang5.n_words)\r\n","\r\n","\r\n","    return (input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4,input_lang5, output_lang5,train_pairs1, \r\n","            test_pairs1, train_pairs2, test_pairs2, train_pairs3, test_pairs3,train_pairs4, test_pairs4,train_pairs5, test_pairs5)\r\n","\r\n","\r\n","(input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, train_pairs1, test_pairs1, train_pairs2,\r\n"," test_pairs2,train_pairs3, test_pairs3, train_pairs4, test_pairs4,train_pairs5, test_pairs5) = prepareData(sents_fr, sents_en)\r\n","print(random.choice(train_pairs1))\r\n","print(random.choice(train_pairs2))\r\n","print(random.choice(train_pairs3))\r\n","print(random.choice(train_pairs4))\r\n","print(random.choice(train_pairs5))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Read 183251 sentence pairs\n","Number of test pairs: 36650\n","Number of train pairs: 146601\n","Counting words...\n","Counted words:\n","fr 57432\n","en 42977\n","Number of train pairs: 146601\n","Counting words...\n","Counted words:\n","fr 57510\n","en 42960\n","Number of train pairs: 146601\n","Counting words...\n","Counted words:\n","fr 57715\n","en 43042\n","Number of train pairs: 146601\n","Counting words...\n","Counted words:\n","fr 57623\n","en 43010\n","Number of train pairs: 146600\n","Counting words...\n","Counted words:\n","fr 57515\n","en 42988\n","['de petits groupes de palestiniens demolissent les vestiges des infrastructures industrielles aneanties par les bombes des blocs de beton qui polluent le paysage sablonneux .', 'small groups of palestinians smash up the remains of gaza s bombed industrial infrastructure the concrete blocks that litter the sandy landscape .']\n","['les hierarques chiites ayant coutume de releguer l avenement du mahdi a un avenir eloigne le penchant millenariste d ahmadinejad les agacent .', 'for the shia religious hierarchy long accustomed to relegating the advent of the mahdi to a distant future ahmadinejad s insistent millenarianism is troublesome .']\n","['le pari de bush est perdu d avance avec des consequences qui seront couteuses d abord pour les usa mais aussi pour le reste du monde .', 'bush s gamble was a loser from the start generating costly results mainly for the us but for the rest of the world too for years to come .']\n","['elu a une majorite ecrasante pour laver de ses vices le systeme politique auquel il a succede chavez a choisi de jeter le bebe avec l eau du bain .', 'elected in a landslide to clean up the political vices of the previous establishment chavez chose to throw the baby out with the bathwater .']\n","['les partisans du nouvel imperialisme nous diraient de ne pas prendre cela au pied de la lettre .', 'devotees of the new imperialism would say don t to be so literal . ']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"npNTNDUOOwoC","executionInfo":{"status":"ok","timestamp":1615719860114,"user_tz":-480,"elapsed":68089,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 235\r\n","class AttnDecoderRNN2(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN2, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","         \r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        #print(encoder_outputs.unsqueeze(0).shape, hidden.view(1, -1, 1).shape)\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","            torch.bmm(encoder_outputs.unsqueeze(0),hidden.view(1, -1, 1)).view(1,-1), dim=1) #dot product\r\n","            #################################\r\n","        #print(attn_weights.shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang1, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang1, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs1))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjoCFY3nTmBG","executionInfo":{"status":"ok","timestamp":1615719862105,"user_tz":-480,"elapsed":70079,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang1, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang1.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang1, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang1.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang1.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs1)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs1:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs1:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08M4DvfPToJk","executionInfo":{"status":"ok","timestamp":1615726196610,"user_tz":-480,"elapsed":6404578,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"607aa86c-86be-40db-83cb-65959d5ad4bc"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang1.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN2(hidden_size, output_lang1.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["1m 12s (- 89m 37s) (1000 1%) 5.9758\n","2m 16s (- 83m 10s) (2000 2%) 5.6541\n","3m 23s (- 81m 13s) (3000 4%) 5.6063\n","4m 28s (- 79m 19s) (4000 5%) 5.5559\n","5m 37s (- 78m 38s) (5000 6%) 5.6226\n","6m 40s (- 76m 50s) (6000 8%) 5.3775\n","7m 45s (- 75m 20s) (7000 9%) 5.3900\n","8m 53s (- 74m 27s) (8000 10%) 5.4831\n","9m 59s (- 73m 14s) (9000 12%) 5.3764\n","11m 6s (- 72m 11s) (10000 13%) 5.3520\n","12m 12s (- 71m 4s) (11000 14%) 5.4529\n","13m 19s (- 69m 58s) (12000 16%) 5.3999\n","14m 28s (- 69m 1s) (13000 17%) 5.4488\n","15m 37s (- 68m 5s) (14000 18%) 5.5397\n","16m 46s (- 67m 7s) (15000 20%) 5.5582\n","17m 56s (- 66m 10s) (16000 21%) 5.6934\n","19m 5s (- 65m 8s) (17000 22%) 5.6072\n","20m 17s (- 64m 15s) (18000 24%) 5.6311\n","21m 27s (- 63m 14s) (19000 25%) 5.6768\n","22m 41s (- 62m 25s) (20000 26%) 5.7638\n","23m 54s (- 61m 27s) (21000 28%) 5.6460\n","25m 3s (- 60m 22s) (22000 29%) 5.5943\n","26m 15s (- 59m 22s) (23000 30%) 5.6245\n","27m 28s (- 58m 23s) (24000 32%) 5.5824\n","28m 39s (- 57m 19s) (25000 33%) 5.5680\n","29m 51s (- 56m 16s) (26000 34%) 5.5251\n","31m 6s (- 55m 18s) (27000 36%) 5.6212\n","32m 17s (- 54m 12s) (28000 37%) 5.5369\n","33m 28s (- 53m 6s) (29000 38%) 5.6045\n","34m 40s (- 52m 1s) (30000 40%) 5.5655\n","35m 51s (- 50m 53s) (31000 41%) 5.4808\n","37m 4s (- 49m 49s) (32000 42%) 5.5833\n","38m 17s (- 48m 44s) (33000 44%) 5.5225\n","39m 30s (- 47m 38s) (34000 45%) 5.5414\n","40m 43s (- 46m 32s) (35000 46%) 5.5097\n","41m 57s (- 45m 26s) (36000 48%) 5.5648\n","43m 10s (- 44m 20s) (37000 49%) 5.5230\n","44m 20s (- 43m 10s) (38000 50%) 5.4698\n","45m 31s (- 42m 1s) (39000 52%) 5.5101\n","46m 43s (- 40m 53s) (40000 53%) 5.4699\n","47m 56s (- 39m 45s) (41000 54%) 5.4840\n","49m 8s (- 38m 36s) (42000 56%) 5.4364\n","50m 19s (- 37m 27s) (43000 57%) 5.3704\n","51m 29s (- 36m 16s) (44000 58%) 5.3666\n","52m 42s (- 35m 8s) (45000 60%) 5.4594\n","53m 55s (- 33m 59s) (46000 61%) 5.4600\n","55m 6s (- 32m 49s) (47000 62%) 5.3387\n","56m 18s (- 31m 40s) (48000 64%) 5.3812\n","57m 30s (- 30m 31s) (49000 65%) 5.4149\n","58m 41s (- 29m 20s) (50000 66%) 5.3384\n","59m 53s (- 28m 10s) (51000 68%) 5.3746\n","61m 3s (- 27m 0s) (52000 69%) 5.3601\n","62m 15s (- 25m 50s) (53000 70%) 5.3725\n","63m 28s (- 24m 41s) (54000 72%) 5.3719\n","64m 39s (- 23m 30s) (55000 73%) 5.3083\n","65m 51s (- 22m 20s) (56000 74%) 5.3593\n","67m 1s (- 21m 9s) (57000 76%) 5.2210\n","68m 14s (- 20m 0s) (58000 77%) 5.3575\n","69m 27s (- 18m 50s) (59000 78%) 5.2964\n","70m 40s (- 17m 40s) (60000 80%) 5.2750\n","71m 53s (- 16m 29s) (61000 81%) 5.3659\n","73m 5s (- 15m 19s) (62000 82%) 5.3119\n","74m 16s (- 14m 8s) (63000 84%) 5.2778\n","75m 27s (- 12m 58s) (64000 85%) 5.1803\n","76m 39s (- 11m 47s) (65000 86%) 5.2933\n","77m 51s (- 10m 36s) (66000 88%) 5.2928\n","79m 3s (- 9m 26s) (67000 89%) 5.2278\n","80m 16s (- 8m 15s) (68000 90%) 5.2170\n","81m 29s (- 7m 5s) (69000 92%) 5.2480\n","82m 41s (- 5m 54s) (70000 93%) 5.2291\n","83m 52s (- 4m 43s) (71000 94%) 5.1144\n","85m 4s (- 3m 32s) (72000 96%) 5.2145\n","86m 15s (- 2m 21s) (73000 97%) 5.2066\n","87m 27s (- 1m 10s) (74000 98%) 5.2565\n","88m 39s (- 0m 0s) (75000 100%) 5.1914\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are  [0.19826077298283268, 0.06482037869684233, 0.022138214204262537]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8X7TtXWDvQCS"},"source":["###Fold2"]},{"cell_type":"code","metadata":{"id":"zTgC4HZSt6XD","executionInfo":{"status":"ok","timestamp":1615726196886,"user_tz":-480,"elapsed":6404853,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 235\r\n","class AttnDecoderRNN2(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN2, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","         \r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        #print(encoder_outputs.unsqueeze(0).shape, hidden.view(1, -1, 1).shape)\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","            torch.bmm(encoder_outputs.unsqueeze(0),hidden.view(1, -1, 1)).view(1,-1), dim=1) #dot product\r\n","            #################################\r\n","        #print(attn_weights.shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang2, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang2, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs2))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xj4EasFzvVmP","executionInfo":{"status":"ok","timestamp":1615726197227,"user_tz":-480,"elapsed":6405192,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang2, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang2.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang2, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang2.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang2.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs2)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs2:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs2:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ab6RRAYUvcdZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615732531955,"user_tz":-480,"elapsed":12739919,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"5516ea4c-3efa-4090-c325-1406f07f3018"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang2.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN2(hidden_size, output_lang2.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["1m 13s (- 90m 38s) (1000 1%) 6.2020\n","2m 20s (- 85m 36s) (2000 2%) 5.7192\n","3m 25s (- 82m 20s) (3000 4%) 5.4713\n","4m 31s (- 80m 17s) (4000 5%) 5.6016\n","5m 37s (- 78m 42s) (5000 6%) 5.5824\n","6m 40s (- 76m 42s) (6000 8%) 5.2177\n","7m 45s (- 75m 23s) (7000 9%) 5.3282\n","8m 51s (- 74m 12s) (8000 10%) 5.3163\n","9m 57s (- 73m 3s) (9000 12%) 5.3405\n","11m 4s (- 71m 57s) (10000 13%) 5.3240\n","12m 8s (- 70m 41s) (11000 14%) 5.2313\n","13m 17s (- 69m 44s) (12000 16%) 5.3763\n","14m 24s (- 68m 41s) (13000 17%) 5.5458\n","15m 33s (- 67m 47s) (14000 18%) 5.5853\n","16m 44s (- 66m 57s) (15000 20%) 5.6376\n","17m 54s (- 66m 2s) (16000 21%) 5.5812\n","19m 4s (- 65m 3s) (17000 22%) 5.5037\n","20m 13s (- 64m 2s) (18000 24%) 5.5927\n","21m 27s (- 63m 13s) (19000 25%) 5.6631\n","22m 37s (- 62m 13s) (20000 26%) 5.6155\n","23m 48s (- 61m 13s) (21000 28%) 5.5333\n","24m 59s (- 60m 12s) (22000 29%) 5.5345\n","26m 12s (- 59m 14s) (23000 30%) 5.5639\n","27m 24s (- 58m 14s) (24000 32%) 5.5362\n","28m 33s (- 57m 7s) (25000 33%) 5.4928\n","29m 44s (- 56m 3s) (26000 34%) 5.5243\n","30m 54s (- 54m 56s) (27000 36%) 5.5221\n","32m 4s (- 53m 49s) (28000 37%) 5.4995\n","33m 16s (- 52m 46s) (29000 38%) 5.5349\n","34m 26s (- 51m 40s) (30000 40%) 5.3930\n","35m 36s (- 50m 31s) (31000 41%) 5.4728\n","36m 47s (- 49m 26s) (32000 42%) 5.3515\n","37m 55s (- 48m 16s) (33000 44%) 5.4650\n","39m 6s (- 47m 10s) (34000 45%) 5.4715\n","40m 17s (- 46m 2s) (35000 46%) 5.4040\n","41m 28s (- 44m 56s) (36000 48%) 5.3850\n","42m 38s (- 43m 47s) (37000 49%) 5.3830\n","43m 50s (- 42m 41s) (38000 50%) 5.4663\n","45m 2s (- 41m 34s) (39000 52%) 5.4201\n","46m 13s (- 40m 26s) (40000 53%) 5.4401\n","47m 23s (- 39m 17s) (41000 54%) 5.3842\n","48m 33s (- 38m 9s) (42000 56%) 5.3800\n","49m 44s (- 37m 0s) (43000 57%) 5.3723\n","50m 55s (- 35m 52s) (44000 58%) 5.3019\n","52m 6s (- 34m 44s) (45000 60%) 5.3583\n","53m 17s (- 33m 36s) (46000 61%) 5.3871\n","54m 29s (- 32m 27s) (47000 62%) 5.3350\n","55m 41s (- 31m 19s) (48000 64%) 5.3818\n","56m 51s (- 30m 10s) (49000 65%) 5.2911\n","58m 1s (- 29m 0s) (50000 66%) 5.2901\n","59m 11s (- 27m 51s) (51000 68%) 5.2862\n","60m 23s (- 26m 42s) (52000 69%) 5.3303\n","61m 34s (- 25m 33s) (53000 70%) 5.3003\n","62m 45s (- 24m 24s) (54000 72%) 5.3529\n","63m 56s (- 23m 14s) (55000 73%) 5.1715\n","65m 6s (- 22m 5s) (56000 74%) 5.2626\n","66m 17s (- 20m 56s) (57000 76%) 5.1791\n","67m 29s (- 19m 47s) (58000 77%) 5.2520\n","68m 40s (- 18m 37s) (59000 78%) 5.2222\n","69m 51s (- 17m 27s) (60000 80%) 5.2255\n","71m 2s (- 16m 18s) (61000 81%) 5.2477\n","72m 12s (- 15m 8s) (62000 82%) 5.2310\n","73m 24s (- 13m 58s) (63000 84%) 5.1575\n","74m 36s (- 12m 49s) (64000 85%) 5.2328\n","75m 48s (- 11m 39s) (65000 86%) 5.1998\n","76m 59s (- 10m 29s) (66000 88%) 5.2156\n","78m 10s (- 9m 20s) (67000 89%) 5.2357\n","79m 21s (- 8m 10s) (68000 90%) 5.1812\n","80m 32s (- 7m 0s) (69000 92%) 5.2270\n","81m 44s (- 5m 50s) (70000 93%) 5.2298\n","82m 58s (- 4m 40s) (71000 94%) 5.2326\n","84m 9s (- 3m 30s) (72000 96%) 5.1152\n","85m 18s (- 2m 20s) (73000 97%) 5.1577\n","86m 26s (- 1m 10s) (74000 98%) 5.0788\n","87m 37s (- 0m 0s) (75000 100%) 5.1756\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are  [0.18856841872817487, 0.05816174101465158, 0.019515511017228742]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_1_JxzKvxF5N"},"source":["###Fold 3"]},{"cell_type":"code","metadata":{"id":"WeLVXQOhxCMM","executionInfo":{"status":"ok","timestamp":1615732532246,"user_tz":-480,"elapsed":12740209,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 235\r\n","class AttnDecoderRNN2(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN2, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","         \r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        #print(encoder_outputs.unsqueeze(0).shape, hidden.view(1, -1, 1).shape)\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","            torch.bmm(encoder_outputs.unsqueeze(0),hidden.view(1, -1, 1)).view(1,-1), dim=1) #dot product\r\n","            #################################\r\n","        #print(attn_weights.shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang3, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang3, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs3))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"9bSwRykXxK_K","executionInfo":{"status":"ok","timestamp":1615732532521,"user_tz":-480,"elapsed":12740482,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang3, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang3.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang3, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang3.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang3.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs3)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs3:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs3:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"aDUlbFWuxLFl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615738791059,"user_tz":-480,"elapsed":18999019,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"d2238af4-17f4-48b5-b7db-9d4b217cee49"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang3.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN2(hidden_size, output_lang3.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["1m 12s (- 89m 27s) (1000 1%) 6.0289\n","2m 17s (- 83m 21s) (2000 2%) 5.6353\n","3m 21s (- 80m 27s) (3000 4%) 5.4675\n","4m 24s (- 78m 21s) (4000 5%) 5.5239\n","5m 28s (- 76m 44s) (5000 6%) 5.3490\n","6m 32s (- 75m 12s) (6000 8%) 5.1971\n","7m 37s (- 74m 1s) (7000 9%) 5.2959\n","8m 42s (- 72m 53s) (8000 10%) 5.3540\n","9m 46s (- 71m 44s) (9000 12%) 5.3301\n","10m 52s (- 70m 44s) (10000 13%) 5.3328\n","11m 57s (- 69m 35s) (11000 14%) 5.4209\n","13m 3s (- 68m 35s) (12000 16%) 5.4087\n","14m 11s (- 67m 39s) (13000 17%) 5.4037\n","15m 18s (- 66m 42s) (14000 18%) 5.5145\n","16m 28s (- 65m 52s) (15000 20%) 5.6606\n","17m 37s (- 64m 58s) (16000 21%) 5.5544\n","18m 47s (- 64m 6s) (17000 22%) 5.6030\n","19m 57s (- 63m 12s) (18000 24%) 5.5948\n","21m 7s (- 62m 15s) (19000 25%) 5.5976\n","22m 17s (- 61m 17s) (20000 26%) 5.6041\n","23m 27s (- 60m 18s) (21000 28%) 5.6085\n","24m 38s (- 59m 22s) (22000 29%) 5.6377\n","25m 46s (- 58m 17s) (23000 30%) 5.5091\n","26m 57s (- 57m 16s) (24000 32%) 5.6091\n","28m 6s (- 56m 12s) (25000 33%) 5.5393\n","29m 15s (- 55m 8s) (26000 34%) 5.5859\n","30m 25s (- 54m 5s) (27000 36%) 5.5405\n","31m 35s (- 53m 1s) (28000 37%) 5.5088\n","32m 45s (- 51m 58s) (29000 38%) 5.6046\n","33m 57s (- 50m 56s) (30000 40%) 5.5684\n","35m 7s (- 49m 50s) (31000 41%) 5.4730\n","36m 17s (- 48m 46s) (32000 42%) 5.5198\n","37m 26s (- 47m 39s) (33000 44%) 5.4785\n","38m 37s (- 46m 34s) (34000 45%) 5.5040\n","39m 46s (- 45m 26s) (35000 46%) 5.4404\n","40m 57s (- 44m 22s) (36000 48%) 5.4228\n","42m 8s (- 43m 17s) (37000 49%) 5.4555\n","43m 19s (- 42m 11s) (38000 50%) 5.4738\n","44m 29s (- 41m 4s) (39000 52%) 5.3749\n","45m 40s (- 39m 57s) (40000 53%) 5.4235\n","46m 51s (- 38m 51s) (41000 54%) 5.4035\n","48m 0s (- 37m 43s) (42000 56%) 5.3138\n","49m 10s (- 36m 35s) (43000 57%) 5.3969\n","50m 19s (- 35m 27s) (44000 58%) 5.3425\n","51m 29s (- 34m 19s) (45000 60%) 5.3031\n","52m 39s (- 33m 12s) (46000 61%) 5.3412\n","53m 49s (- 32m 3s) (47000 62%) 5.3263\n","54m 58s (- 30m 55s) (48000 64%) 5.2859\n","56m 9s (- 29m 47s) (49000 65%) 5.2698\n","57m 19s (- 28m 39s) (50000 66%) 5.2958\n","58m 32s (- 27m 33s) (51000 68%) 5.3075\n","59m 41s (- 26m 24s) (52000 69%) 5.3120\n","60m 53s (- 25m 16s) (53000 70%) 5.3109\n","62m 4s (- 24m 8s) (54000 72%) 5.3375\n","63m 15s (- 23m 0s) (55000 73%) 5.3050\n","64m 25s (- 21m 51s) (56000 74%) 5.2058\n","65m 35s (- 20m 42s) (57000 76%) 5.2119\n","66m 46s (- 19m 34s) (58000 77%) 5.2881\n","67m 57s (- 18m 25s) (59000 78%) 5.3329\n","69m 8s (- 17m 17s) (60000 80%) 5.2492\n","70m 21s (- 16m 8s) (61000 81%) 5.2470\n","71m 33s (- 15m 0s) (62000 82%) 5.2730\n","72m 48s (- 13m 52s) (63000 84%) 5.3084\n","73m 59s (- 12m 42s) (64000 85%) 5.2213\n","75m 10s (- 11m 33s) (65000 86%) 5.1970\n","76m 22s (- 10m 24s) (66000 88%) 5.1907\n","77m 31s (- 9m 15s) (67000 89%) 5.1191\n","78m 43s (- 8m 6s) (68000 90%) 5.2213\n","79m 55s (- 6m 57s) (69000 92%) 5.2093\n","81m 6s (- 5m 47s) (70000 93%) 5.1788\n","82m 18s (- 4m 38s) (71000 94%) 5.2101\n","83m 27s (- 3m 28s) (72000 96%) 5.1616\n","84m 38s (- 2m 19s) (73000 97%) 5.1822\n","85m 49s (- 1m 9s) (74000 98%) 5.2187\n","86m 59s (- 0m 0s) (75000 100%) 5.0990\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are  [0.18596496401447066, 0.06072425983537766, 0.021333504314771712]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"34QQDEirydMQ"},"source":["###Fold 4"]},{"cell_type":"code","metadata":{"id":"zCnOu5OXyPVu","executionInfo":{"status":"ok","timestamp":1615738791344,"user_tz":-480,"elapsed":18999303,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 235\r\n","class AttnDecoderRNN2(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN2, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","         \r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        #print(encoder_outputs.unsqueeze(0).shape, hidden.view(1, -1, 1).shape)\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","            torch.bmm(encoder_outputs.unsqueeze(0),hidden.view(1, -1, 1)).view(1,-1), dim=1) #dot product\r\n","            #################################\r\n","        #print(attn_weights.shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang4, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang4, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs4))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"avak6eD9yXww","executionInfo":{"status":"ok","timestamp":1615738791635,"user_tz":-480,"elapsed":18999592,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang4, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang4.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang4, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang4.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang4.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs4)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs4:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs4:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVOKFdzNyYXX","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"error","timestamp":1615738813843,"user_tz":-480,"elapsed":19021799,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"ebfd96ab-beab-4632-ef1a-0e995cd700d7"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang4.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN2(hidden_size, output_lang4.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":20,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-3e9bc024432e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#reduce number of epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluateBleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-c94345cb2ec8>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m--> 183\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-c94345cb2ec8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             decoder_output, decoder_hidden, decoder_attention = decoder(\n\u001b[0;32m--> 125\u001b[0;31m                 decoder_input, decoder_hidden, encoder_outputs)\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Teacher forcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-c94345cb2ec8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 822\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    823\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"DtGbDe1GzSK9"},"source":["###Fold 5"]},{"cell_type":"code","metadata":{"id":"rM5o8g5vzQE7","executionInfo":{"status":"aborted","timestamp":1615738813074,"user_tz":-480,"elapsed":19021029,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 235\r\n","class AttnDecoderRNN2(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN2, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","         \r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        #print(encoder_outputs.unsqueeze(0).shape, hidden.view(1, -1, 1).shape)\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","            torch.bmm(encoder_outputs.unsqueeze(0),hidden.view(1, -1, 1)).view(1,-1), dim=1) #dot product\r\n","            #################################\r\n","        #print(attn_weights.shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang5, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang5, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs5))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JP78TY53zYHd","executionInfo":{"status":"aborted","timestamp":1615738813076,"user_tz":-480,"elapsed":19021029,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang5, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang5.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang5, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang5.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang5.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs5)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs5:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs5:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6u-YKVdSzaVV","executionInfo":{"status":"aborted","timestamp":1615738813077,"user_tz":-480,"elapsed":19021029,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang5.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN2(hidden_size, output_lang5.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P8qMVNHB402u","executionInfo":{"status":"aborted","timestamp":1615738813077,"user_tz":-480,"elapsed":19021027,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YK2wKfXx41dq","executionInfo":{"status":"aborted","timestamp":1615738813078,"user_tz":-480,"elapsed":19021027,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":[""],"execution_count":null,"outputs":[]}]}