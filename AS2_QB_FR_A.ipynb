{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"AS2_QB_FR_A.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"uT-lrh1Xe3ry","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615773977076,"user_tz":-480,"elapsed":18718,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"6fac975d-30a9-4799-cf40-2048c3596c42"},"source":["import sys,os\r\n","if 'google.colab' in sys.modules:\r\n","  from google.colab import drive\r\n","  drive.mount('/content/gdrive')\r\n","  path_to_file = '/content/gdrive/My Drive/AI Sem II/NLP/A2'\r\n","  print(path_to_file)\r\n","  os.chdir(path_to_file)\r\n","  !pwd"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/AI Sem II/NLP/A2\n","/content/gdrive/My Drive/AI Sem II/NLP/A2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sUm8xUsPjECA","executionInfo":{"status":"ok","timestamp":1615773985108,"user_tz":-480,"elapsed":3128,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["from __future__ import unicode_literals, print_function, division\r\n","from io import open\r\n","import unicodedata\r\n","import string\r\n","import re\r\n","import random\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","from torch import optim\r\n","import torch.nn.functional as F\r\n","\r\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjR9yaPeIEDs","executionInfo":{"status":"ok","timestamp":1615773991000,"user_tz":-480,"elapsed":8535,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"eed7f76c-ea92-40e7-c7d8-b7795cea191c"},"source":["data_fr = 'data/training/news-commentary-v9.fr-en.fr'\r\n","data_en = 'data/training/news-commentary-v9.fr-en.en'\r\n","\r\n","with open(data_fr, 'rb') as fr: \r\n","  sents_fr = [line.decode(\"utf-8\") for line in fr]      \r\n"," # sents_cs = [value for value in sents_cs if value != '']   \r\n","with open(data_en, 'rb') as en: \r\n","  sents_en = [line.decode(\"utf-8\") for line in en]\r\n"," # sents_en = [value for value in sents_en if value != '']\r\n","len(sents_en), len(sents_fr)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(183251, 183251)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08DjJdxvxuAW","executionInfo":{"status":"ok","timestamp":1615773991001,"user_tz":-480,"elapsed":7349,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"b4880f0d-eb8b-46a5-db19-ba79d455451f"},"source":["#max length of string \r\n","length_fr = [len(i.split()) for i in sents_fr]\r\n","max(length_fr)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["223"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrrJEeffxuEB","executionInfo":{"status":"ok","timestamp":1615773991548,"user_tz":-480,"elapsed":7484,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"ca5d33fb-a1a5-4daa-8ee7-29bcae3ed1bf"},"source":["length_en = [len(i.split()) for i in sents_en]\r\n","max(length_en)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["171"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"lXnu1aePaT6s","executionInfo":{"status":"ok","timestamp":1615773991548,"user_tz":-480,"elapsed":6472,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["SOS_token = 0\r\n","EOS_token = 1\r\n","\r\n","class Lang:\r\n","  def __init__(self, name):\r\n","    self.name = name\r\n","    self.word2index = {}\r\n","    self.word2count = {}\r\n","    self.index2word = {0: \"SOS\", 1: \"EOS\"}\r\n","    self.n_words = 2\r\n","\r\n","  def addSentence(self, sentence):\r\n","    \r\n","    for word in sentence.split(' '):\r\n","      self.addWord(word)\r\n","  \r\n","  def addWord(self, word):\r\n","    if word not in self.word2index:\r\n","      self.word2index[word] = self.n_words\r\n","      self.word2count[word] = 1\r\n","      self.index2word[self.n_words] = word \r\n","      self.n_words += 1\r\n","    else:\r\n","      self.word2count[word] += 1\r\n","\r\n","# Turn a Unicode string to plain ASCII, thanks to\r\n","# https://stackoverflow.com/a/518232/2809427\r\n","def unicodeToAscii(s):\r\n","    return ''.join(\r\n","        c for c in unicodedata.normalize('NFD', s)\r\n","        if unicodedata.category(c) != 'Mn'\r\n","    )\r\n","\r\n","# Lowercase, trim, and remove non-letter characters\r\n","\r\n","\r\n","def normalizeString(s):\r\n","    s = unicodeToAscii(s.lower().strip())\r\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\r\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\r\n","    return s"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaTNz04wdqKa","executionInfo":{"status":"ok","timestamp":1615773991549,"user_tz":-480,"elapsed":5513,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["def sent_pairs(lang1=sents_fr, lang2=sents_en):\r\n","  pairs = []\r\n","  for i, (cs_sent, en_sent) in enumerate(zip(lang1, lang2)):\r\n","    #if i < 100:\r\n","      pairs.append([cs_sent, en_sent])\r\n","   # print(i)\r\n","  pairs = [[normalizeString(s) for s in line] for line in pairs]\r\n","  input_lang1 = Lang('fr')\r\n","  output_lang1 = Lang('en')\r\n","\r\n","  input_lang2 = Lang('fr')\r\n","  output_lang2 = Lang('en')\r\n","\r\n","  input_lang3 = Lang('fr')\r\n","  output_lang3 = Lang('en')\r\n","\r\n","  input_lang4 = Lang('fr')\r\n","  output_lang4 = Lang('en')\r\n","\r\n","  input_lang5 = Lang('fr')\r\n","  output_lang5 = Lang('en')\r\n","\r\n","     \r\n","  return input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs\r\n"," "],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TvQxz_O6IMm8"},"source":["The full process for preparing the data is:\r\n","\r\n","-  Read text file and split into lines, split lines into pairs\r\n","-  Normalize text, filter by length and content\r\n","-  Make word lists from sentences in pairs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ll3A_tPrdF8","executionInfo":{"status":"ok","timestamp":1615774024830,"user_tz":-480,"elapsed":32934,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"19182586-037b-429a-d116-889174b8f683"},"source":["\r\n","def prepareData(lang1=sents_fr, lang2=sents_en):\r\n","    input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs = sent_pairs(lang1, lang2)\r\n","    print(\"Read %s sentence pairs\" % len(pairs))\r\n","\r\n","    #Assumption: as the dataset is news commentary on different topics, there is highly unlikely exactly the same sentences \r\n","    # collect test pairs\r\n","    num_test = int(len(pairs)*0.2)\r\n","    print(\"Number of test pairs:\", num_test)\r\n","    random.seed(3)\r\n","    random.shuffle(pairs)\r\n","    \r\n","    #fold 1\r\n","    test_pairs1 = pairs[:num_test]\r\n","     # collect train pairs\r\n","    train_pairs1 = pairs[num_test:]\r\n","    print(\"Number of train pairs:\", len(train_pairs1))\r\n","    print(\"Counting words...\")\r\n","\r\n","    for pair in train_pairs1:      \r\n","      input_lang1.addSentence(pair[0])\r\n","      output_lang1.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang1.name, input_lang1.n_words)\r\n","    print(output_lang1.name, output_lang1.n_words)\r\n","\r\n","    #fold 2\r\n","    test_pairs2 = pairs[num_test:num_test*2]\r\n","     # collect train pairs\r\n","    train_pairs2 = pairs[:num_test]\r\n","    for x in pairs[num_test*2:]:\r\n","      train_pairs2.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs2))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs2:      \r\n","      input_lang2.addSentence(pair[0])\r\n","      output_lang2.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang2.name, input_lang2.n_words)\r\n","    print(output_lang2.name, output_lang2.n_words)\r\n","\r\n","    #fold 3\r\n","    test_pairs3 = pairs[num_test*2:num_test*3]\r\n","     # collect train pairs\r\n","    train_pairs3 = pairs[:num_test*2]\r\n","    for x in pairs[num_test*3:]:\r\n","      train_pairs3.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs3))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs3:      \r\n","      input_lang3.addSentence(pair[0])\r\n","      output_lang3.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang3.name, input_lang3.n_words)\r\n","    print(output_lang3.name, output_lang3.n_words)\r\n","\r\n","\r\n","    #fold 4\r\n","    test_pairs4 = pairs[num_test*3:num_test*4]\r\n","     # collect train pairs\r\n","    train_pairs4 = pairs[:num_test*3]\r\n","    for x in pairs[num_test*4:]:\r\n","      train_pairs4.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs4))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs4:      \r\n","      input_lang4.addSentence(pair[0])\r\n","      output_lang4.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang4.name, input_lang4.n_words)\r\n","    print(output_lang4.name, output_lang4.n_words)\r\n","\r\n","    #fold 5\r\n","    test_pairs5 = pairs[num_test*4:]\r\n","     # collect train pairs\r\n","    train_pairs5 = pairs[:num_test*4]\r\n","    print(\"Number of train pairs:\", len(train_pairs5))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs5:      \r\n","      input_lang5.addSentence(pair[0])\r\n","      output_lang5.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang5.name, input_lang5.n_words)\r\n","    print(output_lang5.name, output_lang5.n_words)\r\n","\r\n","\r\n","    return (input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4,input_lang5, output_lang5,train_pairs1, \r\n","            test_pairs1, train_pairs2, test_pairs2, train_pairs3, test_pairs3,train_pairs4, test_pairs4,train_pairs5, test_pairs5)\r\n","\r\n","\r\n","(input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, train_pairs1, test_pairs1, train_pairs2,\r\n"," test_pairs2,train_pairs3, test_pairs3, train_pairs4, test_pairs4,train_pairs5, test_pairs5) = prepareData(sents_fr, sents_en)\r\n","print(random.choice(train_pairs1))\r\n","print(random.choice(train_pairs2))\r\n","print(random.choice(train_pairs3))\r\n","print(random.choice(train_pairs4))\r\n","print(random.choice(train_pairs5))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Read 183251 sentence pairs\n","Number of test pairs: 36650\n","Number of train pairs: 146601\n","Counting words...\n","Counted words:\n","fr 57432\n","en 42977\n","Number of train pairs: 146601\n","Counting words...\n","Counted words:\n","fr 57510\n","en 42960\n","Number of train pairs: 146601\n","Counting words...\n","Counted words:\n","fr 57715\n","en 43042\n","Number of train pairs: 146601\n","Counting words...\n","Counted words:\n","fr 57623\n","en 43010\n","Number of train pairs: 146600\n","Counting words...\n","Counted words:\n","fr 57515\n","en 42988\n","['de petits groupes de palestiniens demolissent les vestiges des infrastructures industrielles aneanties par les bombes des blocs de beton qui polluent le paysage sablonneux .', 'small groups of palestinians smash up the remains of gaza s bombed industrial infrastructure the concrete blocks that litter the sandy landscape .']\n","['les hierarques chiites ayant coutume de releguer l avenement du mahdi a un avenir eloigne le penchant millenariste d ahmadinejad les agacent .', 'for the shia religious hierarchy long accustomed to relegating the advent of the mahdi to a distant future ahmadinejad s insistent millenarianism is troublesome .']\n","['le pari de bush est perdu d avance avec des consequences qui seront couteuses d abord pour les usa mais aussi pour le reste du monde .', 'bush s gamble was a loser from the start generating costly results mainly for the us but for the rest of the world too for years to come .']\n","['elu a une majorite ecrasante pour laver de ses vices le systeme politique auquel il a succede chavez a choisi de jeter le bebe avec l eau du bain .', 'elected in a landslide to clean up the political vices of the previous establishment chavez chose to throw the baby out with the bathwater .']\n","['les partisans du nouvel imperialisme nous diraient de ne pas prendre cela au pied de la lettre .', 'devotees of the new imperialism would say don t to be so literal . ']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"npNTNDUOOwoC","executionInfo":{"status":"ok","timestamp":1615774025244,"user_tz":-480,"elapsed":26798,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 240\r\n","# additive https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN3(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN3, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\r\n","        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\r\n","        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\r\n","        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\r\n","        \r\n","        ######################/\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        #print((embedded[0]*hidden[0]).shape)\r\n","\r\n","        #additive\r\n","        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\r\n","        #print(x.unsqueeze(0).shape,self.weight.unsqueeze(2).shape)\r\n","        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \r\n","\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","            alignment_scores.view(1,-1), dim=1) #dot product\r\n","            #################################\r\n","        #print(attn_weights.shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        #print(attn_applied.shape)\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang1, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang1, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs1))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjoCFY3nTmBG","executionInfo":{"status":"ok","timestamp":1615774027756,"user_tz":-480,"elapsed":2511,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang1, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang1.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang1, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang1.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang1.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs1)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs1:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs1:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08M4DvfPToJk","executionInfo":{"status":"ok","timestamp":1615779875298,"user_tz":-480,"elapsed":5850046,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"2f6f1cbf-1c66-4a14-a558-f8b86b072c70"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang1.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang1.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["1m 7s (- 82m 41s) (1000 1%) 6.1527\n","2m 9s (- 78m 31s) (2000 2%) 5.8172\n","3m 11s (- 76m 41s) (3000 4%) 5.5865\n","4m 12s (- 74m 39s) (4000 5%) 5.5127\n","5m 16s (- 73m 49s) (5000 6%) 5.5178\n","6m 16s (- 72m 7s) (6000 8%) 5.3911\n","7m 18s (- 70m 55s) (7000 9%) 5.5033\n","8m 22s (- 70m 9s) (8000 10%) 5.4506\n","9m 26s (- 69m 14s) (9000 12%) 5.5056\n","10m 32s (- 68m 29s) (10000 13%) 5.4993\n","11m 38s (- 67m 41s) (11000 14%) 5.6805\n","12m 44s (- 66m 54s) (12000 16%) 5.6302\n","13m 52s (- 66m 11s) (13000 17%) 5.6400\n","15m 0s (- 65m 23s) (14000 18%) 5.6587\n","16m 7s (- 64m 31s) (15000 20%) 5.6553\n","17m 14s (- 63m 36s) (16000 21%) 5.7069\n","18m 20s (- 62m 36s) (17000 22%) 5.6364\n","19m 29s (- 61m 43s) (18000 24%) 5.6128\n","20m 35s (- 60m 42s) (19000 25%) 5.6012\n","21m 46s (- 59m 52s) (20000 26%) 5.6844\n","22m 54s (- 58m 53s) (21000 28%) 5.5105\n","24m 0s (- 57m 50s) (22000 29%) 5.5662\n","25m 9s (- 56m 52s) (23000 30%) 5.5767\n","26m 19s (- 55m 55s) (24000 32%) 5.5727\n","27m 26s (- 54m 53s) (25000 33%) 5.5189\n","28m 35s (- 53m 52s) (26000 34%) 5.5326\n","29m 46s (- 52m 55s) (27000 36%) 5.5272\n","30m 54s (- 51m 52s) (28000 37%) 5.4978\n","32m 1s (- 50m 47s) (29000 38%) 5.5080\n","33m 9s (- 49m 44s) (30000 40%) 5.4776\n","34m 17s (- 48m 39s) (31000 41%) 5.4492\n","35m 26s (- 47m 37s) (32000 42%) 5.4145\n","36m 36s (- 46m 35s) (33000 44%) 5.4849\n","37m 44s (- 45m 31s) (34000 45%) 5.4453\n","38m 54s (- 44m 27s) (35000 46%) 5.4144\n","40m 4s (- 43m 24s) (36000 48%) 5.4827\n","41m 13s (- 42m 20s) (37000 49%) 5.4115\n","42m 20s (- 41m 13s) (38000 50%) 5.4074\n","43m 28s (- 40m 7s) (39000 52%) 5.4295\n","44m 36s (- 39m 1s) (40000 53%) 5.3519\n","45m 45s (- 37m 56s) (41000 54%) 5.4005\n","46m 54s (- 36m 51s) (42000 56%) 5.3315\n","48m 2s (- 35m 45s) (43000 57%) 5.3431\n","49m 9s (- 34m 38s) (44000 58%) 5.3307\n","50m 18s (- 33m 32s) (45000 60%) 5.3503\n","51m 27s (- 32m 26s) (46000 61%) 5.3696\n","52m 34s (- 31m 19s) (47000 62%) 5.3241\n","53m 43s (- 30m 13s) (48000 64%) 5.3098\n","54m 52s (- 29m 6s) (49000 65%) 5.3898\n","55m 59s (- 27m 59s) (50000 66%) 5.2920\n","57m 7s (- 26m 53s) (51000 68%) 5.3085\n","58m 14s (- 25m 45s) (52000 69%) 5.2729\n","59m 22s (- 24m 38s) (53000 70%) 5.2601\n","60m 30s (- 23m 32s) (54000 72%) 5.2908\n","61m 38s (- 22m 24s) (55000 73%) 5.1932\n","62m 46s (- 21m 17s) (56000 74%) 5.2717\n","63m 53s (- 20m 10s) (57000 76%) 5.2064\n","65m 2s (- 19m 3s) (58000 77%) 5.2250\n","66m 11s (- 17m 57s) (59000 78%) 5.2330\n","67m 20s (- 16m 50s) (60000 80%) 5.1960\n","68m 28s (- 15m 43s) (61000 81%) 5.2485\n","69m 37s (- 14m 35s) (62000 82%) 5.2280\n","70m 44s (- 13m 28s) (63000 84%) 5.2467\n","71m 52s (- 12m 21s) (64000 85%) 5.1804\n","72m 59s (- 11m 13s) (65000 86%) 5.1639\n","74m 7s (- 10m 6s) (66000 88%) 5.2367\n","75m 15s (- 8m 59s) (67000 89%) 5.1273\n","76m 24s (- 7m 51s) (68000 90%) 5.1514\n","77m 34s (- 6m 44s) (69000 92%) 5.2321\n","78m 41s (- 5m 37s) (70000 93%) 5.1429\n","79m 49s (- 4m 29s) (71000 94%) 5.0943\n","80m 57s (- 3m 22s) (72000 96%) 5.1378\n","82m 5s (- 2m 14s) (73000 97%) 5.0911\n","83m 13s (- 1m 7s) (74000 98%) 5.1804\n","84m 21s (- 0m 0s) (75000 100%) 5.1380\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are  [0.20707321079286278, 0.0715959786086017, 0.025452374897928738]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8X7TtXWDvQCS"},"source":["###Fold2"]},{"cell_type":"code","metadata":{"id":"zTgC4HZSt6XD","executionInfo":{"status":"ok","timestamp":1615779912603,"user_tz":-480,"elapsed":1258,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 240\r\n","# additive https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN3(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN3, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\r\n","        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\r\n","        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\r\n","        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\r\n","        \r\n","        ######################/\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        #print((embedded[0]*hidden[0]).shape)\r\n","\r\n","        #additive\r\n","        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\r\n","        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\r\n","        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \r\n","\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","            alignment_scores.view(1,-1), dim=1) #dot product\r\n","            #################################\r\n","        #print(attn_weights.shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        #print(attn_applied.shape)\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang2, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang2, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs2))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xj4EasFzvVmP","executionInfo":{"status":"ok","timestamp":1615779913134,"user_tz":-480,"elapsed":1365,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang2, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang2.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang2, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang2.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang2.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs2)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs2:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs2:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ab6RRAYUvcdZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615785795941,"user_tz":-480,"elapsed":5883443,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"09d9b6cc-1b4f-4f00-df8e-35584f938827"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang2.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang2.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["1m 6s (- 82m 27s) (1000 1%) 6.1464\n","2m 10s (- 79m 28s) (2000 2%) 5.7445\n","3m 13s (- 77m 13s) (3000 4%) 5.5759\n","4m 14s (- 75m 16s) (4000 5%) 5.5351\n","5m 17s (- 74m 2s) (5000 6%) 5.6463\n","6m 17s (- 72m 21s) (6000 8%) 5.2841\n","7m 20s (- 71m 15s) (7000 9%) 5.3697\n","8m 23s (- 70m 17s) (8000 10%) 5.4002\n","9m 26s (- 69m 15s) (9000 12%) 5.4159\n","10m 30s (- 68m 19s) (10000 13%) 5.4464\n","11m 32s (- 67m 11s) (11000 14%) 5.3296\n","12m 39s (- 66m 25s) (12000 16%) 5.5226\n","13m 43s (- 65m 28s) (13000 17%) 5.6374\n","14m 50s (- 64m 39s) (14000 18%) 5.6536\n","15m 57s (- 63m 49s) (15000 20%) 5.6166\n","17m 4s (- 62m 59s) (16000 21%) 5.6640\n","18m 11s (- 62m 3s) (17000 22%) 5.5386\n","19m 17s (- 61m 6s) (18000 24%) 5.6718\n","20m 28s (- 60m 21s) (19000 25%) 5.6649\n","21m 36s (- 59m 24s) (20000 26%) 5.6199\n","22m 44s (- 58m 27s) (21000 28%) 5.5502\n","23m 52s (- 57m 31s) (22000 29%) 5.5632\n","25m 1s (- 56m 35s) (23000 30%) 5.5457\n","26m 10s (- 55m 36s) (24000 32%) 5.5259\n","27m 17s (- 54m 34s) (25000 33%) 5.5433\n","28m 25s (- 53m 33s) (26000 34%) 5.4990\n","29m 32s (- 52m 31s) (27000 36%) 5.5635\n","30m 40s (- 51m 28s) (28000 37%) 5.4838\n","31m 49s (- 50m 29s) (29000 38%) 5.4988\n","32m 59s (- 49m 28s) (30000 40%) 5.5100\n","34m 6s (- 48m 24s) (31000 41%) 5.4745\n","35m 15s (- 47m 22s) (32000 42%) 5.3756\n","36m 21s (- 46m 16s) (33000 44%) 5.4414\n","37m 29s (- 45m 12s) (34000 45%) 5.4361\n","38m 36s (- 44m 7s) (35000 46%) 5.3682\n","39m 46s (- 43m 5s) (36000 48%) 5.4259\n","40m 53s (- 42m 0s) (37000 49%) 5.3977\n","42m 3s (- 40m 56s) (38000 50%) 5.4679\n","43m 12s (- 39m 53s) (39000 52%) 5.4501\n","44m 22s (- 38m 49s) (40000 53%) 5.4368\n","45m 29s (- 37m 43s) (41000 54%) 5.3737\n","46m 36s (- 36m 37s) (42000 56%) 5.3289\n","47m 44s (- 35m 31s) (43000 57%) 5.3384\n","48m 52s (- 34m 26s) (44000 58%) 5.2681\n","50m 1s (- 33m 20s) (45000 60%) 5.3168\n","51m 9s (- 32m 15s) (46000 61%) 5.3139\n","52m 17s (- 31m 9s) (47000 62%) 5.2588\n","53m 25s (- 30m 3s) (48000 64%) 5.3229\n","54m 33s (- 28m 56s) (49000 65%) 5.3030\n","55m 40s (- 27m 50s) (50000 66%) 5.3055\n","56m 48s (- 26m 43s) (51000 68%) 5.3128\n","57m 56s (- 25m 37s) (52000 69%) 5.3201\n","59m 5s (- 24m 31s) (53000 70%) 5.3250\n","60m 14s (- 23m 25s) (54000 72%) 5.3168\n","61m 22s (- 22m 19s) (55000 73%) 5.2770\n","62m 30s (- 21m 12s) (56000 74%) 5.2129\n","63m 38s (- 20m 5s) (57000 76%) 5.2464\n","64m 47s (- 18m 59s) (58000 77%) 5.2287\n","65m 56s (- 17m 52s) (59000 78%) 5.2222\n","67m 4s (- 16m 46s) (60000 80%) 5.2511\n","68m 12s (- 15m 39s) (61000 81%) 5.2018\n","69m 20s (- 14m 32s) (62000 82%) 5.2243\n","70m 29s (- 13m 25s) (63000 84%) 5.2026\n","71m 37s (- 12m 18s) (64000 85%) 5.2141\n","72m 47s (- 11m 11s) (65000 86%) 5.1647\n","73m 55s (- 10m 4s) (66000 88%) 5.2180\n","75m 3s (- 8m 57s) (67000 89%) 5.2408\n","76m 11s (- 7m 50s) (68000 90%) 5.1606\n","77m 19s (- 6m 43s) (69000 92%) 5.1958\n","78m 28s (- 5m 36s) (70000 93%) 5.2419\n","79m 38s (- 4m 29s) (71000 94%) 5.1970\n","80m 47s (- 3m 21s) (72000 96%) 5.1104\n","81m 54s (- 2m 14s) (73000 97%) 5.1670\n","82m 59s (- 1m 7s) (74000 98%) 5.1074\n","84m 7s (- 0m 0s) (75000 100%) 5.0988\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are  [0.19828189445173922, 0.06350583685889553, 0.021439046462967126]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_1_JxzKvxF5N"},"source":["###Fold 3"]},{"cell_type":"code","metadata":{"id":"WeLVXQOhxCMM","executionInfo":{"status":"ok","timestamp":1615791696626,"user_tz":-480,"elapsed":1318,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 250\r\n","# additive https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN3(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN3, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\r\n","        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\r\n","        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\r\n","        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\r\n","        \r\n","        ######################/\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        #print((embedded[0]*hidden[0]).shape)\r\n","\r\n","        #additive\r\n","        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\r\n","        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\r\n","        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \r\n","\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","            alignment_scores.view(1,-1), dim=1) #dot product\r\n","            #################################\r\n","        #print(attn_weights.shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        #print(attn_applied.shape)\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang2, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang2, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs2))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"9bSwRykXxK_K","executionInfo":{"status":"ok","timestamp":1615791697088,"user_tz":-480,"elapsed":1366,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang3, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang3.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang3, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang3.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang3.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs3)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs3:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs3:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"aDUlbFWuxLFl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615797604226,"user_tz":-480,"elapsed":5908054,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"18b6ce9b-b38d-4ae1-8084-0463db3970ae"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang3.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang3.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["1m 7s (- 82m 50s) (1000 1%) 6.0418\n","2m 6s (- 77m 9s) (2000 2%) 5.6940\n","3m 7s (- 75m 11s) (3000 4%) 5.4610\n","4m 9s (- 73m 50s) (4000 5%) 5.5075\n","5m 12s (- 72m 54s) (5000 6%) 5.4781\n","6m 14s (- 71m 50s) (6000 8%) 5.4042\n","7m 17s (- 70m 49s) (7000 9%) 5.4121\n","8m 20s (- 69m 53s) (8000 10%) 5.4246\n","9m 24s (- 68m 57s) (9000 12%) 5.5348\n","10m 29s (- 68m 12s) (10000 13%) 5.5128\n","11m 34s (- 67m 21s) (11000 14%) 5.5826\n","12m 41s (- 66m 39s) (12000 16%) 5.7057\n","13m 47s (- 65m 48s) (13000 17%) 5.7344\n","14m 56s (- 65m 4s) (14000 18%) 5.7456\n","16m 4s (- 64m 18s) (15000 20%) 5.6854\n","17m 12s (- 63m 26s) (16000 21%) 5.6593\n","18m 21s (- 62m 37s) (17000 22%) 5.6733\n","19m 29s (- 61m 42s) (18000 24%) 5.5957\n","20m 38s (- 60m 49s) (19000 25%) 5.7049\n","21m 46s (- 59m 51s) (20000 26%) 5.6549\n","22m 53s (- 58m 52s) (21000 28%) 5.5534\n","24m 3s (- 57m 56s) (22000 29%) 5.6106\n","25m 11s (- 56m 56s) (23000 30%) 5.5915\n","26m 19s (- 55m 57s) (24000 32%) 5.5994\n","27m 30s (- 55m 0s) (25000 33%) 5.6146\n","28m 36s (- 53m 55s) (26000 34%) 5.5497\n","29m 46s (- 52m 55s) (27000 36%) 5.5389\n","30m 52s (- 51m 49s) (28000 37%) 5.5158\n","32m 0s (- 50m 46s) (29000 38%) 5.5076\n","33m 9s (- 49m 44s) (30000 40%) 5.4238\n","34m 18s (- 48m 42s) (31000 41%) 5.4634\n","35m 27s (- 47m 39s) (32000 42%) 5.4118\n","36m 37s (- 46m 36s) (33000 44%) 5.4565\n","37m 45s (- 45m 31s) (34000 45%) 5.4519\n","38m 51s (- 44m 24s) (35000 46%) 5.4646\n","40m 1s (- 43m 22s) (36000 48%) 5.4393\n","41m 9s (- 42m 16s) (37000 49%) 5.3392\n","42m 17s (- 41m 10s) (38000 50%) 5.4474\n","43m 25s (- 40m 5s) (39000 52%) 5.3721\n","44m 34s (- 38m 59s) (40000 53%) 5.3876\n","45m 42s (- 37m 54s) (41000 54%) 5.3905\n","46m 51s (- 36m 49s) (42000 56%) 5.3362\n","48m 0s (- 35m 43s) (43000 57%) 5.3300\n","49m 9s (- 34m 38s) (44000 58%) 5.3938\n","50m 18s (- 33m 32s) (45000 60%) 5.3263\n","51m 26s (- 32m 25s) (46000 61%) 5.3349\n","52m 36s (- 31m 20s) (47000 62%) 5.3060\n","53m 45s (- 30m 14s) (48000 64%) 5.3237\n","54m 53s (- 29m 7s) (49000 65%) 5.2498\n","56m 3s (- 28m 1s) (50000 66%) 5.2955\n","57m 11s (- 26m 54s) (51000 68%) 5.2844\n","58m 19s (- 25m 48s) (52000 69%) 5.2743\n","59m 27s (- 24m 40s) (53000 70%) 5.2906\n","60m 34s (- 23m 33s) (54000 72%) 5.1467\n","61m 41s (- 22m 25s) (55000 73%) 5.1868\n","62m 50s (- 21m 19s) (56000 74%) 5.2542\n","63m 59s (- 20m 12s) (57000 76%) 5.2397\n","65m 8s (- 19m 5s) (58000 77%) 5.2348\n","66m 16s (- 17m 58s) (59000 78%) 5.2326\n","67m 24s (- 16m 51s) (60000 80%) 5.1944\n","68m 33s (- 15m 44s) (61000 81%) 5.1934\n","69m 42s (- 14m 37s) (62000 82%) 5.2137\n","70m 51s (- 13m 29s) (63000 84%) 5.1705\n","72m 1s (- 12m 22s) (64000 85%) 5.2268\n","73m 9s (- 11m 15s) (65000 86%) 5.2193\n","74m 19s (- 10m 8s) (66000 88%) 5.2763\n","75m 28s (- 9m 0s) (67000 89%) 5.1895\n","76m 38s (- 7m 53s) (68000 90%) 5.1992\n","77m 47s (- 6m 45s) (69000 92%) 5.2239\n","78m 58s (- 5m 38s) (70000 93%) 5.2343\n","80m 6s (- 4m 30s) (71000 94%) 5.2298\n","81m 14s (- 3m 23s) (72000 96%) 5.1543\n","82m 23s (- 2m 15s) (73000 97%) 5.1648\n","83m 34s (- 1m 7s) (74000 98%) 5.1979\n","84m 43s (- 0m 0s) (75000 100%) 5.1599\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are  [0.1994384988884716, 0.06956790744662926, 0.024764369049969478]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"34QQDEirydMQ"},"source":["###Fold 4"]},{"cell_type":"code","metadata":{"id":"zCnOu5OXyPVu","executionInfo":{"status":"ok","timestamp":1615797606822,"user_tz":-480,"elapsed":2577,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 245\r\n","# additive https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN3(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN3, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\r\n","        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\r\n","        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\r\n","        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\r\n","        \r\n","        ######################/\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        #print((embedded[0]*hidden[0]).shape)\r\n","\r\n","        #additive\r\n","        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\r\n","        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\r\n","        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \r\n","\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","            alignment_scores.view(1,-1), dim=1) #dot product\r\n","            #################################\r\n","        #print(attn_weights.shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        #print(attn_applied.shape)\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang4, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang4, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs4))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"avak6eD9yXww","executionInfo":{"status":"ok","timestamp":1615797606823,"user_tz":-480,"elapsed":2569,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang4, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang4.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang4, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang4.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang4.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs4)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs4:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs4:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVOKFdzNyYXX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615803497089,"user_tz":-480,"elapsed":5892832,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"36250a75-c895-44bc-f637-e1f46fe6db30"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang4.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang4.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["1m 7s (- 82m 45s) (1000 1%) 6.1393\n","2m 10s (- 79m 22s) (2000 2%) 5.7469\n","3m 11s (- 76m 41s) (3000 4%) 5.5859\n","4m 13s (- 74m 58s) (4000 5%) 5.5465\n","5m 15s (- 73m 35s) (5000 6%) 5.4684\n","6m 18s (- 72m 32s) (6000 8%) 5.5268\n","7m 21s (- 71m 32s) (7000 9%) 5.4338\n","8m 25s (- 70m 36s) (8000 10%) 5.4200\n","9m 31s (- 69m 51s) (9000 12%) 5.5425\n","10m 37s (- 69m 6s) (10000 13%) 5.5499\n","11m 42s (- 68m 4s) (11000 14%) 5.6016\n","12m 47s (- 67m 8s) (12000 16%) 5.5551\n","13m 51s (- 66m 6s) (13000 17%) 5.5703\n","14m 57s (- 65m 11s) (14000 18%) 5.6237\n","16m 4s (- 64m 19s) (15000 20%) 5.5930\n","17m 11s (- 63m 23s) (16000 21%) 5.5931\n","18m 17s (- 62m 23s) (17000 22%) 5.6432\n","19m 24s (- 61m 28s) (18000 24%) 5.6535\n","20m 32s (- 60m 31s) (19000 25%) 5.5970\n","21m 39s (- 59m 33s) (20000 26%) 5.5842\n","22m 47s (- 58m 37s) (21000 28%) 5.6004\n","23m 53s (- 57m 34s) (22000 29%) 5.4872\n","25m 0s (- 56m 33s) (23000 30%) 5.5750\n","26m 6s (- 55m 29s) (24000 32%) 5.5237\n","27m 13s (- 54m 27s) (25000 33%) 5.5067\n","28m 21s (- 53m 25s) (26000 34%) 5.4699\n","29m 28s (- 52m 23s) (27000 36%) 5.5223\n","30m 37s (- 51m 24s) (28000 37%) 5.5879\n","31m 44s (- 50m 21s) (29000 38%) 5.5637\n","32m 52s (- 49m 18s) (30000 40%) 5.4848\n","34m 0s (- 48m 15s) (31000 41%) 5.4347\n","35m 10s (- 47m 15s) (32000 42%) 5.4924\n","36m 16s (- 46m 10s) (33000 44%) 5.4542\n","37m 25s (- 45m 7s) (34000 45%) 5.4593\n","38m 31s (- 44m 2s) (35000 46%) 5.3653\n","39m 41s (- 43m 0s) (36000 48%) 5.3921\n","40m 49s (- 41m 56s) (37000 49%) 5.3457\n","41m 58s (- 40m 51s) (38000 50%) 5.4284\n","43m 5s (- 39m 46s) (39000 52%) 5.4178\n","44m 12s (- 38m 40s) (40000 53%) 5.3534\n","45m 21s (- 37m 36s) (41000 54%) 5.3537\n","46m 30s (- 36m 32s) (42000 56%) 5.3925\n","47m 39s (- 35m 28s) (43000 57%) 5.3761\n","48m 47s (- 34m 22s) (44000 58%) 5.3284\n","49m 56s (- 33m 17s) (45000 60%) 5.3046\n","51m 6s (- 32m 13s) (46000 61%) 5.3186\n","52m 13s (- 31m 6s) (47000 62%) 5.2800\n","53m 22s (- 30m 1s) (48000 64%) 5.3489\n","54m 30s (- 28m 55s) (49000 65%) 5.3504\n","55m 39s (- 27m 49s) (50000 66%) 5.2542\n","56m 47s (- 26m 43s) (51000 68%) 5.2605\n","57m 55s (- 25m 37s) (52000 69%) 5.3259\n","59m 4s (- 24m 31s) (53000 70%) 5.2739\n","60m 13s (- 23m 25s) (54000 72%) 5.2332\n","61m 21s (- 22m 18s) (55000 73%) 5.2866\n","62m 29s (- 21m 12s) (56000 74%) 5.2038\n","63m 37s (- 20m 5s) (57000 76%) 5.1914\n","64m 47s (- 18m 59s) (58000 77%) 5.2405\n","65m 56s (- 17m 52s) (59000 78%) 5.2083\n","67m 5s (- 16m 46s) (60000 80%) 5.2733\n","68m 13s (- 15m 39s) (61000 81%) 5.2431\n","69m 21s (- 14m 32s) (62000 82%) 5.1826\n","70m 28s (- 13m 25s) (63000 84%) 5.2017\n","71m 36s (- 12m 18s) (64000 85%) 5.1798\n","72m 45s (- 11m 11s) (65000 86%) 5.1138\n","73m 53s (- 10m 4s) (66000 88%) 5.1380\n","75m 1s (- 8m 57s) (67000 89%) 5.2054\n","76m 11s (- 7m 50s) (68000 90%) 5.1493\n","77m 18s (- 6m 43s) (69000 92%) 5.1420\n","78m 25s (- 5m 36s) (70000 93%) 5.1217\n","79m 34s (- 4m 28s) (71000 94%) 5.1975\n","80m 42s (- 3m 21s) (72000 96%) 5.2079\n","81m 52s (- 2m 14s) (73000 97%) 5.1702\n","83m 0s (- 1m 7s) (74000 98%) 5.1502\n","84m 8s (- 0m 0s) (75000 100%) 5.1481\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are  [0.19882952874350465, 0.06674659895691, 0.023567278402568607]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DtGbDe1GzSK9"},"source":["###Fold 5"]},{"cell_type":"code","metadata":{"id":"rM5o8g5vzQE7","executionInfo":{"status":"ok","timestamp":1615806979417,"user_tz":-480,"elapsed":1295,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 250\r\n","# additive https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN3(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN3, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\r\n","        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\r\n","        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\r\n","        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\r\n","        \r\n","        ######################/\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        #print((embedded[0]*hidden[0]).shape)\r\n","\r\n","        #additive\r\n","        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\r\n","        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\r\n","        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \r\n","\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","            alignment_scores.view(1,-1), dim=1) #dot product\r\n","            #################################\r\n","        #print(attn_weights.shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        #print(attn_applied.shape)\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang5, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang5, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs5))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"JP78TY53zYHd","executionInfo":{"status":"ok","timestamp":1615806979842,"user_tz":-480,"elapsed":1321,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang5, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang5.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang5, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang5.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang5.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs5)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs5:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs5:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"6u-YKVdSzaVV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615812916209,"user_tz":-480,"elapsed":5937294,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"49fcc0c8-6fa8-47e9-d123-8507ab9d3f44"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang5.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang5.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["1m 8s (- 84m 58s) (1000 1%) 6.1356\n","2m 8s (- 77m 54s) (2000 2%) 5.6153\n","3m 9s (- 75m 52s) (3000 4%) 5.5034\n","4m 12s (- 74m 49s) (4000 5%) 5.6018\n","5m 15s (- 73m 41s) (5000 6%) 5.4943\n","6m 17s (- 72m 20s) (6000 8%) 5.4132\n","7m 20s (- 71m 21s) (7000 9%) 5.4318\n","8m 24s (- 70m 24s) (8000 10%) 5.3664\n","9m 28s (- 69m 29s) (9000 12%) 5.4825\n","10m 32s (- 68m 33s) (10000 13%) 5.5454\n","11m 38s (- 67m 42s) (11000 14%) 5.5579\n","12m 45s (- 66m 58s) (12000 16%) 5.6829\n","13m 51s (- 66m 5s) (13000 17%) 5.6837\n","14m 59s (- 65m 18s) (14000 18%) 5.6726\n","16m 7s (- 64m 28s) (15000 20%) 5.5737\n","17m 14s (- 63m 36s) (16000 21%) 5.6573\n","18m 21s (- 62m 36s) (17000 22%) 5.6135\n","19m 26s (- 61m 32s) (18000 24%) 5.5645\n","20m 31s (- 60m 29s) (19000 25%) 5.5632\n","21m 39s (- 59m 33s) (20000 26%) 5.5746\n","22m 48s (- 58m 37s) (21000 28%) 5.6214\n","23m 55s (- 57m 37s) (22000 29%) 5.5937\n","25m 2s (- 56m 37s) (23000 30%) 5.4637\n","26m 12s (- 55m 41s) (24000 32%) 5.6242\n","27m 19s (- 54m 39s) (25000 33%) 5.5134\n","28m 28s (- 53m 39s) (26000 34%) 5.5528\n","29m 35s (- 52m 36s) (27000 36%) 5.5188\n","30m 44s (- 51m 36s) (28000 37%) 5.5174\n","31m 53s (- 50m 34s) (29000 38%) 5.4589\n","33m 2s (- 49m 33s) (30000 40%) 5.5320\n","34m 12s (- 48m 32s) (31000 41%) 5.5350\n","35m 21s (- 47m 31s) (32000 42%) 5.5075\n","36m 30s (- 46m 28s) (33000 44%) 5.3902\n","37m 36s (- 45m 21s) (34000 45%) 5.3912\n","38m 44s (- 44m 16s) (35000 46%) 5.4247\n","39m 55s (- 43m 14s) (36000 48%) 5.4884\n","41m 3s (- 42m 10s) (37000 49%) 5.3534\n","42m 11s (- 41m 4s) (38000 50%) 5.3886\n","43m 19s (- 39m 59s) (39000 52%) 5.4095\n","44m 27s (- 38m 54s) (40000 53%) 5.3793\n","45m 35s (- 37m 48s) (41000 54%) 5.3936\n","46m 43s (- 36m 42s) (42000 56%) 5.3956\n","47m 51s (- 35m 36s) (43000 57%) 5.3404\n","48m 59s (- 34m 31s) (44000 58%) 5.4059\n","50m 8s (- 33m 25s) (45000 60%) 5.3042\n","51m 16s (- 32m 19s) (46000 61%) 5.3377\n","52m 25s (- 31m 13s) (47000 62%) 5.3244\n","53m 35s (- 30m 8s) (48000 64%) 5.3472\n","54m 43s (- 29m 2s) (49000 65%) 5.2852\n","55m 50s (- 27m 55s) (50000 66%) 5.2931\n","56m 57s (- 26m 48s) (51000 68%) 5.2795\n","58m 5s (- 25m 41s) (52000 69%) 5.2173\n","59m 16s (- 24m 36s) (53000 70%) 5.2648\n","60m 24s (- 23m 29s) (54000 72%) 5.2405\n","61m 33s (- 22m 23s) (55000 73%) 5.2489\n","62m 42s (- 21m 16s) (56000 74%) 5.2793\n","63m 51s (- 20m 9s) (57000 76%) 5.2649\n","64m 59s (- 19m 2s) (58000 77%) 5.2646\n","66m 7s (- 17m 55s) (59000 78%) 5.1942\n","67m 16s (- 16m 49s) (60000 80%) 5.2172\n","68m 25s (- 15m 42s) (61000 81%) 5.2176\n","69m 33s (- 14m 35s) (62000 82%) 5.1959\n","70m 42s (- 13m 28s) (63000 84%) 5.2162\n","71m 51s (- 12m 21s) (64000 85%) 5.2552\n","73m 0s (- 11m 13s) (65000 86%) 5.1948\n","74m 8s (- 10m 6s) (66000 88%) 5.1522\n","75m 15s (- 8m 59s) (67000 89%) 5.1497\n","76m 26s (- 7m 52s) (68000 90%) 5.2221\n","77m 35s (- 6m 44s) (69000 92%) 5.1573\n","78m 43s (- 5m 37s) (70000 93%) 5.2287\n","79m 52s (- 4m 30s) (71000 94%) 5.1911\n","81m 0s (- 3m 22s) (72000 96%) 5.1773\n","82m 8s (- 2m 15s) (73000 97%) 5.1750\n","83m 16s (- 1m 7s) (74000 98%) 5.1621\n","84m 24s (- 0m 0s) (75000 100%) 5.1117\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are  [0.21682300054908138, 0.07312996123794763, 0.02581821412660003]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P8qMVNHB402u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615812916210,"user_tz":-480,"elapsed":5933863,"user":{"displayName":"chao wang","photoUrl":"","userId":"16929231235898515362"}},"outputId":"4eb34267-8b44-4f76-d0bf-b2ee3e9de4af"},"source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["> l un des meilleurs aspects et l un des plus vivaces de la revolution orange est qu elle a donne les pleins pouvoirs democratiques aux citoyens .\n","= the best and still most living thing about our orange revolution was the democratic empowerment of our people .\n","< one of the the the and the the the and the the the the the the the . <EOS>\n","\n","> l incapacite de l europe a jouer un role dans le processus de paix ne provient pas de ses supposes prejuges contre les israeliens mais du fait que l ue n est pas un etat . les roles que joue un etat ne lui sont pas attribues .\n","= europe s failure to play a role in resolving this conflict does not result from its supposed anti israeli views but from the fact that the eu is not a state .\n","< europe s role in the middle east it is not a europe but of the the the a europe of the the the the role of in . <EOS>\n","\n","> beaucoup se rappellent la strategie envisagee par l ancien premier ministre israelien yitzhak shamir j aurais entame des negociations sur l autonomie pendant dix ans ce qui nous aurait permis d installer un demi million de personnes en cisjordanie . \n","= many recall the preferred strategy of former israeli prime minister yitzhak shamir i would have conducted negotiations on autonomy for ten years and in the meantime we would have reached a half million people in the west bank . \n","< as a result of a prime minister of the the of the the in the of the the the to the of the <EOS>\n","\n","> serait il possible que les etats unis beneficient d un nouveau depart en europe sous l egide de john kerry ?\n","= but can a kerry led us get a fresh start in europe ?\n","< what might be the the the the the the the the the the a the of the the the the <EOS>\n","\n","> en fin de compte la prochaine decennie sera marquee par le delicat equilibre de la dependance europeenne vis a vis du gaz russe et le besoin russe de revenus tires de l exportation qui placent la russie en position de dependance vis a vis de l europe .\n","= in the end the next decade will be marked by a delicate balance in which europe remains dependent on russian gas but russia s need for export revenues will also make it dependent on europe .\n","< in the end of the eu s the s the the the and and the and and and and and the and and the and the and the and the <EOS>\n","\n","> gates et lui meme ont tout deux evoque le fait de tirer des lecons de l incident .\n","= both he and gates then spoke of learning from the incident .\n","< and both and the two of the the the in the the <EOS>\n","\n","> mais l histoire recente n a pas ete tendre envers les vainqueurs .\n","= but recent history has not been kind to the victors .\n","< but history is not the history of the history . <EOS>\n","\n","> les premieres annees d occupation du japon ont sans aucun doute ete une grande reussite pour la democratie .\n","= the first few years of the occupation of japan were indeed a remarkable success for democracy .\n","< japan s in the the japan have the the the the the the in . the <EOS>\n","\n","> le placement en institution est souvent bien intentionne et decide au nom de la therapie des soins et de la protection .\n","= institutionalization is often based on good intentions and carried out in the name of therapy care and protection .\n","< the is of and and and and and and and and and . <EOS>\n","\n","> elle poursuivait une double strategie d une part elle pretendait qu il n y avait pas de probleme au cachemire un mensonge flagrant d autre part elle encourageait la confrontation ethnique au pakistan .\n","= it was pursuing a two pronged strategy making the argument that all was well in kashmir a blatant lie and supporting ethnic confrontation in pakistan .\n","< it is not a that the the the the the the the the the the the the to the the the <EOS>\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YK2wKfXx41dq"},"source":[""],"execution_count":null,"outputs":[]}]}