{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33941,
     "status": "ok",
     "timestamp": 1615719829911,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "uT-lrh1Xe3ry",
    "outputId": "b369fe60-a837-41b8-aa31-6406ee940d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive/AI Sem II/NLP/A2\n",
      "/content/gdrive/My Drive/AI Sem II/NLP/A2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys,os\n",
    "if 'google.colab' in sys.modules:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  path_to_file = '/content/gdrive/My Drive/AI Sem II/NLP/A2'\n",
    "  print(path_to_file)\n",
    "  os.chdir(path_to_file)\n",
    "  !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 36161,
     "status": "ok",
     "timestamp": 1615719832133,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "sUm8xUsPjECA"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37803,
     "status": "ok",
     "timestamp": 1615719833782,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "hjR9yaPeIEDs",
    "outputId": "1ce18a8d-a9d9-4be5-b9b5-3e538b6e7267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183251, 183251)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fr = 'data/training/news-commentary-v9.fr-en.fr'\n",
    "data_en = 'data/training/news-commentary-v9.fr-en.en'\n",
    "\n",
    "with open(data_fr, 'rb') as fr: \n",
    "  sents_fr = [line.decode(\"utf-8\") for line in fr]      \n",
    " # sents_cs = [value for value in sents_cs if value != '']   \n",
    "with open(data_en, 'rb') as en: \n",
    "  sents_en = [line.decode(\"utf-8\") for line in en]\n",
    " # sents_en = [value for value in sents_en if value != '']\n",
    "len(sents_en), len(sents_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38085,
     "status": "ok",
     "timestamp": 1615719834069,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "08DjJdxvxuAW",
    "outputId": "d29efeac-5dad-4379-a867-8479c8ed2b53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max length of string \n",
    "length_fr = [len(i.split()) for i in sents_fr]\n",
    "max(length_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38412,
     "status": "ok",
     "timestamp": 1615719834401,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "KrrJEeffxuEB",
    "outputId": "44b1ffcc-8ca7-4690-d58e-71b8808a1ab2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_en = [len(i.split()) for i in sents_en]\n",
    "max(length_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 38410,
     "status": "ok",
     "timestamp": 1615719834401,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "lXnu1aePaT6s"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "  def __init__(self, name):\n",
    "    self.name = name\n",
    "    self.word2index = {}\n",
    "    self.word2count = {}\n",
    "    self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "    self.n_words = 2\n",
    "\n",
    "  def addSentence(self, sentence):\n",
    "    \n",
    "    for word in sentence.split(' '):\n",
    "      self.addWord(word)\n",
    "  \n",
    "  def addWord(self, word):\n",
    "    if word not in self.word2index:\n",
    "      self.word2index[word] = self.n_words\n",
    "      self.word2count[word] = 1\n",
    "      self.index2word[self.n_words] = word \n",
    "      self.n_words += 1\n",
    "    else:\n",
    "      self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 38410,
     "status": "ok",
     "timestamp": 1615719834402,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "LaTNz04wdqKa"
   },
   "outputs": [],
   "source": [
    "def sent_pairs(lang1=sents_fr, lang2=sents_en):\n",
    "  pairs = []\n",
    "  for i, (cs_sent, en_sent) in enumerate(zip(lang1, lang2)):\n",
    "    #if i < 100:\n",
    "      pairs.append([cs_sent, en_sent])\n",
    "   # print(i)\n",
    "  pairs = [[normalizeString(s) for s in line] for line in pairs]\n",
    "  input_lang1 = Lang('fr')\n",
    "  output_lang1 = Lang('en')\n",
    "\n",
    "  input_lang2 = Lang('fr')\n",
    "  output_lang2 = Lang('en')\n",
    "\n",
    "  input_lang3 = Lang('fr')\n",
    "  output_lang3 = Lang('en')\n",
    "\n",
    "  input_lang4 = Lang('fr')\n",
    "  output_lang4 = Lang('en')\n",
    "\n",
    "  input_lang5 = Lang('fr')\n",
    "  output_lang5 = Lang('en')\n",
    "\n",
    "     \n",
    "  return input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvQxz_O6IMm8"
   },
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "-  Read text file and split into lines, split lines into pairs\n",
    "-  Normalize text, filter by length and content\n",
    "-  Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70461,
     "status": "ok",
     "timestamp": 1615719866459,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "-ll3A_tPrdF8",
    "outputId": "109562ca-4dbb-4479-df72-7f7eeb57b139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 183251 sentence pairs\n",
      "Number of test pairs: 36650\n",
      "Number of train pairs: 146601\n",
      "Counting words...\n",
      "Counted words:\n",
      "fr 57432\n",
      "en 42977\n",
      "Number of train pairs: 146601\n",
      "Counting words...\n",
      "Counted words:\n",
      "fr 57510\n",
      "en 42960\n",
      "Number of train pairs: 146601\n",
      "Counting words...\n",
      "Counted words:\n",
      "fr 57715\n",
      "en 43042\n",
      "Number of train pairs: 146601\n",
      "Counting words...\n",
      "Counted words:\n",
      "fr 57623\n",
      "en 43010\n",
      "Number of train pairs: 146600\n",
      "Counting words...\n",
      "Counted words:\n",
      "fr 57515\n",
      "en 42988\n",
      "['de petits groupes de palestiniens demolissent les vestiges des infrastructures industrielles aneanties par les bombes des blocs de beton qui polluent le paysage sablonneux .', 'small groups of palestinians smash up the remains of gaza s bombed industrial infrastructure the concrete blocks that litter the sandy landscape .']\n",
      "['les hierarques chiites ayant coutume de releguer l avenement du mahdi a un avenir eloigne le penchant millenariste d ahmadinejad les agacent .', 'for the shia religious hierarchy long accustomed to relegating the advent of the mahdi to a distant future ahmadinejad s insistent millenarianism is troublesome .']\n",
      "['le pari de bush est perdu d avance avec des consequences qui seront couteuses d abord pour les usa mais aussi pour le reste du monde .', 'bush s gamble was a loser from the start generating costly results mainly for the us but for the rest of the world too for years to come .']\n",
      "['elu a une majorite ecrasante pour laver de ses vices le systeme politique auquel il a succede chavez a choisi de jeter le bebe avec l eau du bain .', 'elected in a landslide to clean up the political vices of the previous establishment chavez chose to throw the baby out with the bathwater .']\n",
      "['les partisans du nouvel imperialisme nous diraient de ne pas prendre cela au pied de la lettre .', 'devotees of the new imperialism would say don t to be so literal . ']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def prepareData(lang1=sents_fr, lang2=sents_en):\n",
    "    input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs = sent_pairs(lang1, lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    #Assumption: as the dataset is news commentary on different topics, there is highly unlikely exactly the same sentences \n",
    "    # collect test pairs\n",
    "    num_test = int(len(pairs)*0.2)\n",
    "    print(\"Number of test pairs:\", num_test)\n",
    "    random.seed(3)\n",
    "    random.shuffle(pairs)\n",
    "    \n",
    "    #fold 1\n",
    "    test_pairs1 = pairs[:num_test]\n",
    "     # collect train pairs\n",
    "    train_pairs1 = pairs[num_test:]\n",
    "    print(\"Number of train pairs:\", len(train_pairs1))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "    for pair in train_pairs1:      \n",
    "      input_lang1.addSentence(pair[0])\n",
    "      output_lang1.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang1.name, input_lang1.n_words)\n",
    "    print(output_lang1.name, output_lang1.n_words)\n",
    "\n",
    "    #fold 2\n",
    "    test_pairs2 = pairs[num_test:num_test*2]\n",
    "     # collect train pairs\n",
    "    train_pairs2 = pairs[:num_test]\n",
    "    for x in pairs[num_test*2:]:\n",
    "      train_pairs2.append(x)\n",
    "    print(\"Number of train pairs:\", len(train_pairs2))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs2:      \n",
    "      input_lang2.addSentence(pair[0])\n",
    "      output_lang2.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang2.name, input_lang2.n_words)\n",
    "    print(output_lang2.name, output_lang2.n_words)\n",
    "\n",
    "    #fold 3\n",
    "    test_pairs3 = pairs[num_test*2:num_test*3]\n",
    "     # collect train pairs\n",
    "    train_pairs3 = pairs[:num_test*2]\n",
    "    for x in pairs[num_test*3:]:\n",
    "      train_pairs3.append(x)\n",
    "    print(\"Number of train pairs:\", len(train_pairs3))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs3:      \n",
    "      input_lang3.addSentence(pair[0])\n",
    "      output_lang3.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang3.name, input_lang3.n_words)\n",
    "    print(output_lang3.name, output_lang3.n_words)\n",
    "\n",
    "\n",
    "    #fold 4\n",
    "    test_pairs4 = pairs[num_test*3:num_test*4]\n",
    "     # collect train pairs\n",
    "    train_pairs4 = pairs[:num_test*3]\n",
    "    for x in pairs[num_test*4:]:\n",
    "      train_pairs4.append(x)\n",
    "    print(\"Number of train pairs:\", len(train_pairs4))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs4:      \n",
    "      input_lang4.addSentence(pair[0])\n",
    "      output_lang4.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang4.name, input_lang4.n_words)\n",
    "    print(output_lang4.name, output_lang4.n_words)\n",
    "\n",
    "    #fold 5\n",
    "    test_pairs5 = pairs[num_test*4:]\n",
    "     # collect train pairs\n",
    "    train_pairs5 = pairs[:num_test*4]\n",
    "    print(\"Number of train pairs:\", len(train_pairs5))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs5:      \n",
    "      input_lang5.addSentence(pair[0])\n",
    "      output_lang5.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang5.name, input_lang5.n_words)\n",
    "    print(output_lang5.name, output_lang5.n_words)\n",
    "\n",
    "\n",
    "    return (input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4,input_lang5, output_lang5,train_pairs1, \n",
    "            test_pairs1, train_pairs2, test_pairs2, train_pairs3, test_pairs3,train_pairs4, test_pairs4,train_pairs5, test_pairs5)\n",
    "\n",
    "\n",
    "(input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, train_pairs1, test_pairs1, train_pairs2,\n",
    " test_pairs2,train_pairs3, test_pairs3, train_pairs4, test_pairs4,train_pairs5, test_pairs5) = prepareData(sents_fr, sents_en)\n",
    "print(random.choice(train_pairs1))\n",
    "print(random.choice(train_pairs2))\n",
    "print(random.choice(train_pairs3))\n",
    "print(random.choice(train_pairs4))\n",
    "print(random.choice(train_pairs5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 70751,
     "status": "ok",
     "timestamp": 1615719866750,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "npNTNDUOOwoC"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 235\n",
    "# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN4(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN4, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\n",
    "        ##################\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        x=self.fc(hidden)\n",
    "        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\n",
    "            #################################\n",
    "       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang1, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang1, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs1))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 72167,
     "status": "ok",
     "timestamp": 1615719868168,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "pjoCFY3nTmBG"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang1, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang1.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang1, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang1.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang1.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs1)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs1:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs1:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5649274,
     "status": "ok",
     "timestamp": 1615725445277,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "08M4DvfPToJk",
    "outputId": "cbf72b34-96bf-40fe-e3b4-1b5d4f9f4c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 3s (- 78m 1s) (1000 1%) 6.1003\n",
      "2m 0s (- 73m 35s) (2000 2%) 5.7335\n",
      "3m 0s (- 72m 7s) (3000 4%) 5.6152\n",
      "3m 58s (- 70m 42s) (4000 5%) 5.6211\n",
      "5m 0s (- 70m 11s) (5000 6%) 5.5981\n",
      "5m 58s (- 68m 37s) (6000 8%) 5.3672\n",
      "6m 56s (- 67m 23s) (7000 9%) 5.4511\n",
      "7m 57s (- 66m 37s) (8000 10%) 5.4655\n",
      "8m 56s (- 65m 36s) (9000 12%) 5.4167\n",
      "9m 57s (- 64m 41s) (10000 13%) 5.3526\n",
      "10m 56s (- 63m 41s) (11000 14%) 5.4261\n",
      "11m 57s (- 62m 46s) (12000 16%) 5.4372\n",
      "12m 58s (- 61m 54s) (13000 17%) 5.3913\n",
      "14m 1s (- 61m 5s) (14000 18%) 5.5450\n",
      "15m 3s (- 60m 13s) (15000 20%) 5.5362\n",
      "16m 6s (- 59m 24s) (16000 21%) 5.7007\n",
      "17m 8s (- 58m 28s) (17000 22%) 5.5740\n",
      "18m 13s (- 57m 42s) (18000 24%) 5.6719\n",
      "19m 15s (- 56m 44s) (19000 25%) 5.5782\n",
      "20m 21s (- 55m 58s) (20000 26%) 5.6486\n",
      "21m 25s (- 55m 4s) (21000 28%) 5.4895\n",
      "22m 27s (- 54m 6s) (22000 29%) 5.6012\n",
      "23m 32s (- 53m 13s) (23000 30%) 5.5649\n",
      "24m 37s (- 52m 19s) (24000 32%) 5.5409\n",
      "25m 41s (- 51m 22s) (25000 33%) 5.5699\n",
      "26m 46s (- 50m 26s) (26000 34%) 5.5490\n",
      "27m 53s (- 49m 35s) (27000 36%) 5.6083\n",
      "28m 57s (- 48m 36s) (28000 37%) 5.5489\n",
      "30m 0s (- 47m 36s) (29000 38%) 5.5351\n",
      "31m 5s (- 46m 38s) (30000 40%) 5.4913\n",
      "32m 8s (- 45m 37s) (31000 41%) 5.4646\n",
      "33m 14s (- 44m 39s) (32000 42%) 5.4430\n",
      "34m 18s (- 43m 40s) (33000 44%) 5.4602\n",
      "35m 23s (- 42m 41s) (34000 45%) 5.5049\n",
      "36m 29s (- 41m 42s) (35000 46%) 5.4327\n",
      "37m 35s (- 40m 43s) (36000 48%) 5.4575\n",
      "38m 40s (- 39m 43s) (37000 49%) 5.4334\n",
      "39m 43s (- 38m 40s) (38000 50%) 5.4388\n",
      "40m 47s (- 37m 39s) (39000 52%) 5.4326\n",
      "41m 51s (- 36m 37s) (40000 53%) 5.3201\n",
      "42m 55s (- 35m 36s) (41000 54%) 5.3620\n",
      "44m 0s (- 34m 34s) (42000 56%) 5.3041\n",
      "45m 4s (- 33m 32s) (43000 57%) 5.3262\n",
      "46m 7s (- 32m 30s) (44000 58%) 5.3979\n",
      "47m 12s (- 31m 28s) (45000 60%) 5.3241\n",
      "48m 17s (- 30m 26s) (46000 61%) 5.3706\n",
      "49m 22s (- 29m 24s) (47000 62%) 5.3225\n",
      "50m 27s (- 28m 22s) (48000 64%) 5.3441\n",
      "51m 31s (- 27m 20s) (49000 65%) 5.2891\n",
      "52m 34s (- 26m 17s) (50000 66%) 5.2925\n",
      "53m 39s (- 25m 15s) (51000 68%) 5.3830\n",
      "54m 42s (- 24m 11s) (52000 69%) 5.2500\n",
      "55m 47s (- 23m 9s) (53000 70%) 5.3279\n",
      "56m 52s (- 22m 7s) (54000 72%) 5.2744\n",
      "57m 56s (- 21m 4s) (55000 73%) 5.2645\n",
      "59m 1s (- 20m 1s) (56000 74%) 5.3057\n",
      "60m 4s (- 18m 58s) (57000 76%) 5.2456\n",
      "61m 10s (- 17m 55s) (58000 77%) 5.2729\n",
      "62m 15s (- 16m 52s) (59000 78%) 5.2378\n",
      "63m 20s (- 15m 50s) (60000 80%) 5.1978\n",
      "64m 25s (- 14m 47s) (61000 81%) 5.2627\n",
      "65m 29s (- 13m 43s) (62000 82%) 5.2119\n",
      "66m 33s (- 12m 40s) (63000 84%) 5.2483\n",
      "67m 37s (- 11m 37s) (64000 85%) 5.1705\n",
      "68m 41s (- 10m 34s) (65000 86%) 5.2567\n",
      "69m 46s (- 9m 30s) (66000 88%) 5.3335\n",
      "70m 52s (- 8m 27s) (67000 89%) 5.2074\n",
      "71m 58s (- 7m 24s) (68000 90%) 5.2581\n",
      "73m 3s (- 6m 21s) (69000 92%) 5.2559\n",
      "74m 7s (- 5m 17s) (70000 93%) 5.1074\n",
      "75m 12s (- 4m 14s) (71000 94%) 5.0824\n",
      "76m 16s (- 3m 10s) (72000 96%) 5.2069\n",
      "77m 20s (- 2m 7s) (73000 97%) 5.1537\n",
      "78m 26s (- 1m 3s) (74000 98%) 5.2265\n",
      "79m 30s (- 0m 0s) (75000 100%) 5.1736\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are  [0.21385798193220693, 0.07250217227352795, 0.025202980376621425]\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang1.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8X7TtXWDvQCS"
   },
   "source": [
    "###Fold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5649561,
     "status": "ok",
     "timestamp": 1615725445566,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "zTgC4HZSt6XD"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 235\n",
    "# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN4(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN4, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\n",
    "        ##################\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        x=self.fc(hidden)\n",
    "        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\n",
    "            #################################\n",
    "       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang2, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang2, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs2))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 5649868,
     "status": "ok",
     "timestamp": 1615725445874,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "Xj4EasFzvVmP"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang2, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang2.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang2, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang2.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang2.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs2)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs2:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs2:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11274365,
     "status": "ok",
     "timestamp": 1615731070372,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "ab6RRAYUvcdZ",
    "outputId": "cfefc17a-9a21-4501-c16c-e08630a66431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 2s (- 77m 41s) (1000 1%) 6.1116\n",
      "2m 3s (- 75m 6s) (2000 2%) 5.7738\n",
      "3m 2s (- 72m 52s) (3000 4%) 5.5165\n",
      "4m 0s (- 71m 16s) (4000 5%) 5.5829\n",
      "5m 0s (- 70m 10s) (5000 6%) 5.6764\n",
      "5m 58s (- 68m 48s) (6000 8%) 5.4336\n",
      "6m 59s (- 67m 52s) (7000 9%) 5.4825\n",
      "8m 0s (- 67m 3s) (8000 10%) 5.5177\n",
      "9m 1s (- 66m 13s) (9000 12%) 5.6157\n",
      "10m 2s (- 65m 16s) (10000 13%) 5.4786\n",
      "11m 1s (- 64m 8s) (11000 14%) 5.3637\n",
      "12m 2s (- 63m 14s) (12000 16%) 5.4183\n",
      "13m 1s (- 62m 6s) (13000 17%) 5.3865\n",
      "14m 2s (- 61m 12s) (14000 18%) 5.5318\n",
      "15m 5s (- 60m 23s) (15000 20%) 5.6171\n",
      "16m 9s (- 59m 35s) (16000 21%) 5.6892\n",
      "17m 12s (- 58m 43s) (17000 22%) 5.6252\n",
      "18m 14s (- 57m 46s) (18000 24%) 5.5546\n",
      "19m 20s (- 57m 1s) (19000 25%) 5.6417\n",
      "20m 24s (- 56m 6s) (20000 26%) 5.6185\n",
      "21m 27s (- 55m 11s) (21000 28%) 5.5627\n",
      "22m 32s (- 54m 17s) (22000 29%) 5.5831\n",
      "23m 37s (- 53m 23s) (23000 30%) 5.6024\n",
      "24m 41s (- 52m 28s) (24000 32%) 5.5204\n",
      "25m 44s (- 51m 28s) (25000 33%) 5.5363\n",
      "26m 49s (- 50m 32s) (26000 34%) 5.5490\n",
      "27m 52s (- 49m 34s) (27000 36%) 5.6003\n",
      "28m 56s (- 48m 35s) (28000 37%) 5.5040\n",
      "30m 2s (- 47m 38s) (29000 38%) 5.4628\n",
      "31m 6s (- 46m 39s) (30000 40%) 5.4820\n",
      "32m 9s (- 45m 38s) (31000 41%) 5.4851\n",
      "33m 15s (- 44m 40s) (32000 42%) 5.4161\n",
      "34m 17s (- 43m 38s) (33000 44%) 5.4848\n",
      "35m 22s (- 42m 39s) (34000 45%) 5.4958\n",
      "36m 26s (- 41m 38s) (35000 46%) 5.4051\n",
      "37m 31s (- 40m 39s) (36000 48%) 5.4083\n",
      "38m 35s (- 39m 37s) (37000 49%) 5.4114\n",
      "39m 40s (- 38m 37s) (38000 50%) 5.4460\n",
      "40m 45s (- 37m 36s) (39000 52%) 5.4048\n",
      "41m 50s (- 36m 36s) (40000 53%) 5.4527\n",
      "42m 54s (- 35m 34s) (41000 54%) 5.4113\n",
      "43m 57s (- 34m 32s) (42000 56%) 5.3359\n",
      "45m 1s (- 33m 30s) (43000 57%) 5.3617\n",
      "46m 5s (- 32m 28s) (44000 58%) 5.2896\n",
      "47m 10s (- 31m 27s) (45000 60%) 5.4059\n",
      "48m 15s (- 30m 25s) (46000 61%) 5.3892\n",
      "49m 20s (- 29m 23s) (47000 62%) 5.2864\n",
      "50m 24s (- 28m 21s) (48000 64%) 5.3950\n",
      "51m 28s (- 27m 18s) (49000 65%) 5.2781\n",
      "52m 31s (- 26m 15s) (50000 66%) 5.2437\n",
      "53m 35s (- 25m 13s) (51000 68%) 5.2864\n",
      "54m 39s (- 24m 10s) (52000 69%) 5.3040\n",
      "55m 44s (- 23m 8s) (53000 70%) 5.2987\n",
      "56m 48s (- 22m 5s) (54000 72%) 5.2590\n",
      "57m 52s (- 21m 2s) (55000 73%) 5.1983\n",
      "58m 56s (- 19m 59s) (56000 74%) 5.2330\n",
      "60m 1s (- 18m 57s) (57000 76%) 5.2653\n",
      "61m 6s (- 17m 54s) (58000 77%) 5.2252\n",
      "62m 10s (- 16m 51s) (59000 78%) 5.2355\n",
      "63m 14s (- 15m 48s) (60000 80%) 5.2584\n",
      "64m 19s (- 14m 45s) (61000 81%) 5.2949\n",
      "65m 24s (- 13m 42s) (62000 82%) 5.2918\n",
      "66m 29s (- 12m 39s) (63000 84%) 5.2212\n",
      "67m 34s (- 11m 36s) (64000 85%) 5.2090\n",
      "68m 41s (- 10m 34s) (65000 86%) 5.2069\n",
      "69m 45s (- 9m 30s) (66000 88%) 5.2225\n",
      "70m 50s (- 8m 27s) (67000 89%) 5.2723\n",
      "71m 54s (- 7m 24s) (68000 90%) 5.1432\n",
      "72m 59s (- 6m 20s) (69000 92%) 5.2290\n",
      "74m 4s (- 5m 17s) (70000 93%) 5.2065\n",
      "75m 11s (- 4m 14s) (71000 94%) 5.2921\n",
      "76m 15s (- 3m 10s) (72000 96%) 5.1610\n",
      "77m 19s (- 2m 7s) (73000 97%) 5.2133\n",
      "78m 22s (- 1m 3s) (74000 98%) 5.1617\n",
      "79m 27s (- 0m 0s) (75000 100%) 5.2000\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are  [0.1887738720223302, 0.05656664387322424, 0.01868575932313104]\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang2.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang2.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1_JxzKvxF5N"
   },
   "source": [
    "###Fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 11274673,
     "status": "ok",
     "timestamp": 1615731070682,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "WeLVXQOhxCMM"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 235\n",
    "# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN4(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN4, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\n",
    "        ##################\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        x=self.fc(hidden)\n",
    "        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\n",
    "            #################################\n",
    "       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang3, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang3, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs3))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 11274995,
     "status": "ok",
     "timestamp": 1615731071005,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "9bSwRykXxK_K"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang3, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang3.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang3, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang3.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang3.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs3)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs3:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs3:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16741189,
     "status": "ok",
     "timestamp": 1615736537201,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "aDUlbFWuxLFl",
    "outputId": "9f9880a0-486f-409f-8e92-7e6b26cfd8bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 4s (- 80m 6s) (1000 1%) 6.1452\n",
      "2m 4s (- 75m 33s) (2000 2%) 5.6695\n",
      "3m 3s (- 73m 17s) (3000 4%) 5.5035\n",
      "4m 1s (- 71m 29s) (4000 5%) 5.5569\n",
      "5m 0s (- 70m 4s) (5000 6%) 5.3796\n",
      "5m 59s (- 68m 58s) (6000 8%) 5.3946\n",
      "7m 0s (- 68m 3s) (7000 9%) 5.3879\n",
      "8m 1s (- 67m 8s) (8000 10%) 5.4289\n",
      "9m 0s (- 66m 5s) (9000 12%) 5.3511\n",
      "10m 2s (- 65m 18s) (10000 13%) 5.4991\n",
      "11m 3s (- 64m 17s) (11000 14%) 5.5117\n",
      "12m 4s (- 63m 23s) (12000 16%) 5.4843\n",
      "13m 6s (- 62m 32s) (13000 17%) 5.4492\n",
      "14m 8s (- 61m 37s) (14000 18%) 5.4927\n",
      "15m 12s (- 60m 49s) (15000 20%) 5.5997\n",
      "16m 16s (- 60m 1s) (16000 21%) 5.6281\n",
      "17m 21s (- 59m 13s) (17000 22%) 5.6039\n",
      "18m 26s (- 58m 24s) (18000 24%) 5.6733\n",
      "19m 30s (- 57m 30s) (19000 25%) 5.5655\n",
      "20m 35s (- 56m 37s) (20000 26%) 5.6703\n",
      "21m 39s (- 55m 40s) (21000 28%) 5.5087\n",
      "22m 44s (- 54m 47s) (22000 29%) 5.5786\n",
      "23m 47s (- 53m 48s) (23000 30%) 5.5616\n",
      "24m 52s (- 52m 52s) (24000 32%) 5.5468\n",
      "25m 56s (- 51m 52s) (25000 33%) 5.5471\n",
      "27m 0s (- 50m 53s) (26000 34%) 5.5585\n",
      "28m 5s (- 49m 55s) (27000 36%) 5.5526\n",
      "29m 9s (- 48m 56s) (28000 37%) 5.5023\n",
      "30m 15s (- 47m 59s) (29000 38%) 5.5914\n",
      "31m 21s (- 47m 2s) (30000 40%) 5.5616\n",
      "32m 25s (- 46m 1s) (31000 41%) 5.5099\n",
      "33m 27s (- 44m 57s) (32000 42%) 5.5849\n",
      "34m 26s (- 43m 50s) (33000 44%) 5.5287\n",
      "35m 26s (- 42m 44s) (34000 45%) 5.4160\n",
      "36m 27s (- 41m 39s) (35000 46%) 5.5065\n",
      "37m 28s (- 40m 36s) (36000 48%) 5.3209\n",
      "38m 30s (- 39m 33s) (37000 49%) 5.3314\n",
      "39m 32s (- 38m 29s) (38000 50%) 5.3745\n",
      "40m 33s (- 37m 25s) (39000 52%) 5.3594\n",
      "41m 34s (- 36m 22s) (40000 53%) 5.2710\n",
      "42m 36s (- 35m 20s) (41000 54%) 5.2944\n",
      "43m 37s (- 34m 16s) (42000 56%) 5.2780\n",
      "44m 39s (- 33m 13s) (43000 57%) 5.3561\n",
      "45m 40s (- 32m 10s) (44000 58%) 5.3605\n",
      "46m 42s (- 31m 8s) (45000 60%) 5.3985\n",
      "47m 44s (- 30m 5s) (46000 61%) 5.3094\n",
      "48m 47s (- 29m 3s) (47000 62%) 5.3887\n",
      "49m 49s (- 28m 1s) (48000 64%) 5.2834\n",
      "50m 52s (- 26m 59s) (49000 65%) 5.3302\n",
      "51m 55s (- 25m 57s) (50000 66%) 5.2664\n",
      "53m 1s (- 24m 57s) (51000 68%) 5.4099\n",
      "54m 3s (- 23m 54s) (52000 69%) 5.3079\n",
      "55m 8s (- 22m 53s) (53000 70%) 5.4141\n",
      "56m 12s (- 21m 51s) (54000 72%) 5.3888\n",
      "57m 16s (- 20m 49s) (55000 73%) 5.3533\n",
      "58m 20s (- 19m 47s) (56000 74%) 5.2472\n",
      "59m 24s (- 18m 45s) (57000 76%) 5.3515\n",
      "60m 28s (- 17m 43s) (58000 77%) 5.2971\n",
      "61m 33s (- 16m 41s) (59000 78%) 5.3165\n",
      "62m 37s (- 15m 39s) (60000 80%) 5.2707\n",
      "63m 44s (- 14m 37s) (61000 81%) 5.2938\n",
      "64m 49s (- 13m 35s) (62000 82%) 5.3069\n",
      "65m 58s (- 12m 33s) (63000 84%) 5.3815\n",
      "67m 3s (- 11m 31s) (64000 85%) 5.2834\n",
      "68m 8s (- 10m 28s) (65000 86%) 5.2549\n",
      "69m 13s (- 9m 26s) (66000 88%) 5.2613\n",
      "70m 17s (- 8m 23s) (67000 89%) 5.2682\n",
      "71m 22s (- 7m 20s) (68000 90%) 5.2670\n",
      "72m 28s (- 6m 18s) (69000 92%) 5.2387\n",
      "73m 32s (- 5m 15s) (70000 93%) 5.2258\n",
      "74m 37s (- 4m 12s) (71000 94%) 5.2822\n",
      "75m 40s (- 3m 9s) (72000 96%) 5.2820\n",
      "76m 45s (- 2m 6s) (73000 97%) 5.2836\n",
      "77m 50s (- 1m 3s) (74000 98%) 5.2997\n",
      "78m 55s (- 0m 0s) (75000 100%) 5.1577\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are  [0.18694995205952566, 0.058843287972948216, 0.020129758974315366]\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang3.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang3.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34QQDEirydMQ"
   },
   "source": [
    "###Fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 16741484,
     "status": "ok",
     "timestamp": 1615736537497,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "zCnOu5OXyPVu"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 235\n",
    "# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN4(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN4, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\n",
    "        ##################\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        x=self.fc(hidden)\n",
    "        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\n",
    "            #################################\n",
    "       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang4, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang4, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs4))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 16741796,
     "status": "ok",
     "timestamp": 1615736537810,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "avak6eD9yXww"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang4, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang4.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang4, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang4.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang4.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs4)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs4:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs4:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 16971557,
     "status": "error",
     "timestamp": 1615736767573,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "rVOKFdzNyYXX",
    "outputId": "71f0d86d-491b-42ba-f9ac-abad18267cf1"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang4.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang4.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtGbDe1GzSK9"
   },
   "source": [
    "###Fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16971178,
     "status": "aborted",
     "timestamp": 1615736767195,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "rM5o8g5vzQE7"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 235\n",
    "# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN4(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN4, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\n",
    "        ##################\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        x=self.fc(hidden)\n",
    "        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\n",
    "            #################################\n",
    "       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang5, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang5, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs5))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16971178,
     "status": "aborted",
     "timestamp": 1615736767196,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "JP78TY53zYHd"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang5, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang5.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang5, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang5.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang5.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs5)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs5:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs5:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16971177,
     "status": "aborted",
     "timestamp": 1615736767197,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "6u-YKVdSzaVV"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang5.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang5.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16971176,
     "status": "aborted",
     "timestamp": 1615736767197,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "P8qMVNHB402u"
   },
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16971176,
     "status": "aborted",
     "timestamp": 1615736767198,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "YK2wKfXx41dq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AS2_QB_FR_M.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
