{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22932,
     "status": "ok",
     "timestamp": 1615860005311,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "uT-lrh1Xe3ry",
    "outputId": "869b8a68-6585-413f-e66b-10f1aa9d973b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive/AI Sem II/NLP/A2\n",
      "/content/gdrive/My Drive/AI Sem II/NLP/A2\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "if 'google.colab' in sys.modules:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  path_to_file = '/content/gdrive/My Drive/AI Sem II/NLP/A2'\n",
    "  print(path_to_file)\n",
    "  os.chdir(path_to_file)\n",
    "  !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5599,
     "status": "ok",
     "timestamp": 1615860010915,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "sUm8xUsPjECA"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9662,
     "status": "ok",
     "timestamp": 1615860014987,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "hjR9yaPeIEDs",
    "outputId": "bfac6189-09c2-492e-fbb3-bb383c270828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165602, 165602)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ru = 'data/training/news-commentary-v9.ru-en.ru'\n",
    "data_en = 'data/training/news-commentary-v9.ru-en.en'\n",
    "\n",
    "with open(data_ru, 'rb') as ru: \n",
    "  sents_ru = [line.decode(\"utf-8\") for line in ru]      \n",
    " # sents_cs = [value for value in sents_cs if value != '']   \n",
    "with open(data_en, 'rb') as en: \n",
    "  sents_en = [line.decode(\"utf-8\") for line in en]\n",
    " # sents_en = [value for value in sents_en if value != '']\n",
    "len(sents_en), len(sents_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9656,
     "status": "ok",
     "timestamp": 1615860014988,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "08DjJdxvxuAW",
    "outputId": "c4c7d56b-f066-47d3-8ce7-ab94d6433bea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max length of string \n",
    "length_ru = [len(i.split()) for i in sents_ru]\n",
    "max(length_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11067,
     "status": "ok",
     "timestamp": 1615860016407,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "KrrJEeffxuEB",
    "outputId": "a8dae9d6-a87f-4829-a9fa-b5d99f1d77c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_en = [len(i.split()) for i in sents_en]\n",
    "max(length_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 11065,
     "status": "ok",
     "timestamp": 1615860016407,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "lXnu1aePaT6s"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "  def __init__(self, name):\n",
    "    self.name = name\n",
    "    self.word2index = {}\n",
    "    self.word2count = {}\n",
    "    self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "    self.n_words = 2\n",
    "\n",
    "  def addSentence(self, sentence):\n",
    "    \n",
    "    for word in sentence.split(' '):\n",
    "      self.addWord(word)\n",
    "  \n",
    "  def addWord(self, word):\n",
    "    if word not in self.word2index:\n",
    "      self.word2index[word] = self.n_words\n",
    "      self.word2count[word] = 1\n",
    "      self.index2word[self.n_words] = word \n",
    "      self.n_words += 1\n",
    "    else:\n",
    "      self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 11063,
     "status": "ok",
     "timestamp": 1615860016407,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "LaTNz04wdqKa"
   },
   "outputs": [],
   "source": [
    "def sent_pairs(lang1=sents_ru, lang2=sents_en):\n",
    "  pairs = []\n",
    "  for i, (cs_sent, en_sent) in enumerate(zip(lang1, lang2)):\n",
    "    #if i < 100:\n",
    "      #for russia\n",
    "      en_sent = unicodeToAscii(en_sent.lower().strip()) #for russian\n",
    "      en_sent = re.sub(r\"([.!?])\", r\" \\1\", en_sent)#for russian\n",
    "      en_sent = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", en_sent)#for russian\n",
    "      cs_sent = re.sub(r\"([.!?])\", r\" \\1\", cs_sent)#for russian\n",
    "      pairs.append([cs_sent, en_sent])\n",
    "\n",
    "  # for others\n",
    "  # pairs = [[normalizeString(s) for s in line] for line in pairs] # for others\n",
    "  input_lang1 = Lang('ru')\n",
    "  output_lang1 = Lang('en')\n",
    "\n",
    "  input_lang2 = Lang('ru')\n",
    "  output_lang2 = Lang('en')\n",
    "\n",
    "  input_lang3 = Lang('ru')\n",
    "  output_lang3 = Lang('en')\n",
    "\n",
    "  input_lang4 = Lang('ru')\n",
    "  output_lang4 = Lang('en')\n",
    "\n",
    "  input_lang5 = Lang('ru')\n",
    "  output_lang5 = Lang('en')\n",
    "\n",
    "     \n",
    "  return input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvQxz_O6IMm8"
   },
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "-  Read text file and split into lines, split lines into pairs\n",
    "-  Normalize text, filter by length and content\n",
    "-  Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32391,
     "status": "ok",
     "timestamp": 1615860037742,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "-ll3A_tPrdF8",
    "outputId": "400c3171-bc6d-48fe-98c9-46fa39b6df8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 165602 sentence pairs\n",
      "Number of test pairs: 33120\n",
      "Number of train pairs: 132482\n",
      "Counting words...\n",
      "Counted words:\n",
      "ru 211664\n",
      "en 42098\n",
      "Number of train pairs: 132482\n",
      "Counting words...\n",
      "Counted words:\n",
      "ru 211530\n",
      "en 42042\n",
      "Number of train pairs: 132482\n",
      "Counting words...\n",
      "Counted words:\n",
      "ru 211567\n",
      "en 42086\n",
      "Number of train pairs: 132482\n",
      "Counting words...\n",
      "Counted words:\n",
      "ru 211768\n",
      "en 42154\n",
      "Number of train pairs: 132480\n",
      "Counting words...\n",
      "Counted words:\n",
      "ru 211830\n",
      "en 42243\n",
      "['Скорее, Путина заботит баланс второй мировой войны и сталинизма в советской истории .\\n', 'rather what concerns putin is the balancing of wwii and stalinism in soviet history .']\n",
      "['Кроме того, вопросы повышения качества образования и квалификации, особенно в отношении девочек и женщин, остаются одними из приоритетных .\\n', 'moreover the challenge of raising educational quality and attainment especially of girls and women remains a priority .']\n",
      "['На протяжении слишком многих лет Балтийское море было тупиком на политической карте Европы, разделенной Железным Занавесом .\\n', 'for too many years the baltic sea was a blind alley on the political map of europe divided by the iron curtain .']\n",
      "['Началось все с роста количества призывов к большей социальной справедливости .\\n', 'start with the growing calls for greater social justice .']\n",
      "['Вторая: США, со своими мягкими ограничениями на продажу оружия служат настоящим арсеналом оружия для богатых мексиканских наркобаронов .\\n', 'second the us with its incredibly lax restrictions on gun purchases serves as a veritable arms depot for rich mexican drug lords .']\n"
     ]
    }
   ],
   "source": [
    " def prepareData(lang1=sents_ru, lang2=sents_en):\n",
    "    input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs = sent_pairs(lang1, lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    #Assumption: as the dataset is news commentary on different topics, there is highly unlikely exactly the same sentences \n",
    "    # collect test pairs\n",
    "    num_test = int(len(pairs)*0.2)\n",
    "    print(\"Number of test pairs:\", num_test)\n",
    "    random.seed(4)\n",
    "    random.shuffle(pairs)\n",
    "    \n",
    "    #fold 1\n",
    "    test_pairs1 = pairs[:num_test]\n",
    "     # collect train pairs\n",
    "    train_pairs1 = pairs[num_test:]\n",
    "    print(\"Number of train pairs:\", len(train_pairs1))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "    for pair in train_pairs1:      \n",
    "      input_lang1.addSentence(pair[0])\n",
    "      output_lang1.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang1.name, input_lang1.n_words)\n",
    "    print(output_lang1.name, output_lang1.n_words)\n",
    "\n",
    "    #fold 2\n",
    "    test_pairs2 = pairs[num_test:num_test*2]\n",
    "     # collect train pairs\n",
    "    train_pairs2 = pairs[:num_test]\n",
    "    for x in pairs[num_test*2:]:\n",
    "      train_pairs2.append(x)\n",
    "    print(\"Number of train pairs:\", len(train_pairs2))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs2:      \n",
    "      input_lang2.addSentence(pair[0])\n",
    "      output_lang2.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang2.name, input_lang2.n_words)\n",
    "    print(output_lang2.name, output_lang2.n_words)\n",
    "\n",
    "    #fold 3\n",
    "    test_pairs3 = pairs[num_test*2:num_test*3]\n",
    "     # collect train pairs\n",
    "    train_pairs3 = pairs[:num_test*2]\n",
    "    for x in pairs[num_test*3:]:\n",
    "      train_pairs3.append(x)\n",
    "    print(\"Number of train pairs:\", len(train_pairs3))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs3:      \n",
    "      input_lang3.addSentence(pair[0])\n",
    "      output_lang3.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang3.name, input_lang3.n_words)\n",
    "    print(output_lang3.name, output_lang3.n_words)\n",
    "\n",
    "\n",
    "    #fold 4\n",
    "    test_pairs4 = pairs[num_test*3:num_test*4]\n",
    "     # collect train pairs\n",
    "    train_pairs4 = pairs[:num_test*3]\n",
    "    for x in pairs[num_test*4:]:\n",
    "      train_pairs4.append(x)\n",
    "    print(\"Number of train pairs:\", len(train_pairs4))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs4:      \n",
    "      input_lang4.addSentence(pair[0])\n",
    "      output_lang4.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang4.name, input_lang4.n_words)\n",
    "    print(output_lang4.name, output_lang4.n_words)\n",
    "\n",
    "    #fold 5\n",
    "    test_pairs5 = pairs[num_test*4:]\n",
    "     # collect train pairs\n",
    "    train_pairs5 = pairs[:num_test*4]\n",
    "    print(\"Number of train pairs:\", len(train_pairs5))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs5:      \n",
    "      input_lang5.addSentence(pair[0])\n",
    "      output_lang5.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang5.name, input_lang5.n_words)\n",
    "    print(output_lang5.name, output_lang5.n_words)\n",
    "\n",
    "\n",
    "    return (input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4,input_lang5, output_lang5,train_pairs1, \n",
    "            test_pairs1, train_pairs2, test_pairs2, train_pairs3, test_pairs3,train_pairs4, test_pairs4,train_pairs5, test_pairs5)\n",
    "\n",
    "\n",
    "(input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, train_pairs1, test_pairs1, train_pairs2,\n",
    " test_pairs2,train_pairs3, test_pairs3, train_pairs4, test_pairs4,train_pairs5, test_pairs5) = prepareData(sents_ru, sents_en)\n",
    "print(random.choice(train_pairs1))\n",
    "print(random.choice(train_pairs2))\n",
    "print(random.choice(train_pairs3))\n",
    "print(random.choice(train_pairs4))\n",
    "print(random.choice(train_pairs5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npNTNDUOOwoC"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 171\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang1, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang1, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs1))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjoCFY3nTmBG"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang1, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang1.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang1, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang1.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang1.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs1)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs1:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs1:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08M4DvfPToJk",
    "outputId": "2f8d2bc6-2fc3-4c48-f014-88241baa1cc7"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang1.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8X7TtXWDvQCS"
   },
   "source": [
    "###Fold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1589,
     "status": "ok",
     "timestamp": 1615860039339,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "zTgC4HZSt6XD"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 180\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang1, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang1, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs1))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3416,
     "status": "ok",
     "timestamp": 1615860041168,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "Xj4EasFzvVmP"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang2, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang2.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang2, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang2.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang2.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs2)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs2:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs2:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 44330,
     "status": "error",
     "timestamp": 1615860082089,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "ab6RRAYUvcdZ",
    "outputId": "ed26a6d3-f3e2-4954-ba70-6024b69c2732"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang2.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang2.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1_JxzKvxF5N"
   },
   "source": [
    "###Fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1387,
     "status": "ok",
     "timestamp": 1615860101532,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "WeLVXQOhxCMM"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 180\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        \n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang3, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang3, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs3))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1480,
     "status": "ok",
     "timestamp": 1615860101936,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "9bSwRykXxK_K"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang3, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang3.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang3, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang3.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang3.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs3)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs3:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs3:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8447975,
     "status": "ok",
     "timestamp": 1615811751360,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "aDUlbFWuxLFl",
    "outputId": "949f9a28-d12f-4554-f5b8-12e08ef5e7e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 40s (- 124m 21s) (1000 1%) 6.0982\n",
      "3m 12s (- 117m 1s) (2000 2%) 5.4414\n",
      "4m 44s (- 113m 52s) (3000 4%) 5.3505\n",
      "6m 14s (- 110m 44s) (4000 5%) 5.4275\n",
      "7m 49s (- 109m 29s) (5000 6%) 5.3039\n",
      "9m 22s (- 107m 44s) (6000 8%) 5.3994\n",
      "10m 55s (- 106m 5s) (7000 9%) 5.3472\n",
      "12m 28s (- 104m 31s) (8000 10%) 5.4329\n",
      "14m 4s (- 103m 14s) (9000 12%) 5.3876\n",
      "15m 40s (- 101m 52s) (10000 13%) 5.3524\n",
      "17m 16s (- 100m 32s) (11000 14%) 5.4242\n",
      "18m 54s (- 99m 14s) (12000 16%) 5.5296\n",
      "20m 30s (- 97m 46s) (13000 17%) 5.4515\n",
      "22m 8s (- 96m 27s) (14000 18%) 5.6497\n",
      "23m 42s (- 94m 50s) (15000 20%) 5.3899\n",
      "25m 19s (- 93m 24s) (16000 21%) 5.4820\n",
      "26m 58s (- 92m 3s) (17000 22%) 5.5664\n",
      "28m 36s (- 90m 36s) (18000 24%) 5.5679\n",
      "30m 15s (- 89m 10s) (19000 25%) 5.5810\n",
      "31m 52s (- 87m 40s) (20000 26%) 5.4586\n",
      "33m 31s (- 86m 11s) (21000 28%) 5.5558\n",
      "35m 11s (- 84m 47s) (22000 29%) 5.4866\n",
      "36m 53s (- 83m 24s) (23000 30%) 5.5139\n",
      "38m 30s (- 81m 49s) (24000 32%) 5.4388\n",
      "40m 6s (- 80m 12s) (25000 33%) 5.3606\n",
      "41m 45s (- 78m 42s) (26000 34%) 5.5359\n",
      "43m 21s (- 77m 4s) (27000 36%) 5.4245\n",
      "44m 55s (- 75m 24s) (28000 37%) 5.3940\n",
      "46m 33s (- 73m 51s) (29000 38%) 5.4445\n",
      "48m 11s (- 72m 17s) (30000 40%) 5.4650\n",
      "49m 50s (- 70m 45s) (31000 41%) 5.3817\n",
      "51m 29s (- 69m 12s) (32000 42%) 5.4218\n",
      "53m 4s (- 67m 33s) (33000 44%) 5.3277\n",
      "54m 43s (- 65m 59s) (34000 45%) 5.4013\n",
      "56m 21s (- 64m 25s) (35000 46%) 5.3704\n",
      "57m 58s (- 62m 47s) (36000 48%) 5.4034\n",
      "59m 36s (- 61m 13s) (37000 49%) 5.3432\n",
      "61m 16s (- 59m 39s) (38000 50%) 5.3928\n",
      "62m 56s (- 58m 5s) (39000 52%) 5.3230\n",
      "64m 34s (- 56m 29s) (40000 53%) 5.3751\n",
      "66m 10s (- 54m 52s) (41000 54%) 5.3913\n",
      "67m 50s (- 53m 18s) (42000 56%) 5.4259\n",
      "69m 30s (- 51m 43s) (43000 57%) 5.3686\n",
      "71m 8s (- 50m 7s) (44000 58%) 5.3970\n",
      "72m 46s (- 48m 31s) (45000 60%) 5.3874\n",
      "74m 25s (- 46m 54s) (46000 61%) 5.3070\n",
      "76m 6s (- 45m 20s) (47000 62%) 5.4151\n",
      "77m 43s (- 43m 43s) (48000 64%) 5.2677\n",
      "79m 22s (- 42m 7s) (49000 65%) 5.2502\n",
      "81m 3s (- 40m 31s) (50000 66%) 5.3091\n",
      "82m 44s (- 38m 56s) (51000 68%) 5.3833\n",
      "84m 23s (- 37m 19s) (52000 69%) 5.3824\n",
      "86m 3s (- 35m 43s) (53000 70%) 5.3305\n",
      "87m 41s (- 34m 5s) (54000 72%) 5.3406\n",
      "89m 21s (- 32m 29s) (55000 73%) 5.2681\n",
      "90m 59s (- 30m 52s) (56000 74%) 5.3320\n",
      "92m 39s (- 29m 15s) (57000 76%) 5.3040\n",
      "94m 17s (- 27m 38s) (58000 77%) 5.2199\n",
      "95m 56s (- 26m 1s) (59000 78%) 5.2889\n",
      "97m 36s (- 24m 24s) (60000 80%) 5.2022\n",
      "99m 16s (- 22m 46s) (61000 81%) 5.1512\n",
      "100m 54s (- 21m 9s) (62000 82%) 5.2938\n",
      "102m 35s (- 19m 32s) (63000 84%) 5.4116\n",
      "104m 14s (- 17m 55s) (64000 85%) 5.2277\n",
      "105m 55s (- 16m 17s) (65000 86%) 5.2721\n",
      "107m 37s (- 14m 40s) (66000 88%) 5.3330\n",
      "109m 18s (- 13m 3s) (67000 89%) 5.3450\n",
      "110m 57s (- 11m 25s) (68000 90%) 5.2375\n",
      "112m 39s (- 9m 47s) (69000 92%) 5.3385\n",
      "114m 20s (- 8m 10s) (70000 93%) 5.2387\n",
      "116m 2s (- 6m 32s) (71000 94%) 5.3405\n",
      "117m 42s (- 4m 54s) (72000 96%) 5.2079\n",
      "119m 23s (- 3m 16s) (73000 97%) 5.2915\n",
      "121m 5s (- 1m 38s) (74000 98%) 5.3205\n",
      "122m 47s (- 0m 0s) (75000 100%) 5.2906\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are  [0.16956879399998825, 0.046429028921047236, 0.01523405261598885]\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang3.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang3.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34QQDEirydMQ"
   },
   "source": [
    "###Fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCnOu5OXyPVu"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 190\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang4, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang4, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs4))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avak6eD9yXww"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang4, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang4.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang4, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang4.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang4.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs4)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs4:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs4:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8275481,
     "status": "ok",
     "timestamp": 1615825346190,
     "user": {
      "displayName": "chao wang",
      "photoUrl": "",
      "userId": "16929231235898515362"
     },
     "user_tz": -480
    },
    "id": "rVOKFdzNyYXX",
    "outputId": "95e88247-7459-481d-9174-8fccf6893236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 41s (- 125m 27s) (1000 1%) 5.9419\n",
      "3m 16s (- 119m 40s) (2000 2%) 5.7257\n",
      "4m 50s (- 116m 6s) (3000 4%) 5.3202\n",
      "6m 21s (- 112m 53s) (4000 5%) 5.3840\n",
      "7m 55s (- 110m 57s) (5000 6%) 5.4026\n",
      "9m 29s (- 109m 14s) (6000 8%) 5.3332\n",
      "11m 3s (- 107m 28s) (7000 9%) 5.2367\n",
      "12m 41s (- 106m 21s) (8000 10%) 5.3817\n",
      "14m 17s (- 104m 51s) (9000 12%) 5.4183\n",
      "15m 50s (- 103m 0s) (10000 13%) 5.4598\n",
      "17m 27s (- 101m 36s) (11000 14%) 5.5862\n",
      "19m 6s (- 100m 17s) (12000 16%) 5.6063\n",
      "20m 44s (- 98m 55s) (13000 17%) 5.5124\n",
      "22m 24s (- 97m 36s) (14000 18%) 5.5399\n",
      "24m 3s (- 96m 13s) (15000 20%) 5.5931\n",
      "25m 42s (- 94m 48s) (16000 21%) 5.5716\n",
      "27m 22s (- 93m 24s) (17000 22%) 5.4486\n",
      "29m 4s (- 92m 2s) (18000 24%) 5.5415\n",
      "30m 43s (- 90m 33s) (19000 25%) 5.6012\n",
      "32m 25s (- 89m 8s) (20000 26%) 5.5358\n",
      "34m 1s (- 87m 30s) (21000 28%) 5.4089\n",
      "35m 39s (- 85m 54s) (22000 29%) 5.4519\n",
      "37m 20s (- 84m 25s) (23000 30%) 5.4828\n",
      "38m 56s (- 82m 44s) (24000 32%) 5.4954\n",
      "40m 35s (- 81m 10s) (25000 33%) 5.3703\n",
      "42m 16s (- 79m 39s) (26000 34%) 5.4886\n",
      "43m 57s (- 78m 8s) (27000 36%) 5.4915\n",
      "45m 34s (- 76m 29s) (28000 37%) 5.4452\n",
      "47m 14s (- 74m 56s) (29000 38%) 5.4018\n",
      "48m 56s (- 73m 24s) (30000 40%) 5.3662\n",
      "50m 37s (- 71m 51s) (31000 41%) 5.3494\n",
      "52m 14s (- 70m 11s) (32000 42%) 5.3019\n",
      "53m 52s (- 68m 33s) (33000 44%) 5.3647\n",
      "55m 29s (- 66m 55s) (34000 45%) 5.2906\n",
      "57m 6s (- 65m 15s) (35000 46%) 5.3684\n",
      "58m 45s (- 63m 39s) (36000 48%) 5.4726\n",
      "60m 24s (- 62m 2s) (37000 49%) 5.4490\n",
      "62m 4s (- 60m 26s) (38000 50%) 5.3928\n",
      "63m 41s (- 58m 47s) (39000 52%) 5.3276\n",
      "65m 20s (- 57m 10s) (40000 53%) 5.3661\n",
      "66m 59s (- 55m 33s) (41000 54%) 5.2880\n",
      "68m 39s (- 53m 56s) (42000 56%) 5.2964\n",
      "70m 18s (- 52m 19s) (43000 57%) 5.3285\n",
      "72m 1s (- 50m 44s) (44000 58%) 5.3434\n",
      "73m 42s (- 49m 8s) (45000 60%) 5.2803\n",
      "75m 22s (- 47m 30s) (46000 61%) 5.3501\n",
      "77m 1s (- 45m 53s) (47000 62%) 5.3910\n",
      "78m 40s (- 44m 15s) (48000 64%) 5.3831\n",
      "80m 19s (- 42m 37s) (49000 65%) 5.2130\n",
      "81m 59s (- 40m 59s) (50000 66%) 5.3377\n",
      "83m 39s (- 39m 21s) (51000 68%) 5.2894\n",
      "85m 18s (- 37m 43s) (52000 69%) 5.2266\n",
      "86m 58s (- 36m 6s) (53000 70%) 5.2909\n",
      "88m 37s (- 34m 28s) (54000 72%) 5.3008\n",
      "90m 16s (- 32m 49s) (55000 73%) 5.3321\n",
      "91m 54s (- 31m 11s) (56000 74%) 5.1277\n",
      "93m 33s (- 29m 32s) (57000 76%) 5.1706\n",
      "95m 11s (- 27m 54s) (58000 77%) 5.2173\n",
      "96m 49s (- 26m 15s) (59000 78%) 5.1478\n",
      "98m 30s (- 24m 37s) (60000 80%) 5.3011\n",
      "100m 8s (- 22m 59s) (61000 81%) 5.3007\n",
      "101m 46s (- 21m 20s) (62000 82%) 5.2716\n",
      "103m 23s (- 19m 41s) (63000 84%) 5.1421\n",
      "105m 3s (- 18m 3s) (64000 85%) 5.2268\n",
      "106m 42s (- 16m 24s) (65000 86%) 5.2583\n",
      "108m 21s (- 14m 46s) (66000 88%) 5.2006\n",
      "110m 3s (- 13m 8s) (67000 89%) 5.3156\n",
      "111m 43s (- 11m 30s) (68000 90%) 5.2778\n",
      "113m 22s (- 9m 51s) (69000 92%) 5.2683\n",
      "115m 5s (- 8m 13s) (70000 93%) 5.2241\n",
      "116m 44s (- 6m 34s) (71000 94%) 5.2407\n",
      "118m 22s (- 4m 55s) (72000 96%) 5.1526\n",
      "120m 2s (- 3m 17s) (73000 97%) 5.2321\n",
      "121m 40s (- 1m 38s) (74000 98%) 5.1584\n",
      "123m 20s (- 0m 0s) (75000 100%) 5.2186\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are  [0.17129171116756362, 0.052550652794333554, 0.016585973353710592]\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang4.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang4.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtGbDe1GzSK9"
   },
   "source": [
    "###Fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rM5o8g5vzQE7"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 190\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        \n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang5, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang5, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs5))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JP78TY53zYHd"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang5, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang5.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang5, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang5.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang5.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs5)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs5:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs5:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6u-YKVdSzaVV"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang5.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang5.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8qMVNHB402u"
   },
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGfGFyLuK71_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AS2_QB_RU_A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
