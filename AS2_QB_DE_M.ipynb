{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"AS2_QB_DE_M.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uT-lrh1Xe3ry","executionInfo":{"elapsed":929,"status":"ok","timestamp":1615650324814,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"},"user_tz":-480},"outputId":"237b68e3-f754-4260-b9b4-e30d97aa2aa2"},"source":["import sys,os\r\n","if 'google.colab' in sys.modules:\r\n","  from google.colab import drive\r\n","  drive.mount('/content/gdrive')\r\n","  path_to_file = '/content/gdrive/My Drive/AI Sem II/NLP/A2'\r\n","  print(path_to_file)\r\n","  os.chdir(path_to_file)\r\n","  !pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/My Drive/AI Sem II/NLP/A2\n","/content/gdrive/My Drive/AI Sem II/NLP/A2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sUm8xUsPjECA"},"source":["from __future__ import unicode_literals, print_function, division\r\n","from io import open\r\n","import unicodedata\r\n","import string\r\n","import re\r\n","import random\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","from torch import optim\r\n","import torch.nn.functional as F\r\n","\r\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjR9yaPeIEDs","executionInfo":{"elapsed":8792,"status":"ok","timestamp":1615650332685,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"},"user_tz":-480},"outputId":"a8dbe2dd-26e4-4255-a991-40786ec49d79"},"source":["data_de = 'data/training/news-commentary-v9.de-en.de'\r\n","data_en = 'data/training/news-commentary-v9.de-en.en'\r\n","\r\n","with open(data_de, 'rb') as de: \r\n","  sents_de = [line.decode(\"utf-8\") for line in de]      \r\n"," # sents_cs = [value for value in sents_cs if value != '']   \r\n","with open(data_en, 'rb') as en: \r\n","  sents_en = [line.decode(\"utf-8\") for line in en]\r\n"," # sents_en = [value for value in sents_en if value != '']\r\n","len(sents_en), len(sents_de)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(201288, 201288)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08DjJdxvxuAW","executionInfo":{"elapsed":9153,"status":"ok","timestamp":1615650333055,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"},"user_tz":-480},"outputId":"df8d1e6a-9977-41b7-a016-98b25a1c049f"},"source":["#max length of string \r\n","length_de = [len(i.split()) for i in sents_de]\r\n","max(length_de)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["193"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrrJEeffxuEB","executionInfo":{"elapsed":9146,"status":"ok","timestamp":1615650333055,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"},"user_tz":-480},"outputId":"f1bae2c2-bc1a-4a61-b424-ba10c56d942a"},"source":["length_en = [len(i.split()) for i in sents_en]\r\n","max(length_en)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["171"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"lXnu1aePaT6s"},"source":["SOS_token = 0\r\n","EOS_token = 1\r\n","\r\n","class Lang:\r\n","  def __init__(self, name):\r\n","    self.name = name\r\n","    self.word2index = {}\r\n","    self.word2count = {}\r\n","    self.index2word = {0: \"SOS\", 1: \"EOS\"}\r\n","    self.n_words = 2\r\n","\r\n","  def addSentence(self, sentence):\r\n","    \r\n","    for word in sentence.split(' '):\r\n","      self.addWord(word)\r\n","  \r\n","  def addWord(self, word):\r\n","    if word not in self.word2index:\r\n","      self.word2index[word] = self.n_words\r\n","      self.word2count[word] = 1\r\n","      self.index2word[self.n_words] = word \r\n","      self.n_words += 1\r\n","    else:\r\n","      self.word2count[word] += 1\r\n","\r\n","# Turn a Unicode string to plain ASCII, thanks to\r\n","# https://stackoverflow.com/a/518232/2809427\r\n","def unicodeToAscii(s):\r\n","    return ''.join(\r\n","        c for c in unicodedata.normalize('NFD', s)\r\n","        if unicodedata.category(c) != 'Mn'\r\n","    )\r\n","\r\n","# Lowercase, trim, and remove non-letter characters\r\n","\r\n","\r\n","def normalizeString(s):\r\n","    s = unicodeToAscii(s.lower().strip())\r\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\r\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\r\n","    return s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaTNz04wdqKa"},"source":["def sent_pairs(lang1=sents_de, lang2=sents_en):\r\n","  pairs = []\r\n","  for i, (cs_sent, en_sent) in enumerate(zip(lang1, lang2)):\r\n","    #if i < 100:\r\n","      pairs.append([cs_sent, en_sent])\r\n","   # print(i)\r\n","  pairs = [[normalizeString(s) for s in line] for line in pairs]\r\n","  input_lang1 = Lang('de')\r\n","  output_lang1 = Lang('en')\r\n","\r\n","  input_lang2 = Lang('de')\r\n","  output_lang2 = Lang('en')\r\n","\r\n","  input_lang3 = Lang('de')\r\n","  output_lang3 = Lang('en')\r\n","\r\n","  input_lang4 = Lang('de')\r\n","  output_lang4 = Lang('en')\r\n","\r\n","  input_lang5 = Lang('de')\r\n","  output_lang5 = Lang('en')\r\n","\r\n","     \r\n","  return input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs\r\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TvQxz_O6IMm8"},"source":["The full process for preparing the data is:\r\n","\r\n","-  Read text file and split into lines, split lines into pairs\r\n","-  Normalize text, filter by length and content\r\n","-  Make word lists from sentences in pairs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ll3A_tPrdF8","executionInfo":{"elapsed":44932,"status":"ok","timestamp":1615650368852,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"},"user_tz":-480},"outputId":"53ca8a4a-e95a-4a54-ca3e-4492fd9772b7"},"source":[" def prepareData(lang1=sents_de, lang2=sents_en):\r\n","    input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs = sent_pairs(lang1, lang2)\r\n","    print(\"Read %s sentence pairs\" % len(pairs))\r\n","\r\n","    #Assumption: as the dataset is news commentary on different topics, there is highly unlikely exactly the same sentences \r\n","    # collect test pairs\r\n","    num_test = int(len(pairs)*0.2)\r\n","    print(\"Number of test pairs:\", num_test)\r\n","    random.seed(2)\r\n","    random.shuffle(pairs)\r\n","    \r\n","    #fold 1\r\n","    test_pairs1 = pairs[:num_test]\r\n","     # collect train pairs\r\n","    train_pairs1 = pairs[num_test:]\r\n","    print(\"Number of train pairs:\", len(train_pairs1))\r\n","    print(\"Counting words...\")\r\n","\r\n","    for pair in train_pairs1:      \r\n","      input_lang1.addSentence(pair[0])\r\n","      output_lang1.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang1.name, input_lang1.n_words)\r\n","    print(output_lang1.name, output_lang1.n_words)\r\n","\r\n","    #fold 2\r\n","    test_pairs2 = pairs[num_test:num_test*2]\r\n","     # collect train pairs\r\n","    train_pairs2 = pairs[:num_test]\r\n","    for x in pairs[num_test*2:]:\r\n","      train_pairs2.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs2))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs2:      \r\n","      input_lang2.addSentence(pair[0])\r\n","      output_lang2.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang2.name, input_lang2.n_words)\r\n","    print(output_lang2.name, output_lang2.n_words)\r\n","\r\n","    #fold 3\r\n","    test_pairs3 = pairs[num_test*2:num_test*3]\r\n","     # collect train pairs\r\n","    train_pairs3 = pairs[:num_test*2]\r\n","    for x in pairs[num_test*3:]:\r\n","      train_pairs3.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs3))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs3:      \r\n","      input_lang3.addSentence(pair[0])\r\n","      output_lang3.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang3.name, input_lang3.n_words)\r\n","    print(output_lang3.name, output_lang3.n_words)\r\n","\r\n","\r\n","    #fold 4\r\n","    test_pairs4 = pairs[num_test*3:num_test*4]\r\n","     # collect train pairs\r\n","    train_pairs4 = pairs[:num_test*3]\r\n","    for x in pairs[num_test*4:]:\r\n","      train_pairs4.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs4))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs4:      \r\n","      input_lang4.addSentence(pair[0])\r\n","      output_lang4.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang4.name, input_lang4.n_words)\r\n","    print(output_lang4.name, output_lang4.n_words)\r\n","\r\n","    #fold 5\r\n","    test_pairs5 = pairs[num_test*4:]\r\n","     # collect train pairs\r\n","    train_pairs5 = pairs[:num_test*4]\r\n","    print(\"Number of train pairs:\", len(train_pairs5))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs5:      \r\n","      input_lang5.addSentence(pair[0])\r\n","      output_lang5.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang5.name, input_lang5.n_words)\r\n","    print(output_lang5.name, output_lang5.n_words)\r\n","\r\n","\r\n","    return (input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4,input_lang5, output_lang5,train_pairs1, \r\n","            test_pairs1, train_pairs2, test_pairs2, train_pairs3, test_pairs3,train_pairs4, test_pairs4,train_pairs5, test_pairs5)\r\n","\r\n","\r\n","(input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, train_pairs1, test_pairs1, train_pairs2,\r\n"," test_pairs2,train_pairs3, test_pairs3, train_pairs4, test_pairs4,train_pairs5, test_pairs5) = prepareData(sents_de, sents_en)\r\n","print(random.choice(train_pairs1))\r\n","print(random.choice(train_pairs2))\r\n","print(random.choice(train_pairs3))\r\n","print(random.choice(train_pairs4))\r\n","print(random.choice(train_pairs5))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Read 201288 sentence pairs\n","Number of test pairs: 40257\n","Number of train pairs: 161031\n","Counting words...\n","Counted words:\n","de 119269\n","en 44656\n","Number of train pairs: 161031\n","Counting words...\n","Counted words:\n","de 119522\n","en 44791\n","Number of train pairs: 161031\n","Counting words...\n","Counted words:\n","de 119470\n","en 44801\n","Number of train pairs: 161031\n","Counting words...\n","Counted words:\n","de 119374\n","en 44755\n","Number of train pairs: 161028\n","Counting words...\n","Counted words:\n","de 119765\n","en 44747\n","['sie muss in der einheimischen bevolkerung verwurzelt sein und ihre eigentumlichkeiten berucksichtigen sie darf nicht aus dem ausland auferlegt werden .', 'it must be rooted in the indigenous society and bear its characteristics not be imposed from abroad .']\n","['seine hauptwaffe war die sprache der freiheit .', 'its main weapon was the language of freedom .']\n","['und zwar so lange bis es anzeichen dafur gibt dass eine weitere konjunkturbelebung die stabilitat des preis oder schuldenmanagements bedroht oder bis die arbeitslosigkeit weit genug sinkt um barros multiplikatoren uberbewertet erscheinen zu lassen .', 'indeed we should do it repeatedly until there are signs that additional stimulus may start to threaten price or debt management stability or until unemployment falls far enough to make barro s multipliers overestimates .']\n","['einige der angste in bezug auf die globalisierung des akademischen betriebs mogen verstandlich sein besonders in einer phase enormer wirtschaftlicher unsicherheit .', 'perhaps some of the anxiety over the new global academic enterprise is understandable particularly in a period of massive economic uncertainty .']\n","['die offentlichkeit konnte ein stuck naturgeschichte bekommen und das vermachtnis der natur wird bewahrt .', 'the public could get a piece of the history of life and the natural heritage is preserved .']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"npNTNDUOOwoC"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 200\r\n","# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN4(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN4, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\r\n","        ##################\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        x=self.fc(hidden)\r\n","        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\r\n","            #################################\r\n","       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        \r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang1, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang1, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs1))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjoCFY3nTmBG"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang1, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang1.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang1, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang1.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang1.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs1)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs1:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs1:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"08M4DvfPToJk","outputId":"317ea856-bf7c-4ac3-f092-5ee4108ae160"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang1.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang1.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0m 58s (- 72m 44s) (1000 1%) 6.0785\n","1m 51s (- 67m 44s) (2000 2%) 5.7273\n","2m 44s (- 65m 45s) (3000 4%) 5.5323\n","3m 36s (- 64m 7s) (4000 5%) 5.4098\n","4m 29s (- 62m 54s) (5000 6%) 5.4501\n","5m 23s (- 62m 1s) (6000 8%) 5.5488\n","6m 17s (- 61m 11s) (7000 9%) 5.5089\n","7m 12s (- 60m 23s) (8000 10%) 5.4395\n","8m 7s (- 59m 34s) (9000 12%) 5.4870\n","9m 1s (- 58m 40s) (10000 13%) 5.5076\n","9m 57s (- 57m 53s) (11000 14%) 5.5717\n","10m 52s (- 57m 5s) (12000 16%) 5.4946\n","11m 50s (- 56m 27s) (13000 17%) 5.6596\n","12m 46s (- 55m 41s) (14000 18%) 5.5555\n","13m 42s (- 54m 51s) (15000 20%) 5.4747\n","14m 39s (- 54m 4s) (16000 21%) 5.6016\n","15m 37s (- 53m 17s) (17000 22%) 5.6372\n","16m 35s (- 52m 32s) (18000 24%) 5.6657\n","17m 31s (- 51m 40s) (19000 25%) 5.5729\n","18m 29s (- 50m 50s) (20000 26%) 5.5252\n","19m 27s (- 50m 2s) (21000 28%) 5.6560\n","20m 26s (- 49m 13s) (22000 29%) 5.5959\n","21m 25s (- 48m 27s) (23000 30%) 5.6182\n","22m 23s (- 47m 35s) (24000 32%) 5.5508\n","23m 20s (- 46m 41s) (25000 33%) 5.5265\n","24m 19s (- 45m 49s) (26000 34%) 5.5270\n","25m 15s (- 44m 54s) (27000 36%) 5.4459\n","26m 13s (- 44m 1s) (28000 37%) 5.4991\n","27m 10s (- 43m 6s) (29000 38%) 5.4920\n","28m 7s (- 42m 11s) (30000 40%) 5.4546\n","29m 4s (- 41m 15s) (31000 41%) 5.4354\n","30m 2s (- 40m 21s) (32000 42%) 5.4661\n","31m 0s (- 39m 27s) (33000 44%) 5.5134\n","31m 56s (- 38m 31s) (34000 45%) 5.4228\n","32m 53s (- 37m 34s) (35000 46%) 5.4038\n","33m 52s (- 36m 42s) (36000 48%) 5.4382\n","34m 52s (- 35m 49s) (37000 49%) 5.4596\n","35m 49s (- 34m 52s) (38000 50%) 5.3570\n","36m 47s (- 33m 57s) (39000 52%) 5.3706\n","37m 45s (- 33m 2s) (40000 53%) 5.4324\n","38m 42s (- 32m 5s) (41000 54%) 5.2760\n","39m 40s (- 31m 10s) (42000 56%) 5.3875\n","40m 37s (- 30m 14s) (43000 57%) 5.3072\n","41m 36s (- 29m 18s) (44000 58%) 5.4110\n","42m 33s (- 28m 22s) (45000 60%) 5.2903\n","43m 30s (- 27m 26s) (46000 61%) 5.2794\n","44m 27s (- 26m 29s) (47000 62%) 5.3227\n","45m 25s (- 25m 33s) (48000 64%) 5.3354\n","46m 22s (- 24m 36s) (49000 65%) 5.3096\n","47m 20s (- 23m 40s) (50000 66%) 5.2539\n","48m 19s (- 22m 44s) (51000 68%) 5.3002\n","49m 18s (- 21m 48s) (52000 69%) 5.3554\n","50m 16s (- 20m 51s) (53000 70%) 5.3390\n","51m 13s (- 19m 55s) (54000 72%) 5.2502\n","52m 11s (- 18m 58s) (55000 73%) 5.2631\n","53m 10s (- 18m 2s) (56000 74%) 5.2703\n","54m 7s (- 17m 5s) (57000 76%) 5.2787\n","55m 4s (- 16m 8s) (58000 77%) 5.2656\n","56m 3s (- 15m 12s) (59000 78%) 5.3023\n","57m 1s (- 14m 15s) (60000 80%) 5.2817\n","57m 59s (- 13m 18s) (61000 81%) 5.2694\n","59m 0s (- 12m 22s) (62000 82%) 5.3055\n","60m 0s (- 11m 25s) (63000 84%) 5.2797\n","61m 0s (- 10m 29s) (64000 85%) 5.2933\n","61m 59s (- 9m 32s) (65000 86%) 5.2722\n","62m 58s (- 8m 35s) (66000 88%) 5.2245\n","63m 56s (- 7m 38s) (67000 89%) 5.2352\n","64m 54s (- 6m 40s) (68000 90%) 5.1751\n","65m 50s (- 5m 43s) (69000 92%) 5.1765\n","66m 47s (- 4m 46s) (70000 93%) 5.1472\n","67m 44s (- 3m 48s) (71000 94%) 5.0746\n","68m 39s (- 2m 51s) (72000 96%) 5.0344\n","69m 33s (- 1m 54s) (73000 97%) 4.9842\n","70m 30s (- 0m 57s) (74000 98%) 5.0561\n","71m 24s (- 0m 0s) (75000 100%) 5.1140\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","37000\n","38000\n","39000\n","40000\n","Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are  [0.18682156196960817, 0.06364086821727408, 0.0233224210848711]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8X7TtXWDvQCS"},"source":["###Fold2"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"zTgC4HZSt6XD"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 200\r\n","# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN4(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN4, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\r\n","        ##################\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        x=self.fc(hidden)\r\n","        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\r\n","            #################################\r\n","       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        \r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang2, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang2, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs2))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Xj4EasFzvVmP"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang2, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang2.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang2, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang2.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang2.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs2)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs2:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs2:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"ab6RRAYUvcdZ","outputId":"b66d5e4f-bcc0-47a9-f1c5-2a955643e883"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang2.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang2.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1m 0s (- 74m 56s) (1000 1%) 6.1660\n","1m 55s (- 70m 20s) (2000 2%) 5.7304\n","2m 50s (- 68m 8s) (3000 4%) 5.6017\n","3m 42s (- 65m 47s) (4000 5%) 5.4174\n","4m 34s (- 64m 2s) (5000 6%) 5.3850\n","5m 27s (- 62m 41s) (6000 8%) 5.4675\n","6m 19s (- 61m 24s) (7000 9%) 5.3632\n","7m 13s (- 60m 29s) (8000 10%) 5.3913\n","8m 7s (- 59m 32s) (9000 12%) 5.3616\n","9m 2s (- 58m 46s) (10000 13%) 5.4002\n","9m 56s (- 57m 52s) (11000 14%) 5.5374\n","10m 52s (- 57m 5s) (12000 16%) 5.4735\n","11m 48s (- 56m 17s) (13000 17%) 5.5690\n","12m 45s (- 55m 33s) (14000 18%) 5.6549\n","13m 43s (- 54m 52s) (15000 20%) 5.6594\n","14m 40s (- 54m 6s) (16000 21%) 5.6886\n","15m 38s (- 53m 23s) (17000 22%) 5.7286\n","16m 39s (- 52m 43s) (18000 24%) 5.7108\n","17m 36s (- 51m 53s) (19000 25%) 5.6952\n","18m 34s (- 51m 4s) (20000 26%) 5.6787\n","19m 32s (- 50m 14s) (21000 28%) 5.5752\n","20m 31s (- 49m 25s) (22000 29%) 5.6579\n","21m 30s (- 48m 38s) (23000 30%) 5.6475\n","22m 28s (- 47m 45s) (24000 32%) 5.6399\n","23m 28s (- 46m 56s) (25000 33%) 5.5861\n","24m 26s (- 46m 4s) (26000 34%) 5.5661\n","25m 24s (- 45m 9s) (27000 36%) 5.6171\n","26m 23s (- 44m 17s) (28000 37%) 5.5454\n","27m 21s (- 43m 23s) (29000 38%) 5.5177\n","28m 17s (- 42m 26s) (30000 40%) 5.4971\n","29m 17s (- 41m 34s) (31000 41%) 5.5519\n","30m 14s (- 40m 38s) (32000 42%) 5.4708\n","31m 12s (- 39m 43s) (33000 44%) 5.4866\n","32m 11s (- 38m 49s) (34000 45%) 5.5773\n","33m 9s (- 37m 53s) (35000 46%) 5.5473\n","34m 7s (- 36m 57s) (36000 48%) 5.4548\n","35m 5s (- 36m 2s) (37000 49%) 5.4484\n","36m 4s (- 35m 7s) (38000 50%) 5.3729\n","37m 4s (- 34m 13s) (39000 52%) 5.4237\n","38m 3s (- 33m 17s) (40000 53%) 5.4440\n","38m 59s (- 32m 20s) (41000 54%) 5.3686\n","39m 57s (- 31m 23s) (42000 56%) 5.4515\n","40m 53s (- 30m 25s) (43000 57%) 5.4044\n","41m 51s (- 29m 29s) (44000 58%) 5.3491\n","42m 49s (- 28m 32s) (45000 60%) 5.3688\n","43m 47s (- 27m 36s) (46000 61%) 5.5282\n","44m 45s (- 26m 39s) (47000 62%) 5.3697\n","45m 42s (- 25m 42s) (48000 64%) 5.3790\n","46m 40s (- 24m 45s) (49000 65%) 5.3372\n","47m 37s (- 23m 48s) (50000 66%) 5.3681\n","48m 36s (- 22m 52s) (51000 68%) 5.3943\n","49m 36s (- 21m 56s) (52000 69%) 5.3528\n","50m 33s (- 20m 59s) (53000 70%) 5.2930\n","51m 31s (- 20m 2s) (54000 72%) 5.2464\n","52m 30s (- 19m 5s) (55000 73%) 5.3243\n","53m 28s (- 18m 8s) (56000 74%) 5.3188\n","54m 27s (- 17m 11s) (57000 76%) 5.3034\n","55m 25s (- 16m 14s) (58000 77%) 5.3110\n","56m 23s (- 15m 17s) (59000 78%) 5.2773\n","57m 23s (- 14m 20s) (60000 80%) 5.3240\n","58m 20s (- 13m 23s) (61000 81%) 5.2485\n","59m 17s (- 12m 25s) (62000 82%) 5.2501\n","60m 14s (- 11m 28s) (63000 84%) 5.2435\n","61m 12s (- 10m 31s) (64000 85%) 5.2564\n","62m 9s (- 9m 33s) (65000 86%) 5.2310\n","63m 7s (- 8m 36s) (66000 88%) 5.2650\n","64m 5s (- 7m 39s) (67000 89%) 5.2139\n","65m 4s (- 6m 41s) (68000 90%) 5.2929\n","66m 2s (- 5m 44s) (69000 92%) 5.2605\n","67m 1s (- 4m 47s) (70000 93%) 5.2011\n","67m 57s (- 3m 49s) (71000 94%) 5.1463\n","68m 57s (- 2m 52s) (72000 96%) 5.3074\n","69m 54s (- 1m 54s) (73000 97%) 5.1721\n","70m 52s (- 0m 57s) (74000 98%) 5.2372\n","71m 50s (- 0m 0s) (75000 100%) 5.2680\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","37000\n","38000\n","39000\n","40000\n","Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are  [0.21470830717078465, 0.07053884189100633, 0.025136259898013515]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_1_JxzKvxF5N"},"source":["###Fold 3"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"WeLVXQOhxCMM"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 200\r\n","# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN4(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN4, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\r\n","        ##################\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        x=self.fc(hidden)\r\n","        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\r\n","            #################################\r\n","       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        \r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang3, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang3, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs3))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"9bSwRykXxK_K"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang3, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang3.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang3, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang3.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang3.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs3)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs3:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs3:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"aDUlbFWuxLFl","outputId":"093b0efc-e50b-4670-d77d-cb091495990c"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang3.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang3.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0m 59s (- 73m 7s) (1000 1%) 6.1002\n","1m 53s (- 69m 9s) (2000 2%) 5.7081\n","2m 46s (- 66m 28s) (3000 4%) 5.5944\n","3m 39s (- 64m 54s) (4000 5%) 5.4588\n","4m 33s (- 63m 53s) (5000 6%) 5.5420\n","5m 27s (- 62m 49s) (6000 8%) 5.4373\n","6m 20s (- 61m 36s) (7000 9%) 5.5183\n","7m 14s (- 60m 35s) (8000 10%) 5.4817\n","8m 8s (- 59m 42s) (9000 12%) 5.4402\n","9m 3s (- 58m 55s) (10000 13%) 5.4304\n","10m 0s (- 58m 15s) (11000 14%) 5.6630\n","10m 58s (- 57m 37s) (12000 16%) 5.6562\n","11m 57s (- 56m 59s) (13000 17%) 5.7380\n","12m 54s (- 56m 14s) (14000 18%) 5.7164\n","13m 50s (- 55m 20s) (15000 20%) 5.5965\n","14m 47s (- 54m 31s) (16000 21%) 5.7372\n","15m 44s (- 53m 41s) (17000 22%) 5.6531\n","16m 41s (- 52m 52s) (18000 24%) 5.6006\n","17m 38s (- 51m 58s) (19000 25%) 5.5936\n","18m 35s (- 51m 6s) (20000 26%) 5.5754\n","19m 32s (- 50m 14s) (21000 28%) 5.5752\n","20m 28s (- 49m 20s) (22000 29%) 5.6043\n","21m 26s (- 48m 27s) (23000 30%) 5.5535\n","22m 24s (- 47m 36s) (24000 32%) 5.5608\n","23m 20s (- 46m 40s) (25000 33%) 5.6128\n","24m 18s (- 45m 48s) (26000 34%) 5.5817\n","25m 14s (- 44m 51s) (27000 36%) 5.4783\n","26m 12s (- 43m 59s) (28000 37%) 5.5083\n","27m 10s (- 43m 5s) (29000 38%) 5.4959\n","28m 9s (- 42m 14s) (30000 40%) 5.5196\n","29m 6s (- 41m 18s) (31000 41%) 5.4809\n","30m 4s (- 40m 24s) (32000 42%) 5.4540\n","31m 1s (- 39m 29s) (33000 44%) 5.5071\n","31m 59s (- 38m 34s) (34000 45%) 5.4837\n","32m 56s (- 37m 39s) (35000 46%) 5.4847\n","33m 54s (- 36m 44s) (36000 48%) 5.4794\n","34m 52s (- 35m 49s) (37000 49%) 5.4711\n","35m 50s (- 34m 54s) (38000 50%) 5.4274\n","36m 48s (- 33m 58s) (39000 52%) 5.4776\n","37m 46s (- 33m 3s) (40000 53%) 5.4656\n","38m 46s (- 32m 9s) (41000 54%) 5.4582\n","39m 44s (- 31m 13s) (42000 56%) 5.3833\n","40m 43s (- 30m 18s) (43000 57%) 5.3854\n","41m 41s (- 29m 22s) (44000 58%) 5.3810\n","42m 39s (- 28m 26s) (45000 60%) 5.4016\n","43m 35s (- 27m 28s) (46000 61%) 5.3518\n","44m 33s (- 26m 32s) (47000 62%) 5.3385\n","45m 32s (- 25m 36s) (48000 64%) 5.4163\n","46m 30s (- 24m 40s) (49000 65%) 5.3226\n","47m 27s (- 23m 43s) (50000 66%) 5.3256\n","48m 25s (- 22m 47s) (51000 68%) 5.3530\n","49m 24s (- 21m 51s) (52000 69%) 5.4027\n","50m 21s (- 20m 54s) (53000 70%) 5.2905\n","51m 19s (- 19m 57s) (54000 72%) 5.2865\n","52m 16s (- 19m 0s) (55000 73%) 5.2496\n","53m 13s (- 18m 3s) (56000 74%) 5.3109\n","54m 9s (- 17m 6s) (57000 76%) 5.2375\n","55m 9s (- 16m 9s) (58000 77%) 5.3586\n","56m 5s (- 15m 12s) (59000 78%) 5.2570\n","57m 2s (- 14m 15s) (60000 80%) 5.2167\n","58m 1s (- 13m 19s) (61000 81%) 5.2987\n","58m 59s (- 12m 22s) (62000 82%) 5.2209\n","59m 58s (- 11m 25s) (63000 84%) 5.3363\n","60m 55s (- 10m 28s) (64000 85%) 5.3033\n","61m 51s (- 9m 31s) (65000 86%) 5.2505\n","62m 51s (- 8m 34s) (66000 88%) 5.2506\n","63m 49s (- 7m 37s) (67000 89%) 5.2451\n","64m 45s (- 6m 39s) (68000 90%) 5.2074\n","65m 43s (- 5m 42s) (69000 92%) 5.2525\n","66m 43s (- 4m 45s) (70000 93%) 5.2774\n","67m 42s (- 3m 48s) (71000 94%) 5.2784\n","68m 39s (- 2m 51s) (72000 96%) 5.2138\n","69m 36s (- 1m 54s) (73000 97%) 5.2014\n","70m 35s (- 0m 57s) (74000 98%) 5.2954\n","71m 32s (- 0m 0s) (75000 100%) 5.1270\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","37000\n","38000\n","39000\n","40000\n","Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are  [0.22650412549264434, 0.0774194112769792, 0.027218258463597083]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"34QQDEirydMQ"},"source":["###Fold 4"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"zCnOu5OXyPVu"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 200\r\n","# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN4(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN4, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\r\n","        ##################\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        x=self.fc(hidden)\r\n","        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\r\n","            #################################\r\n","       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        \r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang4, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang4, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs4))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"avak6eD9yXww"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang4, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang4.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang4, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang4.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang4.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs4)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs4:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs4:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"rVOKFdzNyYXX","outputId":"c4e25c0f-39d3-4666-f237-66a2839526e9"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang4.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang4.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0m 58s (- 72m 16s) (1000 1%) 6.1812\n","1m 52s (- 68m 12s) (2000 2%) 5.7121\n","2m 44s (- 65m 48s) (3000 4%) 5.5706\n","3m 37s (- 64m 18s) (4000 5%) 5.4962\n","4m 29s (- 62m 58s) (5000 6%) 5.4948\n","5m 22s (- 61m 45s) (6000 8%) 5.2995\n","6m 15s (- 60m 51s) (7000 9%) 5.4453\n","7m 9s (- 59m 53s) (8000 10%) 5.4433\n","8m 4s (- 59m 10s) (9000 12%) 5.4502\n","8m 58s (- 58m 20s) (10000 13%) 5.4455\n","9m 55s (- 57m 47s) (11000 14%) 5.5792\n","10m 51s (- 57m 1s) (12000 16%) 5.6614\n","11m 48s (- 56m 18s) (13000 17%) 5.6035\n","12m 44s (- 55m 29s) (14000 18%) 5.6108\n","13m 40s (- 54m 40s) (15000 20%) 5.6326\n","14m 36s (- 53m 52s) (16000 21%) 5.6429\n","15m 33s (- 53m 4s) (17000 22%) 5.6567\n","16m 32s (- 52m 21s) (18000 24%) 5.6907\n","17m 29s (- 51m 32s) (19000 25%) 5.5657\n","18m 26s (- 50m 43s) (20000 26%) 5.6234\n","19m 25s (- 49m 57s) (21000 28%) 5.5402\n","20m 23s (- 49m 7s) (22000 29%) 5.5999\n","21m 21s (- 48m 17s) (23000 30%) 5.5874\n","22m 21s (- 47m 30s) (24000 32%) 5.6292\n","23m 18s (- 46m 36s) (25000 33%) 5.5445\n","24m 17s (- 45m 47s) (26000 34%) 5.5742\n","25m 14s (- 44m 52s) (27000 36%) 5.4583\n","26m 13s (- 44m 1s) (28000 37%) 5.5129\n","27m 12s (- 43m 9s) (29000 38%) 5.5239\n","28m 9s (- 42m 14s) (30000 40%) 5.4148\n","29m 7s (- 41m 20s) (31000 41%) 5.4808\n","30m 4s (- 40m 25s) (32000 42%) 5.4119\n","31m 1s (- 39m 28s) (33000 44%) 5.4424\n","31m 59s (- 38m 34s) (34000 45%) 5.4966\n","32m 56s (- 37m 38s) (35000 46%) 5.4019\n","33m 54s (- 36m 43s) (36000 48%) 5.4699\n","34m 53s (- 35m 50s) (37000 49%) 5.4903\n","35m 50s (- 34m 54s) (38000 50%) 5.4135\n","36m 47s (- 33m 57s) (39000 52%) 5.4574\n","37m 45s (- 33m 1s) (40000 53%) 5.3660\n","38m 42s (- 32m 5s) (41000 54%) 5.4313\n","39m 40s (- 31m 10s) (42000 56%) 5.3966\n","40m 36s (- 30m 13s) (43000 57%) 5.3918\n","41m 34s (- 29m 17s) (44000 58%) 5.3771\n","42m 32s (- 28m 21s) (45000 60%) 5.3768\n","43m 30s (- 27m 25s) (46000 61%) 5.3981\n","44m 29s (- 26m 30s) (47000 62%) 5.3230\n","45m 28s (- 25m 34s) (48000 64%) 5.3062\n","46m 26s (- 24m 38s) (49000 65%) 5.3561\n","47m 25s (- 23m 42s) (50000 66%) 5.3460\n","48m 24s (- 22m 46s) (51000 68%) 5.3721\n","49m 21s (- 21m 49s) (52000 69%) 5.3099\n","50m 19s (- 20m 53s) (53000 70%) 5.2833\n","51m 15s (- 19m 56s) (54000 72%) 5.2818\n","52m 14s (- 18m 59s) (55000 73%) 5.3436\n","53m 11s (- 18m 2s) (56000 74%) 5.2810\n","54m 9s (- 17m 6s) (57000 76%) 5.6634\n","55m 5s (- 16m 8s) (58000 77%) 6.6501\n","55m 59s (- 15m 11s) (59000 78%) 7.1171\n","56m 53s (- 14m 13s) (60000 80%) 6.9932\n","57m 48s (- 13m 16s) (61000 81%) 7.2719\n","58m 42s (- 12m 18s) (62000 82%) 6.8810\n","59m 38s (- 11m 21s) (63000 84%) 7.1941\n","60m 31s (- 10m 24s) (64000 85%) 6.9441\n","61m 26s (- 9m 27s) (65000 86%) 8.0257\n","62m 22s (- 8m 30s) (66000 88%) 8.1609\n","63m 16s (- 7m 33s) (67000 89%) 7.8818\n","64m 13s (- 6m 36s) (68000 90%) 8.8167\n","65m 13s (- 5m 40s) (69000 92%) 11.7800\n","66m 12s (- 4m 43s) (70000 93%) 11.2089\n","67m 8s (- 3m 46s) (71000 94%) 10.0319\n","68m 5s (- 2m 50s) (72000 96%) 9.5585\n","69m 0s (- 1m 53s) (73000 97%) 8.6690\n","69m 54s (- 0m 56s) (74000 98%) 8.5466\n","70m 49s (- 0m 0s) (75000 100%) 8.7377\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","37000\n","38000\n","39000\n","40000\n","Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are  [0.009836392605991232, 0.0006573894378418107, 0.00012379163322210888]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DtGbDe1GzSK9"},"source":["###Fold 5"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"rM5o8g5vzQE7"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 200\r\n","# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN4(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN4, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\r\n","        ##################\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        x=self.fc(hidden)\r\n","        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\r\n","            #################################\r\n","       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        \r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","        \r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang5, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang5, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs5))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"JP78TY53zYHd"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang5, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang5.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang5, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang5.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang5.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs5)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs5:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs5:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"6u-YKVdSzaVV","outputId":"011fb820-f2cf-4993-a9dc-b9abf51ee6cc"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang5.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang5.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0m 58s (- 72m 18s) (1000 1%) 6.1012\n","1m 51s (- 67m 40s) (2000 2%) 5.6204\n","2m 43s (- 65m 33s) (3000 4%) 5.5007\n","3m 36s (- 64m 7s) (4000 5%) 5.5144\n","4m 29s (- 62m 54s) (5000 6%) 5.3319\n","5m 23s (- 61m 56s) (6000 8%) 5.5086\n","6m 18s (- 61m 18s) (7000 9%) 5.5308\n","7m 14s (- 60m 37s) (8000 10%) 5.6774\n","8m 8s (- 59m 44s) (9000 12%) 5.5234\n","9m 3s (- 58m 50s) (10000 13%) 5.5153\n","9m 58s (- 58m 1s) (11000 14%) 5.5618\n","10m 54s (- 57m 16s) (12000 16%) 5.5501\n","11m 52s (- 56m 38s) (13000 17%) 5.6719\n","12m 49s (- 55m 53s) (14000 18%) 5.6326\n","13m 47s (- 55m 10s) (15000 20%) 5.6881\n","14m 44s (- 54m 22s) (16000 21%) 5.6208\n","15m 43s (- 53m 38s) (17000 22%) 5.6530\n","16m 39s (- 52m 44s) (18000 24%) 5.5310\n","17m 35s (- 51m 51s) (19000 25%) 5.5662\n","18m 32s (- 50m 59s) (20000 26%) 5.6100\n","19m 29s (- 50m 8s) (21000 28%) 5.5696\n","20m 26s (- 49m 14s) (22000 29%) 5.5893\n","21m 23s (- 48m 21s) (23000 30%) 5.5570\n","22m 22s (- 47m 32s) (24000 32%) 5.5644\n","23m 20s (- 46m 41s) (25000 33%) 5.5261\n","24m 17s (- 45m 47s) (26000 34%) 5.4535\n","25m 15s (- 44m 55s) (27000 36%) 5.5153\n","26m 15s (- 44m 5s) (28000 37%) 5.5198\n","27m 13s (- 43m 11s) (29000 38%) 5.4310\n","28m 11s (- 42m 17s) (30000 40%) 5.4602\n","29m 9s (- 41m 22s) (31000 41%) 5.4586\n","30m 5s (- 40m 26s) (32000 42%) 5.3938\n","31m 1s (- 39m 28s) (33000 44%) 5.4617\n","31m 59s (- 38m 35s) (34000 45%) 5.4600\n","32m 58s (- 37m 40s) (35000 46%) 5.4053\n","33m 55s (- 36m 44s) (36000 48%) 5.4242\n","34m 53s (- 35m 49s) (37000 49%) 5.4519\n","35m 50s (- 34m 54s) (38000 50%) 5.4123\n","36m 49s (- 33m 59s) (39000 52%) 5.4538\n","37m 47s (- 33m 4s) (40000 53%) 5.4802\n","38m 46s (- 32m 9s) (41000 54%) 5.4462\n","39m 44s (- 31m 13s) (42000 56%) 5.4361\n","40m 41s (- 30m 17s) (43000 57%) 5.3984\n","41m 39s (- 29m 21s) (44000 58%) 5.3829\n","42m 39s (- 28m 26s) (45000 60%) 5.4051\n","43m 36s (- 27m 29s) (46000 61%) 5.3710\n","44m 35s (- 26m 33s) (47000 62%) 5.4053\n","45m 33s (- 25m 37s) (48000 64%) 5.3505\n","46m 32s (- 24m 41s) (49000 65%) 5.3550\n","47m 29s (- 23m 44s) (50000 66%) 5.3392\n","48m 28s (- 22m 48s) (51000 68%) 5.3108\n","49m 27s (- 21m 52s) (52000 69%) 5.3042\n","50m 25s (- 20m 55s) (53000 70%) 5.3009\n","51m 23s (- 19m 59s) (54000 72%) 5.3218\n","52m 20s (- 19m 1s) (55000 73%) 5.2882\n","53m 18s (- 18m 5s) (56000 74%) 5.3411\n","54m 17s (- 17m 8s) (57000 76%) 5.3269\n","55m 15s (- 16m 11s) (58000 77%) 5.2919\n","56m 12s (- 15m 14s) (59000 78%) 5.2286\n","57m 11s (- 14m 17s) (60000 80%) 5.2242\n","58m 9s (- 13m 20s) (61000 81%) 5.2711\n","59m 5s (- 12m 23s) (62000 82%) 5.2425\n","60m 4s (- 11m 26s) (63000 84%) 5.2800\n","61m 1s (- 10m 29s) (64000 85%) 5.1373\n","61m 59s (- 9m 32s) (65000 86%) 5.2393\n","62m 57s (- 8m 35s) (66000 88%) 5.2535\n","63m 55s (- 7m 37s) (67000 89%) 5.2241\n","64m 53s (- 6m 40s) (68000 90%) 5.2010\n","65m 52s (- 5m 43s) (69000 92%) 5.2210\n","66m 48s (- 4m 46s) (70000 93%) 5.2241\n","67m 46s (- 3m 49s) (71000 94%) 5.2387\n","68m 44s (- 2m 51s) (72000 96%) 5.2254\n","69m 44s (- 1m 54s) (73000 97%) 5.2056\n","70m 43s (- 0m 57s) (74000 98%) 5.2756\n","71m 42s (- 0m 0s) (75000 100%) 5.2433\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","37000\n","38000\n","39000\n","40000\n","Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are  [0.1849942922049184, 0.057387181158475936, 0.01890457629991385]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-FZN-rDe4xIF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615687289606,"user_tz":-480,"elapsed":866,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"51dc4a20-6010-45f0-a1fc-5a1836cd7a08"},"source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["> die hochrangigen gesprache deren gastgeber der agyptische geheimdienstchef omar suleiman ist sind von zentraler bedeutung fur die beendigung der blutigen schon fast zwei jahre wahrenden konfrontation zwischen dem von der hamas beherrschten gaza und dem von der fatah kontrollierten westjordanland wo der vom westen unterstutzte mahmoud abbas regiert .\n","= the top level talks hosted by egyptian intelligence chief omar suleiman will be crucial to ending nearly two years of bloody confrontation between hamas ruled gaza and the fatah ruled west bank governed by western backed mahmoud abbas .\n","< the the the of the the the of the the the of the the and the the the the the the the the the the the the the the the the . the the the the . the the the . the the the . the the . the the . the the . the <EOS>\n","\n","> aus umweltgrunden und zur reduzierung externer abhangigkeit hat sich dort die energieeffizienz durch eine kombination von steuern hoheren konsumentenpreisen und besserer ausbildung verbessert .\n","= for security and environmental reasons their energy efficiency increased via a combination of taxes higher consumer prices and public education .\n","< a the the and a the the and a the the and a the the and a the the and a the the and the to . the . of <EOS>\n","\n",">  amp amp amp amp amp amp amp die indische stadt delhi fuhrt derzeit neue umweltfreundliche busse ein die mit flussiggas betrieben werden . dies schafft zusatzliche . neue arbeitsplatze .\n","=  the indian city of delhi is introducing new eco friendly compressed natural gas buses which will create an additional new jobs .\n","<  a the a the a the the a the the new the . the the . the . the . the . the <EOS>\n","\n","> zum ersten mal in meinem leben musste ich als ich am sonntag mit meinen kindern zu wahl ging in einer friedlichen feier jener sakularen religion die eine gut funktionierende demokratie darstellt relativ lange geduldig anstehen .\n","= for the first time in my lifetime as i went to vote on sunday with my children in a peaceful celebration of that secular religion that is democracy when it works well i had to wait in line patiently for a relatively long time .\n","< i a a the to the to the to the to the the to the to the to the a the to the to the . of . the . the . the . <EOS>\n","\n","> der scheidende chefokonom des iwf ken rogoff warnt dass die uberschusse die globale stabilitat gefahrden .\n","= the imf s departing chief economist ken rogoff warns that the surpluses put global stability at risk .\n","< the imf s the the the the the the the the the the the the the the . the <EOS>\n","\n","> der solide anstieg der festanstellungen zu anfang des jahres loste allgemein zuversicht aus .\n","= solid increases in payroll employment at the start of the year contributed to a general sense of confidence .\n","< the s of of the of to the of to the of . of . the . of . . the <EOS>\n","\n","> die asiatischen wirtschaften wachsen kraftig und sammeln in ihren zentralbanken forderungen an die usa an .\n","= asian economies are growing vigorously and their central banks are building up claims on the us .\n","< the us and the the the and the the and a the the the and the the to the and <EOS>\n","\n","> uberdies konnen einfache hochrechnungen des wirtschaftswachstums irrefuhrend sein .\n","= moreover simple projections of economic growth trends can mislead .\n","< moreover the can be the the <EOS>\n","\n","> das land schloss au erdem die halfte der uberschussigen krankenhauser und kundigte uberflussigen lehrern vor der krise kam auf sechs kinder ein lehrer .\n","= it also closed half of its excessive number of hospitals and sacked superfluous teachers of which there was one for every six children before the crisis .\n","< the the and a the the the the the and the the the the and a the the the the and the the the <EOS>\n","\n","> zudem gibt es zwei wichtige geopolitische unsicherheiten .\n","= there are two major geopolitical uncertainties as well .\n","< there are two two <EOS>\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OehAhG08d4dt"},"source":[""],"execution_count":null,"outputs":[]}]}