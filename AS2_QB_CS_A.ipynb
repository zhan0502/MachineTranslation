{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17823,
     "status": "ok",
     "timestamp": 1615687752919,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "uT-lrh1Xe3ry",
    "outputId": "c692211b-066b-4a90-fe37-c832c2bb8833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive/AI Sem II/NLP/A2\n",
      "/content/gdrive/My Drive/AI Sem II/NLP/A2\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "if 'google.colab' in sys.modules:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  path_to_file = '/content/gdrive/My Drive/AI Sem II/NLP/A2'\n",
    "  print(path_to_file)\n",
    "  os.chdir(path_to_file)\n",
    "  !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUm8xUsPjECA"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22954,
     "status": "ok",
     "timestamp": 1615687758062,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "hjR9yaPeIEDs",
    "outputId": "59e1fddb-cfdb-4e50-b232-1a63552cd1d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146549, 146549)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cs = 'data/training/news-commentary-v9.cs-en.cs'\n",
    "data_en = 'data/training/news-commentary-v9.cs-en.en'\n",
    "\n",
    "with open(data_cs, 'rb') as cs: \n",
    "  sents_cs = [line.decode(\"utf-8\") for line in cs]      \n",
    " # sents_cs = [value for value in sents_cs if value != '']   \n",
    "with open(data_en, 'rb') as en: \n",
    "  sents_en = [line.decode(\"utf-8\") for line in en]\n",
    " # sents_en = [value for value in sents_en if value != '']\n",
    "len(sents_en), len(sents_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22949,
     "status": "ok",
     "timestamp": 1615687758063,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "08DjJdxvxuAW",
    "outputId": "12bb88b5-d99d-4ea3-d808-1d22b0019b7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max length of string \n",
    "length_cs = [len(i.split()) for i in sents_cs]\n",
    "max(length_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23313,
     "status": "ok",
     "timestamp": 1615687758433,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "KrrJEeffxuEB",
    "outputId": "fcb05cbc-ccf5-458b-b94c-bba32ea78dc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_en = [len(i.split()) for i in sents_en]\n",
    "max(length_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXnu1aePaT6s"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "  def __init__(self, name):\n",
    "    self.name = name\n",
    "    self.word2index = {}\n",
    "    self.word2count = {}\n",
    "    self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "    self.n_words = 2\n",
    "\n",
    "  def addSentence(self, sentence):\n",
    "    \n",
    "    for word in sentence.split(' '):\n",
    "      self.addWord(word)\n",
    "  \n",
    "  def addWord(self, word):\n",
    "    if word not in self.word2index:\n",
    "      self.word2index[word] = self.n_words\n",
    "      self.word2count[word] = 1\n",
    "      self.index2word[self.n_words] = word \n",
    "      self.n_words += 1\n",
    "    else:\n",
    "      self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaTNz04wdqKa"
   },
   "outputs": [],
   "source": [
    "def sent_pairs(lang1=sents_cs, lang2=sents_en):\n",
    "  pairs = []\n",
    "  for i, (cs_sent, en_sent) in enumerate(zip(lang1, lang2)):\n",
    "    #if i < 100:\n",
    "      pairs.append([cs_sent, en_sent])\n",
    "   # print(i)\n",
    "  pairs = [[normalizeString(s) for s in line] for line in pairs]\n",
    "  input_lang1 = Lang('cs')\n",
    "  output_lang1 = Lang('en')\n",
    "\n",
    "  input_lang2 = Lang('cs')\n",
    "  output_lang2 = Lang('en')\n",
    "\n",
    "  input_lang3 = Lang('cs')\n",
    "  output_lang3 = Lang('en')\n",
    "\n",
    "  input_lang4 = Lang('cs')\n",
    "  output_lang4 = Lang('en')\n",
    "\n",
    "  input_lang5 = Lang('cs')\n",
    "  output_lang5 = Lang('en')\n",
    "\n",
    "     \n",
    "  return input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvQxz_O6IMm8"
   },
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "-  Read text file and split into lines, split lines into pairs\n",
    "-  Normalize text, filter by length and content\n",
    "-  Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49701,
     "status": "ok",
     "timestamp": 1615687784834,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "-ll3A_tPrdF8",
    "outputId": "606d301b-7530-4969-d6f7-c1939852bdac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 146549 sentence pairs\n",
      "Number of test pairs: 29309\n",
      "Number of train pairs: 117240\n",
      "Counting words...\n",
      "Counted words:\n",
      "cs 116368\n",
      "en 39131\n",
      "Number of train pairs: 117240\n",
      "Counting words...\n",
      "Counted words:\n",
      "cs 116383\n",
      "en 39093\n",
      "Number of train pairs: 117240\n",
      "Counting words...\n",
      "Counted words:\n",
      "cs 116290\n",
      "en 39170\n",
      "Number of train pairs: 117240\n",
      "Counting words...\n",
      "Counted words:\n",
      "cs 116345\n",
      "en 39130\n",
      "Number of train pairs: 117236\n",
      "Counting words...\n",
      "Counted words:\n",
      "cs 116262\n",
      "en 38952\n",
      "['ma li dnesni uverove zadrhnuti nejake historicke paralely pak jde spise o normalni krize z let nebo .', 'if today s credit crunch has historical parallels they are closer to nineteenth century normal crises like or .']\n",
      "['rozsahla ofenziva vice nez vojaku by se pak stala presvedcivou nezbytnosti jez by politicky ospravedlnila stovky obeti ktere by si vyzadala .', 'that would make a large scale offensive by more than soldiers a compelling necessity justifying politically the hundreds of casualties it would have cost .']\n",
      "['ma li nam vsak byt voditkem historie ani prisnejsi sankce nemusi stacit na to aby vladce iranu presvedcily ze je treba jednat konstruktivne a akceptovat rozumne meze jejich jadernych snah .', 'but if history is a guide even strong sanctions may not be enough to persuade iran s rulers to negotiate constructively and accept meaningful constraints on their nuclear activities .']\n",
      "['bolivijci moralesovy kroky siroce podporuji nebot takzvane privatizace neboli kapitalizace provadene za vlady byvaleho prezidenta gonzala goniho sancheze de lozady chapou jako zlodejnu bolivie ziskala pouhych vynosu !', 'morales actions are widely supported by bolivians who see the so called privatizations or capitalizations under former president gonzalo goni sanchez de lozada as a rip off bolivia received only of the proceeds !']\n",
      "['deset let vyzkumu pripadnych zdravotnich ucinku jedne tridy nanomaterialu na bazi uhliku znamych jako fullereny prinasi zpravu ze molekuly fullerenu tvarem pripominajici fotbalove mice a zname jako buckybally jsou ucinne antioxidanty silou srovnatelne s vitaminem e . jine studie uvadeji ze buckybally mohou byt toxicke pro nadorove bunky .', 'for example ten years of studies of the possible health effects of a class of carbon based nanomaterials known as fullerenes report that the soccer ball shaped fullerene molecules known as buckyballs are powerful antioxidants comparable in strength to vitamin e . other studies report that some types of buckyballs can be toxic to tumor cells .']\n"
     ]
    }
   ],
   "source": [
    " def prepareData(lang1=sents_cs, lang2=sents_en):\n",
    "    input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs = sent_pairs(lang1, lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    #Assumption: as the dataset is news commentary on different topics, there is highly unlikely exactly the same sentences \n",
    "    # collect test pairs\n",
    "    num_test = int(len(pairs)*0.2)\n",
    "    print(\"Number of test pairs:\", num_test)\n",
    "    random.seed(1)\n",
    "    random.shuffle(pairs)\n",
    "    \n",
    "    #fold 1\n",
    "    test_pairs1 = pairs[:num_test]\n",
    "     # collect train pairs\n",
    "    train_pairs1 = pairs[num_test:]\n",
    "    print(\"Number of train pairs:\", len(train_pairs1))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "    for pair in train_pairs1:      \n",
    "      input_lang1.addSentence(pair[0])\n",
    "      output_lang1.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang1.name, input_lang1.n_words)\n",
    "    print(output_lang1.name, output_lang1.n_words)\n",
    "\n",
    "    #fold 2\n",
    "    test_pairs2 = pairs[num_test:num_test*2]\n",
    "     # collect train pairs\n",
    "    train_pairs2 = pairs[:num_test]\n",
    "    for x in pairs[num_test*2:]:\n",
    "      train_pairs2.append(x)\n",
    "    print(\"Number of train pairs:\", len(train_pairs2))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs2:      \n",
    "      input_lang2.addSentence(pair[0])\n",
    "      output_lang2.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang2.name, input_lang2.n_words)\n",
    "    print(output_lang2.name, output_lang2.n_words)\n",
    "\n",
    "    #fold 3\n",
    "    test_pairs3 = pairs[num_test*2:num_test*3]\n",
    "     # collect train pairs\n",
    "    train_pairs3 = pairs[:num_test*2]\n",
    "    for x in pairs[num_test*3:]:\n",
    "      train_pairs3.append(x)\n",
    "    print(\"Number of train pairs:\", len(train_pairs3))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs3:      \n",
    "      input_lang3.addSentence(pair[0])\n",
    "      output_lang3.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang3.name, input_lang3.n_words)\n",
    "    print(output_lang3.name, output_lang3.n_words)\n",
    "\n",
    "\n",
    "    #fold 4\n",
    "    test_pairs4 = pairs[num_test*3:num_test*4]\n",
    "     # collect train pairs\n",
    "    train_pairs4 = pairs[:num_test*3]\n",
    "    for x in pairs[num_test*4:]:\n",
    "      train_pairs4.append(x)\n",
    "    print(\"Number of train pairs:\", len(train_pairs4))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs4:      \n",
    "      input_lang4.addSentence(pair[0])\n",
    "      output_lang4.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang4.name, input_lang4.n_words)\n",
    "    print(output_lang4.name, output_lang4.n_words)\n",
    "\n",
    "    #fold 5\n",
    "    test_pairs5 = pairs[num_test*4:]\n",
    "     # collect train pairs\n",
    "    train_pairs5 = pairs[:num_test*4]\n",
    "    print(\"Number of train pairs:\", len(train_pairs5))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs5:      \n",
    "      input_lang5.addSentence(pair[0])\n",
    "      output_lang5.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang5.name, input_lang5.n_words)\n",
    "    print(output_lang5.name, output_lang5.n_words)\n",
    "\n",
    "\n",
    "    return (input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4,input_lang5, output_lang5,train_pairs1, \n",
    "            test_pairs1, train_pairs2, test_pairs2, train_pairs3, test_pairs3,train_pairs4, test_pairs4,train_pairs5, test_pairs5)\n",
    "\n",
    "\n",
    "(input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, train_pairs1, test_pairs1, train_pairs2,\n",
    " test_pairs2,train_pairs3, test_pairs3, train_pairs4, test_pairs4,train_pairs5, test_pairs5) = prepareData(sents_cs, sents_en)\n",
    "print(random.choice(train_pairs1))\n",
    "print(random.choice(train_pairs2))\n",
    "print(random.choice(train_pairs3))\n",
    "print(random.choice(train_pairs4))\n",
    "print(random.choice(train_pairs5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npNTNDUOOwoC"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 164\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        \n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang1, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang1, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs1))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjoCFY3nTmBG"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang1, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang1.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang1, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang1.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang1.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs1)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs1:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs1:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5173376,
     "status": "ok",
     "timestamp": 1615692908520,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "08M4DvfPToJk",
    "outputId": "c5bf3a1f-e1fa-4c6c-dfca-d7515c2e2ec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 58s (- 72m 45s) (1000 1%) 6.1088\n",
      "1m 52s (- 68m 43s) (2000 2%) 5.7441\n",
      "2m 46s (- 66m 33s) (3000 4%) 5.6047\n",
      "3m 38s (- 64m 46s) (4000 5%) 5.4433\n",
      "4m 33s (- 63m 42s) (5000 6%) 5.4516\n",
      "5m 26s (- 62m 39s) (6000 8%) 5.4673\n",
      "6m 20s (- 61m 32s) (7000 9%) 5.4069\n",
      "7m 13s (- 60m 31s) (8000 10%) 5.4048\n",
      "8m 8s (- 59m 45s) (9000 12%) 5.5605\n",
      "9m 6s (- 59m 11s) (10000 13%) 5.6930\n",
      "10m 5s (- 58m 41s) (11000 14%) 5.7403\n",
      "11m 3s (- 58m 4s) (12000 16%) 5.6494\n",
      "12m 2s (- 57m 27s) (13000 17%) 5.6953\n",
      "13m 0s (- 56m 40s) (14000 18%) 5.7097\n",
      "13m 58s (- 55m 54s) (15000 20%) 5.6785\n",
      "14m 57s (- 55m 10s) (16000 21%) 5.6633\n",
      "15m 57s (- 54m 28s) (17000 22%) 5.6404\n",
      "16m 55s (- 53m 36s) (18000 24%) 5.6110\n",
      "17m 53s (- 52m 43s) (19000 25%) 5.6032\n",
      "18m 51s (- 51m 51s) (20000 26%) 5.6245\n",
      "19m 49s (- 50m 59s) (21000 28%) 5.6526\n",
      "20m 49s (- 50m 9s) (22000 29%) 5.6712\n",
      "21m 48s (- 49m 19s) (23000 30%) 5.6250\n",
      "22m 48s (- 48m 27s) (24000 32%) 5.5882\n",
      "23m 47s (- 47m 35s) (25000 33%) 5.6218\n",
      "24m 47s (- 46m 43s) (26000 34%) 5.5826\n",
      "25m 46s (- 45m 49s) (27000 36%) 5.5418\n",
      "26m 45s (- 44m 55s) (28000 37%) 5.5421\n",
      "27m 44s (- 43m 59s) (29000 38%) 5.5883\n",
      "28m 41s (- 43m 2s) (30000 40%) 5.4986\n",
      "29m 41s (- 42m 8s) (31000 41%) 5.5012\n",
      "30m 41s (- 41m 14s) (32000 42%) 5.5112\n",
      "31m 42s (- 40m 21s) (33000 44%) 5.5329\n",
      "32m 40s (- 39m 24s) (34000 45%) 5.5157\n",
      "33m 40s (- 38m 29s) (35000 46%) 5.4316\n",
      "34m 41s (- 37m 34s) (36000 48%) 5.5226\n",
      "35m 41s (- 36m 39s) (37000 49%) 5.5002\n",
      "36m 41s (- 35m 43s) (38000 50%) 5.5252\n",
      "37m 40s (- 34m 46s) (39000 52%) 5.4629\n",
      "38m 42s (- 33m 52s) (40000 53%) 5.4843\n",
      "39m 42s (- 32m 56s) (41000 54%) 5.4687\n",
      "40m 44s (- 32m 0s) (42000 56%) 5.4482\n",
      "41m 46s (- 31m 5s) (43000 57%) 5.4420\n",
      "42m 44s (- 30m 6s) (44000 58%) 5.4152\n",
      "43m 45s (- 29m 10s) (45000 60%) 5.4030\n",
      "44m 46s (- 28m 13s) (46000 61%) 5.4182\n",
      "45m 46s (- 27m 16s) (47000 62%) 5.3653\n",
      "46m 47s (- 26m 18s) (48000 64%) 5.3503\n",
      "47m 47s (- 25m 21s) (49000 65%) 5.3689\n",
      "48m 49s (- 24m 24s) (50000 66%) 5.4033\n",
      "49m 51s (- 23m 27s) (51000 68%) 5.3579\n",
      "50m 53s (- 22m 30s) (52000 69%) 5.3871\n",
      "51m 55s (- 21m 33s) (53000 70%) 5.3607\n",
      "52m 55s (- 20m 34s) (54000 72%) 5.3227\n",
      "53m 57s (- 19m 37s) (55000 73%) 5.2924\n",
      "54m 56s (- 18m 38s) (56000 74%) 5.2887\n",
      "55m 57s (- 17m 40s) (57000 76%) 5.3247\n",
      "56m 59s (- 16m 42s) (58000 77%) 5.3834\n",
      "58m 0s (- 15m 43s) (59000 78%) 5.3851\n",
      "59m 2s (- 14m 45s) (60000 80%) 5.3132\n",
      "60m 3s (- 13m 47s) (61000 81%) 5.2998\n",
      "61m 3s (- 12m 48s) (62000 82%) 5.2369\n",
      "62m 3s (- 11m 49s) (63000 84%) 5.1944\n",
      "63m 4s (- 10m 50s) (64000 85%) 5.2620\n",
      "64m 4s (- 9m 51s) (65000 86%) 5.3185\n",
      "65m 7s (- 8m 52s) (66000 88%) 5.2848\n",
      "66m 8s (- 7m 53s) (67000 89%) 5.2415\n",
      "67m 8s (- 6m 54s) (68000 90%) 5.1863\n",
      "68m 9s (- 5m 55s) (69000 92%) 5.2405\n",
      "69m 10s (- 4m 56s) (70000 93%) 5.2774\n",
      "70m 11s (- 3m 57s) (71000 94%) 5.2574\n",
      "71m 11s (- 2m 57s) (72000 96%) 5.2392\n",
      "72m 14s (- 1m 58s) (73000 97%) 5.2772\n",
      "73m 15s (- 0m 59s) (74000 98%) 5.2552\n",
      "74m 15s (- 0m 0s) (75000 100%) 5.2875\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are  [0.2279452757853373, 0.07526460685895614, 0.02626717708417253]\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang1.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8X7TtXWDvQCS"
   },
   "source": [
    "###Fold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTgC4HZSt6XD"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 180\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang2, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang2, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs2))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xj4EasFzvVmP"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang2, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang2.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang2, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang2.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang2.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs2)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs2:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs2:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab6RRAYUvcdZ",
    "outputId": "a0dab41e-7045-494d-f6ae-d9650ef99eed"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang2.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang2.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1_JxzKvxF5N"
   },
   "source": [
    "###Fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeLVXQOhxCMM"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 180\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang3, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang3, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs3))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bSwRykXxK_K"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang3, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang3.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang3, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang3.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang3.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs3)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs3:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs3:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDUlbFWuxLFl"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang3.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang3.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34QQDEirydMQ"
   },
   "source": [
    "###Fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCnOu5OXyPVu"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 190\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang4, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang4, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs4))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avak6eD9yXww"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang4, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang4.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang4, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang4.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang4.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs4)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs4:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs4:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVOKFdzNyYXX"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang4.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang4.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtGbDe1GzSK9"
   },
   "source": [
    "###Fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rM5o8g5vzQE7"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 200\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang5, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang5, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs5))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JP78TY53zYHd"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang5, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang5.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang5, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang5.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang5.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs5)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs5:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs5:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6u-YKVdSzaVV"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang5.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang5.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8qMVNHB402u"
   },
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AS2_QB_CS_A.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
