{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27957,
     "status": "ok",
     "timestamp": 1615781285951,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "uT-lrh1Xe3ry",
    "outputId": "b6680498-f770-4940-9e0d-378fbeda4d3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive/AI Sem II/NLP/A2\n",
      "/content/gdrive/My Drive/AI Sem II/NLP/A2\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "if 'google.colab' in sys.modules:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  path_to_file = '/content/gdrive/My Drive/AI Sem II/NLP/A2'\n",
    "  print(path_to_file)\n",
    "  os.chdir(path_to_file)\n",
    "  !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUm8xUsPjECA"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5813,
     "status": "ok",
     "timestamp": 1615781291140,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "hjR9yaPeIEDs",
    "outputId": "210df2a2-d37a-4b0a-ca73-bccbe6c5c34d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201288, 201288)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_de = 'data/training/news-commentary-v9.de-en.de'\n",
    "data_en = 'data/training/news-commentary-v9.de-en.en'\n",
    "\n",
    "with open(data_de, 'rb') as de: \n",
    "  sents_de = [line.decode(\"utf-8\") for line in de]      \n",
    " # sents_cs = [value for value in sents_cs if value != '']   \n",
    "with open(data_en, 'rb') as en: \n",
    "  sents_en = [line.decode(\"utf-8\") for line in en]\n",
    " # sents_en = [value for value in sents_en if value != '']\n",
    "len(sents_en), len(sents_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5441,
     "status": "ok",
     "timestamp": 1615781291145,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "08DjJdxvxuAW",
    "outputId": "586fa9fe-f34d-4b2a-d611-ad73e361c97d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max length of string \n",
    "length_de = [len(i.split()) for i in sents_de]\n",
    "max(length_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3887,
     "status": "ok",
     "timestamp": 1615781291825,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "KrrJEeffxuEB",
    "outputId": "3fb3f773-99f8-43df-f421-582bfa5bbc8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_en = [len(i.split()) for i in sents_en]\n",
    "max(length_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXnu1aePaT6s"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "  def __init__(self, name):\n",
    "    self.name = name\n",
    "    self.word2index = {}\n",
    "    self.word2count = {}\n",
    "    self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "    self.n_words = 2\n",
    "\n",
    "  def addSentence(self, sentence):\n",
    "    \n",
    "    for word in sentence.split(' '):\n",
    "      self.addWord(word)\n",
    "  \n",
    "  def addWord(self, word):\n",
    "    if word not in self.word2index:\n",
    "      self.word2index[word] = self.n_words\n",
    "      self.word2count[word] = 1\n",
    "      self.index2word[self.n_words] = word \n",
    "      self.n_words += 1\n",
    "    else:\n",
    "      self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaTNz04wdqKa"
   },
   "outputs": [],
   "source": [
    "def sent_pairs(lang1=sents_de, lang2=sents_en):\n",
    "  pairs = []\n",
    "  for i, (cs_sent, en_sent) in enumerate(zip(lang1, lang2)):\n",
    "    #if i < 100:\n",
    "      pairs.append([cs_sent, en_sent])\n",
    "   # print(i)\n",
    "  pairs = [[normalizeString(s) for s in line] for line in pairs]\n",
    "  input_lang1 = Lang('de')\n",
    "  output_lang1 = Lang('en')\n",
    "\n",
    "  input_lang2 = Lang('de')\n",
    "  output_lang2 = Lang('en')\n",
    "\n",
    "  input_lang3 = Lang('de')\n",
    "  output_lang3 = Lang('en')\n",
    "\n",
    "  input_lang4 = Lang('de')\n",
    "  output_lang4 = Lang('en')\n",
    "\n",
    "  input_lang5 = Lang('de')\n",
    "  output_lang5 = Lang('en')\n",
    "\n",
    "     \n",
    "  return input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvQxz_O6IMm8"
   },
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "-  Read text file and split into lines, split lines into pairs\n",
    "-  Normalize text, filter by length and content\n",
    "-  Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35307,
     "status": "ok",
     "timestamp": 1615781328309,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "-ll3A_tPrdF8",
    "outputId": "86799d70-aea9-4b0b-e87a-17bce2f0573b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 201288 sentence pairs\n",
      "Number of test pairs: 40257\n",
      "Number of train pairs: 161031\n",
      "Counting words...\n",
      "Counted words:\n",
      "de 119299\n",
      "en 44724\n",
      "Number of train pairs: 161031\n",
      "Counting words...\n",
      "Counted words:\n",
      "de 119369\n",
      "en 44741\n",
      "Number of train pairs: 161031\n",
      "Counting words...\n",
      "Counted words:\n",
      "de 119648\n",
      "en 44762\n",
      "Number of train pairs: 161031\n",
      "Counting words...\n",
      "Counted words:\n",
      "de 119505\n",
      "en 44759\n",
      "Number of train pairs: 161028\n",
      "Counting words...\n",
      "Counted words:\n",
      "de 119517\n",
      "en 44794\n",
      "['stattdessen ist ein funftel des menschlichen genoms jetzt mit privaten patenten belegt das bedeutet dass sich patienten keine tests fur krebserzeugende gene leisten konnen und wissenschaftler keine fortschritte erzielen konnen wenn ein anderes team die patente auf die gene besitzt die sie untersuchen wollen .', 'instead one fifth of the human genome is now subject to private patents meaning that patients can t afford tests for genes that cause cancer and researchers can t make progress if another team owns the patents on the genes that they want to study .']\n",
      "['man konnte der offentlichen universalbibliothek gestatten sogar werke die noch im druck sind und deren urheberrecht noch nicht abgelaufen ist zu digitalisieren im austausch gegen an die verlage und autoren gezahlte gebuhren die auf der haufigkeit mit der die digitale version gelesen wird beruhen .', 'the universal public library could be allowed to digitize even works that are in print and in copyright in exchange for fees paid to the publisher and author based on the number of times the digital version is read .']\n",
      "['oppositionelle gruppen in syrien betteln um die art von waffen mit denen flugzeuge von prasident baschar al assad bekampft und mit denen schwer erkampfte gebiete verteidigt werden konnen mit denen die sicherheit der zivilbevolkerung gewahrleistet werden kann und die assad signalisieren dass die welt nicht untatig danebensteht wahrend er alles daran setzt sein eigenes volk zu bezwingen .', 'syrian opposition groups beg for the kinds of weapons needed to fight president bashar al assad s planes defend hard won territory provide safety for civilians and signal to assad that the world will not stand by as he does whatever it takes to subdue his own people .']\n",
      "['die welt gema xi', 'the world according to xi']\n",
      "['dennoch ist chancengleichheit im hinblick auf den zugang zu bildung ein womoglich unwahrscheinliches ideal .', 'but equal access is probably an unlikely ideal .']\n"
     ]
    }
   ],
   "source": [
    " def prepareData(lang1=sents_de, lang2=sents_en):\n",
    "    input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs = sent_pairs(lang1, lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    #Assumption: as the dataset is news commentary on different topics, there is highly unlikely exactly the same sentences \n",
    "    # collect test pairs\n",
    "    num_test = int(len(pairs)*0.2)\n",
    "    print(\"Number of test pairs:\", num_test)\n",
    "    random.seed(2)\n",
    "    random.shuffle(pairs)\n",
    "    \n",
    "    #fold 1\n",
    "    test_pairs1 = pairs[:num_test]\n",
    "     # collect train pairs\n",
    "    train_pairs1 = pairs[num_test:]\n",
    "    print(\"Number of train pairs:\", len(train_pairs1))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "    for pair in train_pairs1:      \n",
    "      input_lang1.addSentence(pair[0])\n",
    "      output_lang1.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang1.name, input_lang1.n_words)\n",
    "    print(output_lang1.name, output_lang1.n_words)\n",
    "\n",
    "    #fold 2\n",
    "    test_pairs2 = pairs[num_test:num_test*2]\n",
    "     # collect train pairs\n",
    "    train_pairs2 = pairs[:num_test]\n",
    "    for x in pairs[num_test*2:]:\n",
    "      train_pairs2.append(x)\n",
    "    print(\"Number of train pairs:\", len(train_pairs2))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs2:      \n",
    "      input_lang2.addSentence(pair[0])\n",
    "      output_lang2.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang2.name, input_lang2.n_words)\n",
    "    print(output_lang2.name, output_lang2.n_words)\n",
    "\n",
    "    #fold 3\n",
    "    test_pairs3 = pairs[num_test*2:num_test*3]\n",
    "     # collect train pairs\n",
    "    train_pairs3 = pairs[:num_test*2]\n",
    "    for x in pairs[num_test*3:]:\n",
    "      train_pairs3.append(x)\n",
    "    print(\"Number of train pairs:\", len(train_pairs3))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs3:      \n",
    "      input_lang3.addSentence(pair[0])\n",
    "      output_lang3.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang3.name, input_lang3.n_words)\n",
    "    print(output_lang3.name, output_lang3.n_words)\n",
    "\n",
    "\n",
    "    #fold 4\n",
    "    test_pairs4 = pairs[num_test*3:num_test*4]\n",
    "     # collect train pairs\n",
    "    train_pairs4 = pairs[:num_test*3]\n",
    "    for x in pairs[num_test*4:]:\n",
    "      train_pairs4.append(x)\n",
    "    print(\"Number of train pairs:\", len(train_pairs4))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs4:      \n",
    "      input_lang4.addSentence(pair[0])\n",
    "      output_lang4.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang4.name, input_lang4.n_words)\n",
    "    print(output_lang4.name, output_lang4.n_words)\n",
    "\n",
    "    #fold 5\n",
    "    test_pairs5 = pairs[num_test*4:]\n",
    "     # collect train pairs\n",
    "    train_pairs5 = pairs[:num_test*4]\n",
    "    print(\"Number of train pairs:\", len(train_pairs5))\n",
    "    print(\"Counting words...\")\n",
    "\n",
    "\n",
    "    for pair in train_pairs5:      \n",
    "      input_lang5.addSentence(pair[0])\n",
    "      output_lang5.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang5.name, input_lang5.n_words)\n",
    "    print(output_lang5.name, output_lang5.n_words)\n",
    "\n",
    "\n",
    "    return (input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4,input_lang5, output_lang5,train_pairs1, \n",
    "            test_pairs1, train_pairs2, test_pairs2, train_pairs3, test_pairs3,train_pairs4, test_pairs4,train_pairs5, test_pairs5)\n",
    "\n",
    "\n",
    "(input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, train_pairs1, test_pairs1, train_pairs2,\n",
    " test_pairs2,train_pairs3, test_pairs3, train_pairs4, test_pairs4,train_pairs5, test_pairs5) = prepareData(sents_de, sents_en)\n",
    "print(random.choice(train_pairs1))\n",
    "print(random.choice(train_pairs2))\n",
    "print(random.choice(train_pairs3))\n",
    "print(random.choice(train_pairs4))\n",
    "print(random.choice(train_pairs5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npNTNDUOOwoC"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 205\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang1, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang1, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs1))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjoCFY3nTmBG"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang1, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang1.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang1, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang1.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang1.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs1)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs1:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs1:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5539828,
     "status": "ok",
     "timestamp": 1615786841387,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "08M4DvfPToJk",
    "outputId": "1d5f2708-2606-40b8-9d7f-6f8e684d9b51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 0s (- 74m 56s) (1000 1%) 6.2003\n",
      "1m 56s (- 70m 38s) (2000 2%) 5.7427\n",
      "2m 52s (- 68m 55s) (3000 4%) 5.6219\n",
      "3m 46s (- 66m 55s) (4000 5%) 5.5020\n",
      "4m 41s (- 65m 41s) (5000 6%) 5.4756\n",
      "5m 37s (- 64m 41s) (6000 8%) 5.5383\n",
      "6m 34s (- 63m 54s) (7000 9%) 5.4504\n",
      "7m 31s (- 62m 58s) (8000 10%) 5.5067\n",
      "8m 29s (- 62m 12s) (9000 12%) 5.5610\n",
      "9m 25s (- 61m 15s) (10000 13%) 5.6257\n",
      "10m 24s (- 60m 35s) (11000 14%) 5.7123\n",
      "11m 23s (- 59m 47s) (12000 16%) 5.6389\n",
      "12m 23s (- 59m 4s) (13000 17%) 5.6647\n",
      "13m 23s (- 58m 22s) (14000 18%) 5.6502\n",
      "14m 24s (- 57m 37s) (15000 20%) 5.7241\n",
      "15m 24s (- 56m 50s) (16000 21%) 5.6447\n",
      "16m 26s (- 56m 4s) (17000 22%) 5.5932\n",
      "17m 26s (- 55m 15s) (18000 24%) 5.5993\n",
      "18m 26s (- 54m 20s) (19000 25%) 5.5744\n",
      "19m 28s (- 53m 32s) (20000 26%) 5.6018\n",
      "20m 29s (- 52m 42s) (21000 28%) 5.6563\n",
      "21m 31s (- 51m 50s) (22000 29%) 5.6255\n",
      "22m 31s (- 50m 55s) (23000 30%) 5.5570\n",
      "23m 34s (- 50m 5s) (24000 32%) 5.6615\n",
      "24m 33s (- 49m 7s) (25000 33%) 5.5300\n",
      "25m 34s (- 48m 11s) (26000 34%) 5.4896\n",
      "26m 35s (- 47m 16s) (27000 36%) 5.5485\n",
      "27m 36s (- 46m 19s) (28000 37%) 5.5877\n",
      "28m 36s (- 45m 22s) (29000 38%) 5.5262\n",
      "29m 37s (- 44m 25s) (30000 40%) 5.4892\n",
      "30m 37s (- 43m 28s) (31000 41%) 5.5277\n",
      "31m 41s (- 42m 35s) (32000 42%) 5.4902\n",
      "32m 41s (- 41m 36s) (33000 44%) 5.4325\n",
      "33m 41s (- 40m 38s) (34000 45%) 5.4385\n",
      "34m 42s (- 39m 39s) (35000 46%) 5.4544\n",
      "35m 43s (- 38m 42s) (36000 48%) 5.4986\n",
      "36m 43s (- 37m 43s) (37000 49%) 5.4677\n",
      "37m 46s (- 36m 47s) (38000 50%) 5.5076\n",
      "38m 49s (- 35m 50s) (39000 52%) 5.5199\n",
      "39m 49s (- 34m 50s) (40000 53%) 5.3610\n",
      "40m 50s (- 33m 51s) (41000 54%) 5.4411\n",
      "41m 51s (- 32m 53s) (42000 56%) 5.3784\n",
      "42m 53s (- 31m 54s) (43000 57%) 5.3395\n",
      "43m 53s (- 30m 55s) (44000 58%) 5.3398\n",
      "44m 53s (- 29m 55s) (45000 60%) 5.2965\n",
      "45m 52s (- 28m 55s) (46000 61%) 5.3647\n",
      "46m 54s (- 27m 56s) (47000 62%) 5.3920\n",
      "47m 56s (- 26m 58s) (48000 64%) 5.3459\n",
      "48m 57s (- 25m 58s) (49000 65%) 5.3322\n",
      "49m 58s (- 24m 59s) (50000 66%) 5.3724\n",
      "50m 57s (- 23m 58s) (51000 68%) 5.2902\n",
      "51m 58s (- 22m 59s) (52000 69%) 5.2785\n",
      "53m 0s (- 22m 0s) (53000 70%) 5.2326\n",
      "54m 3s (- 21m 1s) (54000 72%) 5.3473\n",
      "55m 6s (- 20m 2s) (55000 73%) 5.3025\n",
      "56m 7s (- 19m 2s) (56000 74%) 5.3423\n",
      "57m 6s (- 18m 2s) (57000 76%) 5.2304\n",
      "58m 8s (- 17m 2s) (58000 77%) 5.3149\n",
      "59m 8s (- 16m 2s) (59000 78%) 5.2000\n",
      "60m 9s (- 15m 2s) (60000 80%) 5.2184\n",
      "61m 11s (- 14m 2s) (61000 81%) 5.2392\n",
      "62m 11s (- 13m 2s) (62000 82%) 5.2034\n",
      "63m 12s (- 12m 2s) (63000 84%) 5.2957\n",
      "64m 14s (- 11m 2s) (64000 85%) 5.2877\n",
      "65m 16s (- 10m 2s) (65000 86%) 5.2080\n",
      "66m 16s (- 9m 2s) (66000 88%) 5.2044\n",
      "67m 16s (- 8m 2s) (67000 89%) 5.1776\n",
      "68m 19s (- 7m 2s) (68000 90%) 5.2205\n",
      "69m 19s (- 6m 1s) (69000 92%) 5.1920\n",
      "70m 20s (- 5m 1s) (70000 93%) 5.2203\n",
      "71m 20s (- 4m 1s) (71000 94%) 5.1894\n",
      "72m 22s (- 3m 0s) (72000 96%) 5.2010\n",
      "73m 23s (- 2m 0s) (73000 97%) 5.2199\n",
      "74m 23s (- 1m 0s) (74000 98%) 5.2606\n",
      "75m 25s (- 0m 0s) (75000 100%) 5.2536\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are  [0.25230932041612397, 0.08599007324843685, 0.03157294070482542]\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang1.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang1.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8X7TtXWDvQCS"
   },
   "source": [
    "###Fold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTgC4HZSt6XD"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 205\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang2, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang2, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs2))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xj4EasFzvVmP"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang2, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang2.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang2, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang2.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang2.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs2)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs2:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs2:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10789598,
     "status": "ok",
     "timestamp": 1615792111061,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "ab6RRAYUvcdZ",
    "outputId": "eda83339-e274-4cf6-8500-5515013cea0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 59s (- 72m 48s) (1000 1%) 6.1650\n",
      "1m 54s (- 69m 33s) (2000 2%) 5.6446\n",
      "2m 49s (- 67m 52s) (3000 4%) 5.4622\n",
      "3m 45s (- 66m 38s) (4000 5%) 5.5261\n",
      "4m 41s (- 65m 45s) (5000 6%) 5.4173\n",
      "5m 40s (- 65m 10s) (6000 8%) 5.5273\n",
      "6m 37s (- 64m 18s) (7000 9%) 5.5262\n",
      "7m 34s (- 63m 24s) (8000 10%) 5.5000\n",
      "8m 30s (- 62m 25s) (9000 12%) 5.3811\n",
      "9m 29s (- 61m 40s) (10000 13%) 5.5639\n",
      "10m 29s (- 61m 3s) (11000 14%) 5.6171\n",
      "11m 29s (- 60m 18s) (12000 16%) 5.6444\n",
      "12m 26s (- 59m 22s) (13000 17%) 5.6005\n",
      "13m 26s (- 58m 35s) (14000 18%) 5.6268\n",
      "14m 27s (- 57m 50s) (15000 20%) 5.6370\n",
      "15m 29s (- 57m 8s) (16000 21%) 5.6602\n",
      "16m 30s (- 56m 18s) (17000 22%) 5.6704\n",
      "17m 30s (- 55m 27s) (18000 24%) 5.5839\n",
      "18m 31s (- 54m 34s) (19000 25%) 5.5902\n",
      "19m 32s (- 53m 45s) (20000 26%) 5.6931\n",
      "20m 34s (- 52m 54s) (21000 28%) 5.6761\n",
      "21m 35s (- 52m 1s) (22000 29%) 5.6435\n",
      "22m 37s (- 51m 8s) (23000 30%) 5.5753\n",
      "23m 37s (- 50m 11s) (24000 32%) 5.5767\n",
      "24m 38s (- 49m 17s) (25000 33%) 5.5188\n",
      "25m 41s (- 48m 24s) (26000 34%) 5.5920\n",
      "26m 41s (- 47m 27s) (27000 36%) 5.4315\n",
      "27m 42s (- 46m 31s) (28000 37%) 5.5415\n",
      "28m 45s (- 45m 36s) (29000 38%) 5.4953\n",
      "29m 46s (- 44m 39s) (30000 40%) 5.4943\n",
      "30m 47s (- 43m 41s) (31000 41%) 5.4891\n",
      "31m 47s (- 42m 43s) (32000 42%) 5.3972\n",
      "32m 48s (- 41m 45s) (33000 44%) 5.3956\n",
      "33m 48s (- 40m 45s) (34000 45%) 5.3954\n",
      "34m 48s (- 39m 46s) (35000 46%) 5.4086\n",
      "35m 49s (- 38m 48s) (36000 48%) 5.4731\n",
      "36m 50s (- 37m 50s) (37000 49%) 5.3672\n",
      "37m 50s (- 36m 50s) (38000 50%) 5.3905\n",
      "38m 50s (- 35m 51s) (39000 52%) 5.3683\n",
      "39m 51s (- 34m 52s) (40000 53%) 5.3721\n",
      "40m 51s (- 33m 53s) (41000 54%) 5.3391\n",
      "41m 54s (- 32m 55s) (42000 56%) 5.3823\n",
      "42m 55s (- 31m 56s) (43000 57%) 5.3768\n",
      "43m 55s (- 30m 56s) (44000 58%) 5.3824\n",
      "44m 56s (- 29m 57s) (45000 60%) 5.3864\n",
      "45m 57s (- 28m 58s) (46000 61%) 5.3698\n",
      "46m 58s (- 27m 59s) (47000 62%) 5.3265\n",
      "47m 59s (- 26m 59s) (48000 64%) 5.3253\n",
      "48m 58s (- 25m 59s) (49000 65%) 5.2593\n",
      "50m 0s (- 25m 0s) (50000 66%) 5.3735\n",
      "51m 1s (- 24m 0s) (51000 68%) 5.2918\n",
      "52m 4s (- 23m 1s) (52000 69%) 5.3123\n",
      "53m 4s (- 22m 1s) (53000 70%) 5.2857\n",
      "54m 5s (- 21m 2s) (54000 72%) 5.3152\n",
      "55m 6s (- 20m 2s) (55000 73%) 5.3025\n",
      "56m 8s (- 19m 2s) (56000 74%) 5.3027\n",
      "57m 9s (- 18m 3s) (57000 76%) 5.2871\n",
      "58m 10s (- 17m 3s) (58000 77%) 5.2287\n",
      "59m 11s (- 16m 3s) (59000 78%) 5.2828\n",
      "60m 12s (- 15m 3s) (60000 80%) 5.2422\n",
      "61m 14s (- 14m 3s) (61000 81%) 5.3186\n",
      "62m 15s (- 13m 3s) (62000 82%) 5.2463\n",
      "63m 14s (- 12m 2s) (63000 84%) 5.2256\n",
      "64m 15s (- 11m 2s) (64000 85%) 5.2345\n",
      "65m 14s (- 10m 2s) (65000 86%) 5.2038\n",
      "66m 14s (- 9m 1s) (66000 88%) 5.2144\n",
      "67m 15s (- 8m 1s) (67000 89%) 5.2321\n",
      "68m 16s (- 7m 1s) (68000 90%) 5.2260\n",
      "69m 16s (- 6m 1s) (69000 92%) 5.1791\n",
      "70m 16s (- 5m 1s) (70000 93%) 5.1708\n",
      "71m 18s (- 4m 1s) (71000 94%) 5.1833\n",
      "72m 19s (- 3m 0s) (72000 96%) 5.1743\n",
      "73m 20s (- 2m 0s) (73000 97%) 5.1832\n",
      "74m 21s (- 1m 0s) (74000 98%) 5.1187\n",
      "75m 20s (- 0m 0s) (75000 100%) 5.1403\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are  [0.19732456050465316, 0.0698534783932649, 0.02622121957290612]\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang2.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang2.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1_JxzKvxF5N"
   },
   "source": [
    "###Fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeLVXQOhxCMM"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 210\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        \n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang3, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang3, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs3))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bSwRykXxK_K"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang3, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang3.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang3, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang3.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang3.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs3)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs3:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs3:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5453154,
     "status": "ok",
     "timestamp": 1615803190757,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "aDUlbFWuxLFl",
    "outputId": "35ade3be-b86d-44ae-fe28-5a7333693527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 1s (- 76m 20s) (1000 1%) 6.1380\n",
      "1m 57s (- 71m 33s) (2000 2%) 5.7217\n",
      "2m 53s (- 69m 33s) (3000 4%) 5.5020\n",
      "3m 50s (- 68m 17s) (4000 5%) 5.4785\n",
      "4m 48s (- 67m 16s) (5000 6%) 5.4562\n",
      "5m 47s (- 66m 32s) (6000 8%) 5.5473\n",
      "6m 43s (- 65m 17s) (7000 9%) 5.4555\n",
      "7m 38s (- 63m 59s) (8000 10%) 5.3468\n",
      "8m 37s (- 63m 12s) (9000 12%) 5.5747\n",
      "9m 37s (- 62m 32s) (10000 13%) 5.6556\n",
      "10m 37s (- 61m 50s) (11000 14%) 5.6372\n",
      "11m 38s (- 61m 6s) (12000 16%) 5.6781\n",
      "12m 41s (- 60m 31s) (13000 17%) 5.7053\n",
      "13m 43s (- 59m 48s) (14000 18%) 5.6898\n",
      "14m 45s (- 59m 0s) (15000 20%) 5.7613\n",
      "15m 47s (- 58m 12s) (16000 21%) 5.7201\n",
      "16m 48s (- 57m 19s) (17000 22%) 5.6089\n",
      "17m 50s (- 56m 31s) (18000 24%) 5.6697\n",
      "18m 52s (- 55m 37s) (19000 25%) 5.6203\n",
      "19m 54s (- 54m 44s) (20000 26%) 5.6519\n",
      "20m 55s (- 53m 48s) (21000 28%) 5.6235\n",
      "21m 57s (- 52m 53s) (22000 29%) 5.5824\n",
      "22m 59s (- 51m 59s) (23000 30%) 5.5974\n",
      "24m 2s (- 51m 4s) (24000 32%) 5.5743\n",
      "25m 2s (- 50m 4s) (25000 33%) 5.4881\n",
      "26m 4s (- 49m 8s) (26000 34%) 5.5172\n",
      "27m 6s (- 48m 11s) (27000 36%) 5.4881\n",
      "28m 5s (- 47m 9s) (28000 37%) 5.4895\n",
      "29m 7s (- 46m 11s) (29000 38%) 5.5409\n",
      "30m 8s (- 45m 13s) (30000 40%) 5.4099\n",
      "31m 11s (- 44m 16s) (31000 41%) 5.5671\n",
      "32m 11s (- 43m 15s) (32000 42%) 5.4729\n",
      "33m 13s (- 42m 17s) (33000 44%) 5.4127\n",
      "34m 16s (- 41m 19s) (34000 45%) 5.4484\n",
      "35m 18s (- 40m 21s) (35000 46%) 5.5620\n",
      "36m 20s (- 39m 22s) (36000 48%) 5.4108\n",
      "37m 22s (- 38m 23s) (37000 49%) 5.4192\n",
      "38m 26s (- 37m 25s) (38000 50%) 5.3646\n",
      "39m 28s (- 36m 26s) (39000 52%) 5.4498\n",
      "40m 30s (- 35m 26s) (40000 53%) 5.4177\n",
      "41m 30s (- 34m 25s) (41000 54%) 5.3067\n",
      "42m 33s (- 33m 26s) (42000 56%) 5.3471\n",
      "43m 36s (- 32m 27s) (43000 57%) 5.3871\n",
      "44m 38s (- 31m 27s) (44000 58%) 5.3640\n",
      "45m 41s (- 30m 27s) (45000 60%) 5.3790\n",
      "46m 43s (- 29m 27s) (46000 61%) 5.3861\n",
      "47m 44s (- 28m 26s) (47000 62%) 5.2984\n",
      "48m 46s (- 27m 26s) (48000 64%) 5.3115\n",
      "49m 48s (- 26m 25s) (49000 65%) 5.2968\n",
      "50m 52s (- 25m 26s) (50000 66%) 5.4052\n",
      "51m 54s (- 24m 25s) (51000 68%) 5.3196\n",
      "52m 55s (- 23m 24s) (52000 69%) 5.3412\n",
      "53m 58s (- 22m 24s) (53000 70%) 5.3381\n",
      "54m 59s (- 21m 22s) (54000 72%) 5.2700\n",
      "56m 1s (- 20m 22s) (55000 73%) 5.3307\n",
      "57m 3s (- 19m 21s) (56000 74%) 5.3119\n",
      "58m 6s (- 18m 20s) (57000 76%) 5.2694\n",
      "59m 8s (- 17m 20s) (58000 77%) 5.3035\n",
      "60m 10s (- 16m 19s) (59000 78%) 5.2135\n",
      "61m 12s (- 15m 18s) (60000 80%) 5.2639\n",
      "62m 14s (- 14m 17s) (61000 81%) 5.2548\n",
      "63m 18s (- 13m 16s) (62000 82%) 5.2808\n",
      "64m 20s (- 12m 15s) (63000 84%) 5.2749\n",
      "65m 23s (- 11m 14s) (64000 85%) 5.2418\n",
      "66m 26s (- 10m 13s) (65000 86%) 5.2902\n",
      "67m 28s (- 9m 12s) (66000 88%) 5.2429\n",
      "68m 30s (- 8m 10s) (67000 89%) 5.2235\n",
      "69m 33s (- 7m 9s) (68000 90%) 5.2584\n",
      "70m 34s (- 6m 8s) (69000 92%) 5.2721\n",
      "71m 35s (- 5m 6s) (70000 93%) 5.2267\n",
      "72m 37s (- 4m 5s) (71000 94%) 5.2022\n",
      "73m 40s (- 3m 4s) (72000 96%) 5.2189\n",
      "74m 42s (- 2m 2s) (73000 97%) 5.1492\n",
      "75m 44s (- 1m 1s) (74000 98%) 5.2201\n",
      "76m 47s (- 0m 0s) (75000 100%) 5.2421\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are  [0.20657294621824704, 0.06866274881028465, 0.025256683994413165]\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang3.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang3.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34QQDEirydMQ"
   },
   "source": [
    "###Fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 1240,
     "status": "ok",
     "timestamp": 1615816855461,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "zCnOu5OXyPVu"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 240\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang4, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang4, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs4))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 1192,
     "status": "ok",
     "timestamp": 1615816855861,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "avak6eD9yXww"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang4, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang4.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang4, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang4.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang4.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs4)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs4:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs4:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5429809,
     "status": "ok",
     "timestamp": 1615822285053,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "rVOKFdzNyYXX",
    "outputId": "8a078694-6c54-4caf-e36a-2116dd7ba5b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 59s (- 73m 7s) (1000 1%) 5.9343\n",
      "1m 54s (- 69m 56s) (2000 2%) 5.8366\n",
      "2m 49s (- 67m 45s) (3000 4%) 5.5328\n",
      "3m 44s (- 66m 28s) (4000 5%) 5.4804\n",
      "4m 41s (- 65m 40s) (5000 6%) 5.4423\n",
      "5m 36s (- 64m 25s) (6000 8%) 5.4339\n",
      "6m 31s (- 63m 20s) (7000 9%) 5.4314\n",
      "7m 27s (- 62m 31s) (8000 10%) 5.3438\n",
      "8m 26s (- 61m 54s) (9000 12%) 5.6289\n",
      "9m 23s (- 61m 4s) (10000 13%) 5.5458\n",
      "10m 23s (- 60m 25s) (11000 14%) 5.6124\n",
      "11m 21s (- 59m 39s) (12000 16%) 5.6847\n",
      "12m 20s (- 58m 53s) (13000 17%) 5.6750\n",
      "13m 20s (- 58m 6s) (14000 18%) 5.5487\n",
      "14m 19s (- 57m 17s) (15000 20%) 5.6293\n",
      "15m 19s (- 56m 30s) (16000 21%) 5.5931\n",
      "16m 18s (- 55m 37s) (17000 22%) 5.5992\n",
      "17m 20s (- 54m 54s) (18000 24%) 5.6416\n",
      "18m 19s (- 54m 0s) (19000 25%) 5.5993\n",
      "19m 19s (- 53m 9s) (20000 26%) 5.6233\n",
      "20m 20s (- 52m 17s) (21000 28%) 5.5758\n",
      "21m 21s (- 51m 26s) (22000 29%) 5.5695\n",
      "22m 20s (- 50m 29s) (23000 30%) 5.5751\n",
      "23m 20s (- 49m 35s) (24000 32%) 5.5355\n",
      "24m 19s (- 48m 39s) (25000 33%) 5.4999\n",
      "25m 19s (- 47m 44s) (26000 34%) 5.5938\n",
      "26m 19s (- 46m 48s) (27000 36%) 5.5286\n",
      "27m 19s (- 45m 52s) (28000 37%) 5.4905\n",
      "28m 20s (- 44m 57s) (29000 38%) 5.5165\n",
      "29m 22s (- 44m 3s) (30000 40%) 5.5713\n",
      "30m 23s (- 43m 8s) (31000 41%) 5.4751\n",
      "31m 23s (- 42m 11s) (32000 42%) 5.4251\n",
      "32m 24s (- 41m 14s) (33000 44%) 5.3990\n",
      "33m 23s (- 40m 16s) (34000 45%) 5.4192\n",
      "34m 22s (- 39m 17s) (35000 46%) 5.4206\n",
      "35m 25s (- 38m 22s) (36000 48%) 5.4700\n",
      "36m 25s (- 37m 24s) (37000 49%) 5.3706\n",
      "37m 25s (- 36m 25s) (38000 50%) 5.4165\n",
      "38m 25s (- 35m 27s) (39000 52%) 5.3806\n",
      "39m 25s (- 34m 29s) (40000 53%) 5.3435\n",
      "40m 26s (- 33m 32s) (41000 54%) 5.3235\n",
      "41m 26s (- 32m 34s) (42000 56%) 5.3977\n",
      "42m 28s (- 31m 36s) (43000 57%) 5.3713\n",
      "43m 29s (- 30m 38s) (44000 58%) 5.4236\n",
      "44m 29s (- 29m 39s) (45000 60%) 5.3128\n",
      "45m 29s (- 28m 40s) (46000 61%) 5.2944\n",
      "46m 32s (- 27m 43s) (47000 62%) 5.3137\n",
      "47m 33s (- 26m 45s) (48000 64%) 5.3467\n",
      "48m 34s (- 25m 46s) (49000 65%) 5.3949\n",
      "49m 34s (- 24m 47s) (50000 66%) 5.3872\n",
      "50m 35s (- 23m 48s) (51000 68%) 5.3328\n",
      "51m 36s (- 22m 49s) (52000 69%) 5.3519\n",
      "52m 39s (- 21m 51s) (53000 70%) 5.3770\n",
      "53m 39s (- 20m 51s) (54000 72%) 5.3020\n",
      "54m 38s (- 19m 52s) (55000 73%) 5.2465\n",
      "55m 39s (- 18m 53s) (56000 74%) 5.2939\n",
      "56m 39s (- 17m 53s) (57000 76%) 5.3530\n",
      "57m 39s (- 16m 54s) (58000 77%) 5.2450\n",
      "58m 41s (- 15m 54s) (59000 78%) 5.3347\n",
      "59m 41s (- 14m 55s) (60000 80%) 5.2151\n",
      "60m 42s (- 13m 55s) (61000 81%) 5.2862\n",
      "61m 42s (- 12m 56s) (62000 82%) 5.1931\n",
      "62m 45s (- 11m 57s) (63000 84%) 5.2653\n",
      "63m 46s (- 10m 57s) (64000 85%) 5.2554\n",
      "64m 47s (- 9m 58s) (65000 86%) 5.1768\n",
      "65m 49s (- 8m 58s) (66000 88%) 5.2430\n",
      "66m 51s (- 7m 58s) (67000 89%) 5.2671\n",
      "67m 51s (- 6m 59s) (68000 90%) 5.1408\n",
      "68m 52s (- 5m 59s) (69000 92%) 5.1783\n",
      "69m 53s (- 4m 59s) (70000 93%) 5.2748\n",
      "70m 55s (- 3m 59s) (71000 94%) 5.1983\n",
      "71m 56s (- 2m 59s) (72000 96%) 5.2687\n",
      "72m 57s (- 1m 59s) (73000 97%) 5.1869\n",
      "73m 59s (- 0m 59s) (74000 98%) 5.2674\n",
      "74m 59s (- 0m 0s) (75000 100%) 5.1920\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are  [0.2302767281957183, 0.08058228821986646, 0.03036540269994112]\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang4.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang4.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtGbDe1GzSK9"
   },
   "source": [
    "###Fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3888909,
     "status": "aborted",
     "timestamp": 1615811744163,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "rM5o8g5vzQE7"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "MAX_LENGTH = 240\n",
    "# additive https://blog.floydhub.com/attention-mechanism/\n",
    "class AttnDecoderRNN3(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        #################\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn = nn.Linear(self.hidden_size , self.max_length) #additive\n",
    "        \n",
    "        ######################/\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #print((embedded[0]*hidden[0]).shape)\n",
    "\n",
    "        #additive\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        #print(x.unsqueeze(0).shape, self.weight.unsqueeze(2).shape)\n",
    "        alignment_scores = torch.bmm(x.unsqueeze(0), self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            #################################\n",
    "            alignment_scores.view(1,-1), dim=1) #dot product\n",
    "            #################################\n",
    "        #print(attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        #print(attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        \n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang5, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang5, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs5))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1615807831401,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "JP78TY53zYHd"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang5, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang5.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang5, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "        \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            #elif n.leng > max_length:\n",
    "            #    continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        utterance.append(output_lang5.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            utterance.append(output_lang5.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_pairs5)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    i= 0\n",
    "    for sent_eng, sents_fre in test_pairs5:\n",
    "        i=i+1\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "        if i%1000==0:\n",
    "          print(i)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    for sent_eng, sents_fre in test_pairs5:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    #return bleu 1, bleu 2, bleu 3\n",
    "    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\n",
    "    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\n",
    "    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\n",
    "    #print (references,  candidates)\n",
    "    scores = [score1, score2, score3]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1615807831402,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "6u-YKVdSzaVV"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang5.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN3(hidden_size, output_lang5.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\n",
    "print(\"Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1615807831402,
     "user": {
      "displayName": "Ning Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64",
      "userId": "12536691088853738123"
     },
     "user_tz": -480
    },
    "id": "-FZN-rDe4xIF"
   },
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0ssX56GEsvF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AS2_QB_DE_A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
