{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"AS2_QA_CS.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uT-lrh1Xe3ry","executionInfo":{"status":"ok","timestamp":1615650431120,"user_tz":-480,"elapsed":17931,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"11ee2825-73f3-403b-9087-8a0ec452133e"},"source":["import sys,os\r\n","if 'google.colab' in sys.modules:\r\n","  from google.colab import drive\r\n","  drive.mount('/content/gdrive')\r\n","  path_to_file = '/content/gdrive/My Drive/AI Sem II/NLP/A2'\r\n","  print(path_to_file)\r\n","  os.chdir(path_to_file)\r\n","  !pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/AI Sem II/NLP/A2\n","/content/gdrive/My Drive/AI Sem II/NLP/A2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sUm8xUsPjECA"},"source":["from __future__ import unicode_literals, print_function, division\r\n","from io import open\r\n","import unicodedata\r\n","import string\r\n","import re\r\n","import random\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","from torch import optim\r\n","import torch.nn.functional as F\r\n","\r\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjR9yaPeIEDs","executionInfo":{"status":"ok","timestamp":1615650440870,"user_tz":-480,"elapsed":2226,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"f654a8da-063c-49f0-a614-8b4fc20e43b1"},"source":["data_cs = 'data/training/news-commentary-v9.cs-en.cs'\r\n","data_en = 'data/training/news-commentary-v9.cs-en.en'\r\n","\r\n","with open(data_cs, 'rb') as cs: \r\n","  sents_cs = [line.decode(\"utf-8\") for line in cs]      \r\n"," # sents_cs = [value for value in sents_cs if value != '']   \r\n","with open(data_en, 'rb') as en: \r\n","  sents_en = [line.decode(\"utf-8\") for line in en]\r\n"," # sents_en = [value for value in sents_en if value != '']\r\n","len(sents_en), len(sents_cs)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(146549, 146549)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08DjJdxvxuAW","executionInfo":{"status":"ok","timestamp":1615650441317,"user_tz":-480,"elapsed":1573,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"a52ade64-1e11-4352-e31b-193a5e226e36"},"source":["#max length of string \r\n","length_cs = [len(i.split()) for i in sents_cs]\r\n","max(length_cs)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["117"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrrJEeffxuEB","executionInfo":{"status":"ok","timestamp":1615650442697,"user_tz":-480,"elapsed":719,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"48984bc5-838f-4459-8620-3d2a5f36fe1c"},"source":["length_en = [len(i.split()) for i in sents_en]\r\n","max(length_en)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["164"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"lXnu1aePaT6s"},"source":["SOS_token = 0\r\n","EOS_token = 1\r\n","\r\n","class Lang:\r\n","  def __init__(self, name):\r\n","    self.name = name\r\n","    self.word2index = {}\r\n","    self.word2count = {}\r\n","    self.index2word = {0: \"SOS\", 1: \"EOS\"}\r\n","    self.n_words = 2\r\n","\r\n","  def addSentence(self, sentence):\r\n","    \r\n","    for word in sentence.split(' '):\r\n","      self.addWord(word)\r\n","  \r\n","  def addWord(self, word):\r\n","    if word not in self.word2index:\r\n","      self.word2index[word] = self.n_words\r\n","      self.word2count[word] = 1\r\n","      self.index2word[self.n_words] = word \r\n","      self.n_words += 1\r\n","    else:\r\n","      self.word2count[word] += 1\r\n","\r\n","# Turn a Unicode string to plain ASCII, thanks to\r\n","# https://stackoverflow.com/a/518232/2809427\r\n","def unicodeToAscii(s):\r\n","    return ''.join(\r\n","        c for c in unicodedata.normalize('NFD', s)\r\n","        if unicodedata.category(c) != 'Mn'\r\n","    )\r\n","\r\n","# Lowercase, trim, and remove non-letter characters\r\n","\r\n","\r\n","def normalizeString(s):\r\n","    s = unicodeToAscii(s.lower().strip())\r\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\r\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\r\n","    return s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaTNz04wdqKa"},"source":["def sent_pairs(lang1=sents_cs, lang2=sents_en):\r\n","  pairs = []\r\n","  for i, (cs_sent, en_sent) in enumerate(zip(lang1, lang2)):\r\n","    #if i < 100:\r\n","      pairs.append([cs_sent, en_sent])\r\n","   # print(i)\r\n","  pairs = [[normalizeString(s) for s in line] for line in pairs]\r\n","  input_lang1 = Lang('cs')\r\n","  output_lang1 = Lang('en')\r\n","\r\n","  input_lang2 = Lang('cs')\r\n","  output_lang2 = Lang('en')\r\n","\r\n","  input_lang3 = Lang('cs')\r\n","  output_lang3 = Lang('en')\r\n","\r\n","  input_lang4 = Lang('cs')\r\n","  output_lang4 = Lang('en')\r\n","\r\n","  input_lang5 = Lang('cs')\r\n","  output_lang5 = Lang('en')\r\n","\r\n","     \r\n","  return input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs\r\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TvQxz_O6IMm8"},"source":["The full process for preparing the data is:\r\n","\r\n","-  Read text file and split into lines, split lines into pairs\r\n","-  Normalize text, filter by length and content\r\n","-  Make word lists from sentences in pairs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ll3A_tPrdF8","executionInfo":{"status":"ok","timestamp":1615650482586,"user_tz":-480,"elapsed":35501,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"67f8619a-289e-4f5c-be48-fc65d728ac90"},"source":[" def prepareData(lang1=sents_cs, lang2=sents_en):\r\n","    input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs = sent_pairs(lang1, lang2)\r\n","    print(\"Read %s sentence pairs\" % len(pairs))\r\n","\r\n","    #Assumption: as the dataset is news commentary on different topics, there is highly unlikely exactly the same sentences \r\n","    # collect test pairs\r\n","    num_test = int(len(pairs)*0.2)\r\n","    print(\"Number of test pairs:\", num_test)\r\n","    random.seed(1)\r\n","    random.shuffle(pairs)\r\n","    \r\n","    #fold 1\r\n","    test_pairs1 = pairs[:num_test]\r\n","     # collect train pairs\r\n","    train_pairs1 = pairs[num_test:]\r\n","    print(\"Number of train pairs:\", len(train_pairs1))\r\n","    print(\"Counting words...\")\r\n","\r\n","    for pair in train_pairs1:      \r\n","      input_lang1.addSentence(pair[0])\r\n","      output_lang1.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang1.name, input_lang1.n_words)\r\n","    print(output_lang1.name, output_lang1.n_words)\r\n","\r\n","    #fold 2\r\n","    test_pairs2 = pairs[num_test:num_test*2]\r\n","     # collect train pairs\r\n","    train_pairs2 = pairs[:num_test]\r\n","    for x in pairs[num_test*2:]:\r\n","      train_pairs2.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs2))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs2:      \r\n","      input_lang2.addSentence(pair[0])\r\n","      output_lang2.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang2.name, input_lang2.n_words)\r\n","    print(output_lang2.name, output_lang2.n_words)\r\n","\r\n","    #fold 3\r\n","    test_pairs3 = pairs[num_test*2:num_test*3]\r\n","     # collect train pairs\r\n","    train_pairs3 = pairs[:num_test*2]\r\n","    for x in pairs[num_test*3:]:\r\n","      train_pairs3.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs3))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs3:      \r\n","      input_lang3.addSentence(pair[0])\r\n","      output_lang3.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang3.name, input_lang3.n_words)\r\n","    print(output_lang3.name, output_lang3.n_words)\r\n","\r\n","\r\n","    #fold 4\r\n","    test_pairs4 = pairs[num_test*3:num_test*4]\r\n","     # collect train pairs\r\n","    train_pairs4 = pairs[:num_test*3]\r\n","    for x in pairs[num_test*4:]:\r\n","      train_pairs4.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs4))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs4:      \r\n","      input_lang4.addSentence(pair[0])\r\n","      output_lang4.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang4.name, input_lang4.n_words)\r\n","    print(output_lang4.name, output_lang4.n_words)\r\n","\r\n","    #fold 5\r\n","    test_pairs5 = pairs[num_test*4:]\r\n","     # collect train pairs\r\n","    train_pairs5 = pairs[:num_test*4]\r\n","    print(\"Number of train pairs:\", len(train_pairs5))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs5:      \r\n","      input_lang5.addSentence(pair[0])\r\n","      output_lang5.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang5.name, input_lang5.n_words)\r\n","    print(output_lang5.name, output_lang5.n_words)\r\n","\r\n","\r\n","    return (input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4,input_lang5, output_lang5,train_pairs1, \r\n","            test_pairs1, train_pairs2, test_pairs2, train_pairs3, test_pairs3,train_pairs4, test_pairs4,train_pairs5, test_pairs5)\r\n","\r\n","\r\n","(input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, train_pairs1, test_pairs1, train_pairs2,\r\n"," test_pairs2,train_pairs3, test_pairs3, train_pairs4, test_pairs4,train_pairs5, test_pairs5) = prepareData(sents_cs, sents_en)\r\n","print(random.choice(train_pairs1))\r\n","print(random.choice(train_pairs2))\r\n","print(random.choice(train_pairs3))\r\n","print(random.choice(train_pairs4))\r\n","print(random.choice(train_pairs5))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Read 146549 sentence pairs\n","Number of test pairs: 29309\n","Number of train pairs: 117240\n","Counting words...\n","Counted words:\n","cs 116234\n","en 38995\n","Number of train pairs: 117240\n","Counting words...\n","Counted words:\n","cs 116224\n","en 39014\n","Number of train pairs: 117240\n","Counting words...\n","Counted words:\n","cs 116264\n","en 39073\n","Number of train pairs: 117240\n","Counting words...\n","Counted words:\n","cs 116432\n","en 39163\n","Number of train pairs: 117236\n","Counting words...\n","Counted words:\n","cs 116390\n","en 39237\n","['jeho reformy ale prekypely v revoluci spise pohanenou zdola nez rizenou shora .', 'but his reforms snowballed into a revolution driven from below rather than controlled from above .']\n","['prozradil londynskym sunday times ze u iranskeho pobrezi rozmistil ponorky vyzbrojene jadernymi zbranemi .', 'it leaked to the london sunday times that it had placed nuclear armed submarines off iran s coast .']\n","['staty ktere planuji nove programy jaderne energetiky si musi uvedomit ze dosazeni techto cilu je narocny a dlouhodoby ukol .', 'countries planning new nuclear power programs must recognize that achieving their goals is a challenging long term undertaking .']\n","['ovsem z naseho pohledu toho k cemu nas ostatni nasi blizni mravne zavazuji je mezi temito dvema ciny a pristupy k lidskemu zivotu jez vyjadruji obrovsky rozdil .', 'but in our sense of what we are owed morally by our fellow human beings there is a huge difference between these two acts and the attitudes they express toward human life .']\n","['znechuceni lidi z politiku nebylo v evrope v usa ani v japonsku od . let nikdy tak velke .', 'not since the s has popular disgust with politicians in europe the us as well as japan run so high .']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"npNTNDUOOwoC"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 164\r\n","class AttnDecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","\r\n","        attn_weights = F.softmax(\r\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang1, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang1, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs1))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjoCFY3nTmBG"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang1, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang1.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang1, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang1.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang1.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs1)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs1:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs1:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"08M4DvfPToJk","outputId":"90148305-b6f8-46b5-fc58-d1a2e3777402"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang1.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang1.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1m 4s (- 79m 24s) (1000 1%) 6.0163\n","2m 3s (- 74m 49s) (2000 2%) 5.5841\n","3m 4s (- 73m 38s) (3000 4%) 5.5673\n","4m 3s (- 72m 0s) (4000 5%) 5.4593\n","5m 2s (- 70m 36s) (5000 6%) 5.3522\n","6m 2s (- 69m 33s) (6000 8%) 5.3391\n","7m 2s (- 68m 26s) (7000 9%) 5.3289\n","8m 3s (- 67m 31s) (8000 10%) 5.5755\n","9m 6s (- 66m 44s) (9000 12%) 5.4493\n","10m 7s (- 65m 49s) (10000 13%) 5.6683\n","11m 12s (- 65m 14s) (11000 14%) 5.7436\n","12m 16s (- 64m 24s) (12000 16%) 5.6964\n","13m 22s (- 63m 45s) (13000 17%) 5.7409\n","14m 27s (- 62m 58s) (14000 18%) 5.8236\n","15m 32s (- 62m 11s) (15000 20%) 5.7610\n","16m 39s (- 61m 27s) (16000 21%) 5.7675\n","17m 46s (- 60m 39s) (17000 22%) 5.7591\n","18m 52s (- 59m 45s) (18000 24%) 5.7396\n","19m 59s (- 58m 55s) (19000 25%) 5.7491\n","21m 5s (- 57m 59s) (20000 26%) 5.6736\n","22m 11s (- 57m 2s) (21000 28%) 5.5908\n","23m 16s (- 56m 5s) (22000 29%) 5.6060\n","24m 23s (- 55m 8s) (23000 30%) 5.7079\n","25m 28s (- 54m 8s) (24000 32%) 5.6334\n","26m 34s (- 53m 9s) (25000 33%) 5.5889\n","27m 40s (- 52m 8s) (26000 34%) 5.5657\n","28m 43s (- 51m 3s) (27000 36%) 5.6186\n","29m 49s (- 50m 4s) (28000 37%) 5.5819\n","30m 55s (- 49m 2s) (29000 38%) 5.5946\n","32m 2s (- 48m 3s) (30000 40%) 5.4763\n","33m 8s (- 47m 2s) (31000 41%) 5.5016\n","34m 13s (- 45m 58s) (32000 42%) 5.5263\n","35m 19s (- 44m 57s) (33000 44%) 5.5207\n","36m 26s (- 43m 56s) (34000 45%) 5.5526\n","37m 30s (- 42m 52s) (35000 46%) 5.5188\n","38m 37s (- 41m 50s) (36000 48%) 5.6032\n","39m 42s (- 40m 46s) (37000 49%) 5.4572\n","40m 49s (- 39m 44s) (38000 50%) 5.5269\n","41m 55s (- 38m 42s) (39000 52%) 5.4880\n","43m 2s (- 37m 39s) (40000 53%) 5.5411\n","44m 8s (- 36m 36s) (41000 54%) 5.4615\n","45m 12s (- 35m 30s) (42000 56%) 5.3735\n","46m 17s (- 34m 27s) (43000 57%) 5.4640\n","47m 25s (- 33m 24s) (44000 58%) 5.4739\n","48m 31s (- 32m 20s) (45000 60%) 5.4002\n","49m 39s (- 31m 18s) (46000 61%) 5.5114\n","50m 44s (- 30m 14s) (47000 62%) 5.4121\n","51m 52s (- 29m 10s) (48000 64%) 5.4161\n","52m 59s (- 28m 7s) (49000 65%) 5.3715\n","54m 5s (- 27m 2s) (50000 66%) 5.4910\n","55m 12s (- 25m 58s) (51000 68%) 5.4712\n","56m 19s (- 24m 54s) (52000 69%) 5.4180\n","57m 25s (- 23m 50s) (53000 70%) 5.4147\n","58m 33s (- 22m 46s) (54000 72%) 5.3907\n","59m 40s (- 21m 42s) (55000 73%) 5.3945\n","60m 46s (- 20m 37s) (56000 74%) 5.3730\n","61m 52s (- 19m 32s) (57000 76%) 5.3677\n","62m 59s (- 18m 27s) (58000 77%) 5.3372\n","64m 5s (- 17m 22s) (59000 78%) 5.3063\n","65m 10s (- 16m 17s) (60000 80%) 5.3271\n","66m 18s (- 15m 13s) (61000 81%) 5.3707\n","67m 25s (- 14m 8s) (62000 82%) 5.4214\n","68m 33s (- 13m 3s) (63000 84%) 5.4338\n","69m 40s (- 11m 58s) (64000 85%) 5.3405\n","70m 47s (- 10m 53s) (65000 86%) 5.3518\n","71m 52s (- 9m 48s) (66000 88%) 5.3555\n","72m 58s (- 8m 42s) (67000 89%) 5.2703\n","74m 7s (- 7m 37s) (68000 90%) 5.3677\n","75m 12s (- 6m 32s) (69000 92%) 5.3471\n","76m 20s (- 5m 27s) (70000 93%) 5.2885\n","77m 25s (- 4m 21s) (71000 94%) 5.3133\n","78m 31s (- 3m 16s) (72000 96%) 5.2138\n","79m 37s (- 2m 10s) (73000 97%) 5.2852\n","80m 44s (- 1m 5s) (74000 98%) 5.2591\n","81m 52s (- 0m 0s) (75000 100%) 5.3386\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are  [0.21050110814505307, 0.06959602713612544, 0.024092929557136003]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8X7TtXWDvQCS"},"source":["###Fold2"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"zTgC4HZSt6XD"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 164\r\n","class AttnDecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","\r\n","        attn_weights = F.softmax(\r\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang2, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang2, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs2))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Xj4EasFzvVmP"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang2, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang2.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang2, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang2.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang2.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs2)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs2:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs2:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ab6RRAYUvcdZ","outputId":"d60e871a-0bec-4484-b3e2-2adf746a01f6"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang2.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang2.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1m 5s (- 80m 29s) (1000 1%) 6.0622\n","2m 4s (- 75m 45s) (2000 2%) 5.6567\n","3m 4s (- 73m 41s) (3000 4%) 5.4526\n","4m 2s (- 71m 46s) (4000 5%) 5.3783\n","5m 3s (- 70m 43s) (5000 6%) 5.4373\n","6m 1s (- 69m 13s) (6000 8%) 5.2798\n","7m 3s (- 68m 31s) (7000 9%) 5.3683\n","8m 5s (- 67m 45s) (8000 10%) 5.4208\n","9m 5s (- 66m 39s) (9000 12%) 5.3614\n","10m 8s (- 65m 56s) (10000 13%) 5.4758\n","11m 11s (- 65m 8s) (11000 14%) 5.4328\n","12m 16s (- 64m 29s) (12000 16%) 5.6203\n","13m 22s (- 63m 48s) (13000 17%) 5.7743\n","14m 28s (- 63m 3s) (14000 18%) 5.7261\n","15m 33s (- 62m 13s) (15000 20%) 5.7123\n","16m 38s (- 61m 22s) (16000 21%) 5.6690\n","17m 41s (- 60m 22s) (17000 22%) 5.6276\n","18m 46s (- 59m 27s) (18000 24%) 5.6638\n","19m 51s (- 58m 30s) (19000 25%) 5.6192\n","20m 56s (- 57m 35s) (20000 26%) 5.6530\n","22m 3s (- 56m 42s) (21000 28%) 5.6836\n","23m 8s (- 55m 45s) (22000 29%) 5.6284\n","24m 15s (- 54m 51s) (23000 30%) 5.6844\n","25m 21s (- 53m 53s) (24000 32%) 5.5999\n","26m 27s (- 52m 54s) (25000 33%) 5.5929\n","27m 32s (- 51m 54s) (26000 34%) 5.6492\n","28m 35s (- 50m 50s) (27000 36%) 5.6088\n","29m 41s (- 49m 49s) (28000 37%) 5.5410\n","30m 47s (- 48m 50s) (29000 38%) 5.6175\n","31m 53s (- 47m 50s) (30000 40%) 5.5646\n","32m 57s (- 46m 47s) (31000 41%) 5.5061\n","34m 3s (- 45m 45s) (32000 42%) 5.5343\n","35m 10s (- 44m 46s) (33000 44%) 5.5698\n","36m 14s (- 43m 42s) (34000 45%) 5.4660\n","37m 19s (- 42m 39s) (35000 46%) 5.4696\n","38m 25s (- 41m 37s) (36000 48%) 5.4662\n","39m 30s (- 40m 34s) (37000 49%) 5.5186\n","40m 35s (- 39m 31s) (38000 50%) 5.4370\n","41m 42s (- 38m 30s) (39000 52%) 5.4966\n","42m 48s (- 37m 27s) (40000 53%) 5.4653\n","43m 53s (- 36m 23s) (41000 54%) 5.4481\n","44m 59s (- 35m 20s) (42000 56%) 5.4688\n","46m 4s (- 34m 16s) (43000 57%) 5.4246\n","47m 9s (- 33m 13s) (44000 58%) 5.4384\n","48m 13s (- 32m 8s) (45000 60%) 5.4425\n","49m 16s (- 31m 4s) (46000 61%) 5.3841\n","50m 23s (- 30m 1s) (47000 62%) 5.4247\n","51m 30s (- 28m 58s) (48000 64%) 5.3574\n","52m 36s (- 27m 54s) (49000 65%) 5.3740\n","53m 41s (- 26m 50s) (50000 66%) 5.4202\n","54m 47s (- 25m 47s) (51000 68%) 5.4370\n","55m 52s (- 24m 42s) (52000 69%) 5.3402\n","56m 59s (- 23m 39s) (53000 70%) 5.4227\n","58m 6s (- 22m 35s) (54000 72%) 5.3493\n","59m 13s (- 21m 32s) (55000 73%) 5.3753\n","60m 17s (- 20m 27s) (56000 74%) 5.2957\n","61m 22s (- 19m 22s) (57000 76%) 5.2824\n","62m 27s (- 18m 18s) (58000 77%) 5.3771\n","63m 32s (- 17m 13s) (59000 78%) 5.3414\n","64m 39s (- 16m 9s) (60000 80%) 5.4109\n","65m 45s (- 15m 5s) (61000 81%) 5.4056\n","66m 53s (- 14m 1s) (62000 82%) 5.3008\n","67m 59s (- 12m 56s) (63000 84%) 5.3468\n","69m 5s (- 11m 52s) (64000 85%) 5.4010\n","70m 13s (- 10m 48s) (65000 86%) 5.3676\n","71m 18s (- 9m 43s) (66000 88%) 5.3493\n","72m 23s (- 8m 38s) (67000 89%) 5.2569\n","73m 30s (- 7m 34s) (68000 90%) 5.3441\n","74m 35s (- 6m 29s) (69000 92%) 5.2528\n","75m 40s (- 5m 24s) (70000 93%) 5.2894\n","76m 47s (- 4m 19s) (71000 94%) 5.3429\n","77m 54s (- 3m 14s) (72000 96%) 5.3086\n","79m 1s (- 2m 9s) (73000 97%) 5.3801\n","80m 7s (- 1m 4s) (74000 98%) 5.2787\n","81m 12s (- 0m 0s) (75000 100%) 5.2951\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are  [0.15947716227327627, 0.049474488945633374, 0.016855258898818816]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_1_JxzKvxF5N"},"source":["###Fold 3"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"WeLVXQOhxCMM"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 164\r\n","class AttnDecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","\r\n","        attn_weights = F.softmax(\r\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang3, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang3, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs3))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"9bSwRykXxK_K"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang3, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang3.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang3, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang3.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang3.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs3)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs3:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs3:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"aDUlbFWuxLFl","outputId":"e2cd886f-7f0c-4aed-cf64-4750a75f63f2"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang3.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang3.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1m 2s (- 77m 18s) (1000 1%) 5.9532\n","2m 2s (- 74m 34s) (2000 2%) 5.7176\n","3m 2s (- 72m 58s) (3000 4%) 5.5728\n","4m 1s (- 71m 23s) (4000 5%) 5.5550\n","4m 58s (- 69m 33s) (5000 6%) 5.2229\n","5m 57s (- 68m 28s) (6000 8%) 5.3290\n","6m 55s (- 67m 17s) (7000 9%) 5.3888\n","7m 54s (- 66m 16s) (8000 10%) 5.3673\n","8m 55s (- 65m 27s) (9000 12%) 5.3808\n","9m 56s (- 64m 35s) (10000 13%) 5.3453\n","10m 58s (- 63m 52s) (11000 14%) 5.5627\n","12m 2s (- 63m 13s) (12000 16%) 5.6921\n","13m 7s (- 62m 36s) (13000 17%) 5.6948\n","14m 10s (- 61m 46s) (14000 18%) 5.6799\n","15m 15s (- 61m 1s) (15000 20%) 5.7623\n","16m 19s (- 60m 12s) (16000 21%) 5.6968\n","17m 26s (- 59m 29s) (17000 22%) 5.7575\n","18m 30s (- 58m 36s) (18000 24%) 5.6907\n","19m 35s (- 57m 45s) (19000 25%) 5.6875\n","20m 41s (- 56m 54s) (20000 26%) 5.6887\n","21m 48s (- 56m 4s) (21000 28%) 5.6730\n","22m 53s (- 55m 9s) (22000 29%) 5.6131\n","23m 58s (- 54m 12s) (23000 30%) 5.6265\n","25m 4s (- 53m 16s) (24000 32%) 5.6490\n","26m 9s (- 52m 19s) (25000 33%) 5.5783\n","27m 12s (- 51m 17s) (26000 34%) 5.5397\n","28m 16s (- 50m 16s) (27000 36%) 5.5786\n","29m 21s (- 49m 16s) (28000 37%) 5.5749\n","30m 27s (- 48m 19s) (29000 38%) 5.6186\n","31m 33s (- 47m 20s) (30000 40%) 5.5816\n","32m 39s (- 46m 21s) (31000 41%) 5.5693\n","33m 45s (- 45m 22s) (32000 42%) 5.6078\n","34m 51s (- 44m 21s) (33000 44%) 5.5557\n","35m 57s (- 43m 21s) (34000 45%) 5.5213\n","37m 2s (- 42m 20s) (35000 46%) 5.4866\n","38m 8s (- 41m 19s) (36000 48%) 5.4695\n","39m 13s (- 40m 17s) (37000 49%) 5.5093\n","40m 18s (- 39m 15s) (38000 50%) 5.5715\n","41m 23s (- 38m 12s) (39000 52%) 5.4507\n","42m 28s (- 37m 9s) (40000 53%) 5.4129\n","43m 34s (- 36m 7s) (41000 54%) 5.4908\n","44m 41s (- 35m 6s) (42000 56%) 5.4646\n","45m 48s (- 34m 5s) (43000 57%) 5.4615\n","46m 55s (- 33m 3s) (44000 58%) 5.4490\n","48m 0s (- 32m 0s) (45000 60%) 5.4362\n","49m 4s (- 30m 56s) (46000 61%) 5.4288\n","50m 9s (- 29m 52s) (47000 62%) 5.3548\n","51m 14s (- 28m 49s) (48000 64%) 5.5008\n","52m 20s (- 27m 46s) (49000 65%) 5.4585\n","53m 27s (- 26m 43s) (50000 66%) 5.3840\n","54m 33s (- 25m 40s) (51000 68%) 5.3913\n","55m 39s (- 24m 37s) (52000 69%) 5.3948\n","56m 46s (- 23m 33s) (53000 70%) 5.3375\n","57m 52s (- 22m 30s) (54000 72%) 5.3607\n","58m 58s (- 21m 26s) (55000 73%) 5.3651\n","60m 3s (- 20m 22s) (56000 74%) 5.2692\n","61m 10s (- 19m 19s) (57000 76%) 5.3915\n","62m 15s (- 18m 14s) (58000 77%) 5.3598\n","63m 22s (- 17m 11s) (59000 78%) 5.3799\n","64m 29s (- 16m 7s) (60000 80%) 5.4041\n","65m 36s (- 15m 3s) (61000 81%) 5.4221\n","66m 41s (- 13m 59s) (62000 82%) 5.3984\n","67m 48s (- 12m 55s) (63000 84%) 5.3683\n","68m 55s (- 11m 50s) (64000 85%) 5.4151\n","69m 59s (- 10m 46s) (65000 86%) 5.3073\n","71m 4s (- 9m 41s) (66000 88%) 5.3722\n","72m 11s (- 8m 37s) (67000 89%) 5.3600\n","73m 18s (- 7m 32s) (68000 90%) 5.3593\n","74m 24s (- 6m 28s) (69000 92%) 5.3637\n","75m 30s (- 5m 23s) (70000 93%) 5.2513\n","76m 36s (- 4m 18s) (71000 94%) 5.2243\n","77m 42s (- 3m 14s) (72000 96%) 5.3617\n","78m 47s (- 2m 9s) (73000 97%) 5.2861\n","79m 50s (- 1m 4s) (74000 98%) 5.3010\n","80m 57s (- 0m 0s) (75000 100%) 5.2254\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are  [0.17160965670381292, 0.05505041309089688, 0.020182546083081426]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"34QQDEirydMQ"},"source":["###Fold 4"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"zCnOu5OXyPVu"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 164\r\n","class AttnDecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","\r\n","        attn_weights = F.softmax(\r\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang4, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang4, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs4))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"avak6eD9yXww"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang4, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang4.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang4, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang4.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang4.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs4)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs4:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs4:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"rVOKFdzNyYXX","outputId":"30151586-0acd-4b94-b789-c1fa40b3c35d"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang4.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang4.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1m 6s (- 82m 20s) (1000 1%) 5.9656\n","2m 5s (- 76m 16s) (2000 2%) 5.4930\n","3m 4s (- 73m 44s) (3000 4%) 5.4357\n","4m 4s (- 72m 27s) (4000 5%) 5.4627\n","5m 5s (- 71m 20s) (5000 6%) 5.5332\n","6m 3s (- 69m 45s) (6000 8%) 5.2899\n","7m 1s (- 68m 17s) (7000 9%) 5.3821\n","8m 1s (- 67m 12s) (8000 10%) 5.2953\n","9m 1s (- 66m 12s) (9000 12%) 5.3482\n","10m 1s (- 65m 9s) (10000 13%) 5.4557\n","11m 3s (- 64m 19s) (11000 14%) 5.5882\n","12m 10s (- 63m 55s) (12000 16%) 5.7224\n","13m 13s (- 63m 4s) (13000 17%) 5.6434\n","14m 18s (- 62m 21s) (14000 18%) 5.6938\n","15m 23s (- 61m 35s) (15000 20%) 5.7075\n","16m 28s (- 60m 46s) (16000 21%) 5.6992\n","17m 35s (- 59m 59s) (17000 22%) 5.6278\n","18m 39s (- 59m 5s) (18000 24%) 5.6756\n","19m 45s (- 58m 14s) (19000 25%) 5.6823\n","20m 51s (- 57m 21s) (20000 26%) 5.6047\n","21m 56s (- 56m 25s) (21000 28%) 5.6360\n","23m 3s (- 55m 33s) (22000 29%) 5.6749\n","24m 9s (- 54m 38s) (23000 30%) 5.7009\n","25m 14s (- 53m 38s) (24000 32%) 5.6416\n","26m 19s (- 52m 38s) (25000 33%) 5.5450\n","27m 25s (- 51m 40s) (26000 34%) 5.5655\n","28m 32s (- 50m 44s) (27000 36%) 5.5544\n","29m 37s (- 49m 43s) (28000 37%) 5.6278\n","30m 44s (- 48m 46s) (29000 38%) 5.6018\n","31m 50s (- 47m 46s) (30000 40%) 5.5541\n","32m 57s (- 46m 47s) (31000 41%) 5.5244\n","34m 3s (- 45m 45s) (32000 42%) 5.5021\n","35m 6s (- 44m 40s) (33000 44%) 5.4997\n","36m 12s (- 43m 40s) (34000 45%) 5.5315\n","37m 19s (- 42m 38s) (35000 46%) 5.5334\n","38m 26s (- 41m 39s) (36000 48%) 5.5195\n","39m 31s (- 40m 35s) (37000 49%) 5.4636\n","40m 38s (- 39m 34s) (38000 50%) 5.5018\n","41m 42s (- 38m 30s) (39000 52%) 5.4734\n","42m 47s (- 37m 26s) (40000 53%) 5.4561\n","43m 54s (- 36m 24s) (41000 54%) 5.4653\n","45m 0s (- 35m 21s) (42000 56%) 5.4838\n","46m 6s (- 34m 19s) (43000 57%) 5.5390\n","47m 13s (- 33m 16s) (44000 58%) 5.4993\n","48m 19s (- 32m 13s) (45000 60%) 5.4432\n","49m 26s (- 31m 10s) (46000 61%) 5.4298\n","50m 32s (- 30m 6s) (47000 62%) 5.4309\n","51m 39s (- 29m 3s) (48000 64%) 5.3807\n","52m 44s (- 27m 59s) (49000 65%) 5.3782\n","53m 50s (- 26m 55s) (50000 66%) 5.4236\n","54m 55s (- 25m 50s) (51000 68%) 5.4329\n","56m 0s (- 24m 46s) (52000 69%) 5.4458\n","57m 7s (- 23m 42s) (53000 70%) 5.4449\n","58m 14s (- 22m 38s) (54000 72%) 5.4714\n","59m 21s (- 21m 35s) (55000 73%) 5.4049\n","60m 29s (- 20m 31s) (56000 74%) 5.4578\n","61m 33s (- 19m 26s) (57000 76%) 5.3508\n","62m 39s (- 18m 22s) (58000 77%) 5.2771\n","63m 45s (- 17m 17s) (59000 78%) 5.3788\n","64m 50s (- 16m 12s) (60000 80%) 5.3392\n","65m 54s (- 15m 7s) (61000 81%) 5.2616\n","67m 1s (- 14m 3s) (62000 82%) 5.3869\n","68m 8s (- 12m 58s) (63000 84%) 5.3898\n","69m 14s (- 11m 54s) (64000 85%) 5.3306\n","70m 19s (- 10m 49s) (65000 86%) 5.3137\n","71m 24s (- 9m 44s) (66000 88%) 5.3226\n","72m 29s (- 8m 39s) (67000 89%) 5.3064\n","73m 35s (- 7m 34s) (68000 90%) 5.3252\n","74m 38s (- 6m 29s) (69000 92%) 5.1796\n","75m 43s (- 5m 24s) (70000 93%) 5.2428\n","76m 48s (- 4m 19s) (71000 94%) 5.1725\n","77m 54s (- 3m 14s) (72000 96%) 5.2380\n","79m 0s (- 2m 9s) (73000 97%) 5.2361\n","80m 6s (- 1m 4s) (74000 98%) 5.2447\n","81m 11s (- 0m 0s) (75000 100%) 5.2769\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are  [0.2116784985695682, 0.0667304927681249, 0.021551610490107214]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DtGbDe1GzSK9"},"source":["###Fold 5"]},{"cell_type":"code","metadata":{"id":"rM5o8g5vzQE7"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 164\r\n","class AttnDecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","\r\n","        attn_weights = F.softmax(\r\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang5, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang5, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs5))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JP78TY53zYHd"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang5, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang5.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang5, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang5.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang5.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs5)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs5:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs5:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6u-YKVdSzaVV"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang5.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang5.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"P8qMVNHB402u"},"source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yMu9L_ekRd4N"},"source":[""],"execution_count":null,"outputs":[]}]}