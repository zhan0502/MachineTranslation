{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AS2_QA_RU.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uT-lrh1Xe3ry","executionInfo":{"status":"ok","timestamp":1615739114786,"user_tz":-480,"elapsed":24434,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"b48b57d4-5832-415b-c8e9-4728e8ff64f4"},"source":["import sys,os\r\n","if 'google.colab' in sys.modules:\r\n","  from google.colab import drive\r\n","  drive.mount('/content/gdrive')\r\n","  path_to_file = '/content/gdrive/My Drive/AI Sem II/NLP/A2'\r\n","  print(path_to_file)\r\n","  os.chdir(path_to_file)\r\n","  !pwd"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/AI Sem II/NLP/A2\n","/content/gdrive/My Drive/AI Sem II/NLP/A2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sUm8xUsPjECA","executionInfo":{"status":"ok","timestamp":1615739117723,"user_tz":-480,"elapsed":4788,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["from __future__ import unicode_literals, print_function, division\r\n","from io import open\r\n","import unicodedata\r\n","import string\r\n","import re\r\n","import random\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","from torch import optim\r\n","import torch.nn.functional as F\r\n","\r\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjR9yaPeIEDs","executionInfo":{"status":"ok","timestamp":1615739119454,"user_tz":-480,"elapsed":6510,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"438b7ea1-7fef-4d07-877f-baac0b2fafb3"},"source":["data_ru = 'data/training/news-commentary-v9.ru-en.ru'\r\n","data_en = 'data/training/news-commentary-v9.ru-en.en'\r\n","\r\n","with open(data_ru, 'rb') as ru: \r\n","  sents_ru = [line.decode(\"utf-8\") for line in ru]      \r\n"," # sents_cs = [value for value in sents_cs if value != '']   \r\n","with open(data_en, 'rb') as en: \r\n","  sents_en = [line.decode(\"utf-8\") for line in en]\r\n"," # sents_en = [value for value in sents_en if value != '']\r\n","len(sents_en), len(sents_ru)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(165602, 165602)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08DjJdxvxuAW","executionInfo":{"status":"ok","timestamp":1615739119919,"user_tz":-480,"elapsed":6958,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"7f4386b7-33b8-4a6c-f9b5-55ae6dd18c5a"},"source":["#max length of string \r\n","length_ru = [len(i.split()) for i in sents_ru]\r\n","max(length_ru)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["160"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"KrrJEeffxuEB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615739119921,"user_tz":-480,"elapsed":6943,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"bfa9d663-e7d6-46c1-8e82-98ac9271f9f5"},"source":["length_en = [len(i.split()) for i in sents_en]\r\n","max(length_en)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["171"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"lXnu1aePaT6s","executionInfo":{"status":"ok","timestamp":1615739119923,"user_tz":-480,"elapsed":6929,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["SOS_token = 0\r\n","EOS_token = 1\r\n","\r\n","class Lang:\r\n","  def __init__(self, name):\r\n","    self.name = name\r\n","    self.word2index = {}\r\n","    self.word2count = {}\r\n","    self.index2word = {0: \"SOS\", 1: \"EOS\"}\r\n","    self.n_words = 2\r\n","\r\n","  def addSentence(self, sentence):\r\n","    \r\n","    for word in sentence.split(' '):\r\n","      self.addWord(word)\r\n","  \r\n","  def addWord(self, word):\r\n","    if word not in self.word2index:\r\n","      self.word2index[word] = self.n_words\r\n","      self.word2count[word] = 1\r\n","      self.index2word[self.n_words] = word \r\n","      self.n_words += 1\r\n","    else:\r\n","      self.word2count[word] += 1\r\n","\r\n","# Turn a Unicode string to plain ASCII, thanks to\r\n","# https://stackoverflow.com/a/518232/2809427\r\n","def unicodeToAscii(s):\r\n","    return ''.join(\r\n","        c for c in unicodedata.normalize('NFD', s)\r\n","        if unicodedata.category(c) != 'Mn'\r\n","    )\r\n","\r\n","# Lowercase, trim, and remove non-letter characters\r\n","\r\n","\r\n","def normalizeString(s):\r\n","    s = unicodeToAscii(s.lower().strip())\r\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\r\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\r\n","    return s"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaTNz04wdqKa","executionInfo":{"status":"ok","timestamp":1615739119923,"user_tz":-480,"elapsed":6926,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["def sent_pairs(lang1=sents_ru, lang2=sents_en):\r\n","  pairs = []\r\n","  for i, (cs_sent, en_sent) in enumerate(zip(lang1, lang2)):\r\n","    #if i < 100:\r\n","      #for russia\r\n","      en_sent = unicodeToAscii(en_sent.lower().strip()) #for russian\r\n","      en_sent = re.sub(r\"([.!?])\", r\" \\1\", en_sent)#for russian\r\n","      en_sent = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", en_sent)#for russian\r\n","      cs_sent = re.sub(r\"([.!?])\", r\" \\1\", cs_sent)#for russian\r\n","      pairs.append([cs_sent, en_sent])\r\n","\r\n","  # for others\r\n","  # pairs = [[normalizeString(s) for s in line] for line in pairs] # for others\r\n","  input_lang1 = Lang('ru')\r\n","  output_lang1 = Lang('en')\r\n","\r\n","  input_lang2 = Lang('ru')\r\n","  output_lang2 = Lang('en')\r\n","\r\n","  input_lang3 = Lang('ru')\r\n","  output_lang3 = Lang('en')\r\n","\r\n","  input_lang4 = Lang('ru')\r\n","  output_lang4 = Lang('en')\r\n","\r\n","  input_lang5 = Lang('ru')\r\n","  output_lang5 = Lang('en')\r\n","\r\n","     \r\n","  return input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs\r\n"," "],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TvQxz_O6IMm8"},"source":["The full process for preparing the data is:\r\n","\r\n","-  Read text file and split into lines, split lines into pairs\r\n","-  Normalize text, filter by length and content\r\n","-  Make word lists from sentences in pairs"]},{"cell_type":"code","metadata":{"id":"-ll3A_tPrdF8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615739147615,"user_tz":-480,"elapsed":34616,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"f8085f54-1fcc-4670-c55e-f1ebb7a66a5f"},"source":[" def prepareData(lang1=sents_ru, lang2=sents_en):\r\n","    input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs = sent_pairs(lang1, lang2)\r\n","    print(\"Read %s sentence pairs\" % len(pairs))\r\n","\r\n","    #Assumption: as the dataset is news commentary on different topics, there is highly unlikely exactly the same sentences \r\n","    # collect test pairs\r\n","    num_test = int(len(pairs)*0.2)\r\n","    print(\"Number of test pairs:\", num_test)\r\n","    random.shuffle(pairs)\r\n","    \r\n","    #fold 1\r\n","    test_pairs1 = pairs[:num_test]\r\n","     # collect train pairs\r\n","    train_pairs1 = pairs[num_test:]\r\n","    print(\"Number of train pairs:\", len(train_pairs1))\r\n","    print(\"Counting words...\")\r\n","\r\n","    for pair in train_pairs1:      \r\n","      input_lang1.addSentence(pair[0])\r\n","      output_lang1.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang1.name, input_lang1.n_words)\r\n","    print(output_lang1.name, output_lang1.n_words)\r\n","\r\n","    #fold 2\r\n","    test_pairs2 = pairs[num_test:num_test*2]\r\n","     # collect train pairs\r\n","    train_pairs2 = pairs[:num_test]\r\n","    for x in pairs[num_test*2:]:\r\n","      train_pairs2.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs2))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs2:      \r\n","      input_lang2.addSentence(pair[0])\r\n","      output_lang2.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang2.name, input_lang2.n_words)\r\n","    print(output_lang2.name, output_lang2.n_words)\r\n","\r\n","    #fold 3\r\n","    test_pairs3 = pairs[num_test*2:num_test*3]\r\n","     # collect train pairs\r\n","    train_pairs3 = pairs[:num_test*2]\r\n","    for x in pairs[num_test*3:]:\r\n","      train_pairs3.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs3))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs3:      \r\n","      input_lang3.addSentence(pair[0])\r\n","      output_lang3.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang3.name, input_lang3.n_words)\r\n","    print(output_lang3.name, output_lang3.n_words)\r\n","\r\n","\r\n","    #fold 4\r\n","    test_pairs4 = pairs[num_test*3:num_test*4]\r\n","     # collect train pairs\r\n","    train_pairs4 = pairs[:num_test*3]\r\n","    for x in pairs[num_test*4:]:\r\n","      train_pairs4.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs4))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs4:      \r\n","      input_lang4.addSentence(pair[0])\r\n","      output_lang4.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang4.name, input_lang4.n_words)\r\n","    print(output_lang4.name, output_lang4.n_words)\r\n","\r\n","    #fold 5\r\n","    test_pairs5 = pairs[num_test*4:]\r\n","     # collect train pairs\r\n","    train_pairs5 = pairs[:num_test*4]\r\n","    print(\"Number of train pairs:\", len(train_pairs5))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs5:      \r\n","      input_lang5.addSentence(pair[0])\r\n","      output_lang5.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang5.name, input_lang5.n_words)\r\n","    print(output_lang5.name, output_lang5.n_words)\r\n","\r\n","\r\n","    return (input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4,input_lang5, output_lang5,train_pairs1, \r\n","            test_pairs1, train_pairs2, test_pairs2, train_pairs3, test_pairs3,train_pairs4, test_pairs4,train_pairs5, test_pairs5)\r\n","\r\n","\r\n","(input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, train_pairs1, test_pairs1, train_pairs2,\r\n"," test_pairs2,train_pairs3, test_pairs3, train_pairs4, test_pairs4,train_pairs5, test_pairs5) = prepareData(sents_ru, sents_en)\r\n","print(random.choice(train_pairs1))\r\n","print(random.choice(train_pairs2))\r\n","print(random.choice(train_pairs3))\r\n","print(random.choice(train_pairs4))\r\n","print(random.choice(train_pairs5))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Read 165602 sentence pairs\n","Number of test pairs: 33120\n","Number of train pairs: 132482\n","Counting words...\n","Counted words:\n","ru 211091\n","en 42042\n","Number of train pairs: 132482\n","Counting words...\n","Counted words:\n","ru 212073\n","en 42220\n","Number of train pairs: 132482\n","Counting words...\n","Counted words:\n","ru 211329\n","en 42015\n","Number of train pairs: 132482\n","Counting words...\n","Counted words:\n","ru 211937\n","en 42215\n","Number of train pairs: 132480\n","Counting words...\n","Counted words:\n","ru 211829\n","en 42191\n","['Предрассудки должны уступить место эмпатии, а отчужденность уважению .\\n', 'prejudice must make way for empathy and alienation for respect .']\n","['Такие эпидемии носят взрывной характер и охватывают все население в считанные недели .\\n', 'in urban areas where indigenous workers tend to lack immunity to malaria occasional episodes of the disease result in reduced productivity .']\n","['К тому же существовали влиятельные организации предпринимателей, вовлеченные в процесс принятия решений .\\n', 'there were also influential entrepreneurs and business organizations that were actively involved in the decision making process .']\n","['Вражда между Пакистанской народной партией, лидером которой является вдовец Беназир, Асиф Али Зардари, и Пакистанской мусульманской лигой, лидером которой является бывший премьер министр Наваз Шариф, дала Мушаррафу возможность восстановиться после того, как его сторонники были побеждены на февральских выборах .\\n', 'feuding between the pakistan people s party led by benazir s widower asif ali zardari and the pakistan muslim league n led by former prime minister nawaz sharif had given musharraf a chance to regain some standing after his allies were defeated in the february elections .']\n","['Бесполетная зона для Сирии\\n', 'a no fly zone for syria']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"npNTNDUOOwoC","executionInfo":{"status":"ok","timestamp":1615739147945,"user_tz":-480,"elapsed":34943,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 171\r\n","class AttnDecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","\r\n","        attn_weights = F.softmax(\r\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang1, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang1, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs1))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjoCFY3nTmBG","executionInfo":{"status":"ok","timestamp":1615739150191,"user_tz":-480,"elapsed":37187,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang1, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang1.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang1, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang1.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang1.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs1)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs1:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs1:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08M4DvfPToJk","executionInfo":{"status":"ok","timestamp":1615747384279,"user_tz":-480,"elapsed":8271272,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"e8b46282-5a5e-499e-ca10-6cdc398bbf01"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang1.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang1.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["1m 37s (- 120m 24s) (1000 1%) 5.9405\n","3m 8s (- 114m 30s) (2000 2%) 5.6117\n","4m 39s (- 111m 56s) (3000 4%) 5.4388\n","6m 10s (- 109m 39s) (4000 5%) 5.4012\n","7m 43s (- 108m 8s) (5000 6%) 5.3503\n","9m 14s (- 106m 14s) (6000 8%) 5.3070\n","10m 46s (- 104m 42s) (7000 9%) 5.1513\n","12m 16s (- 102m 49s) (8000 10%) 5.2881\n","13m 48s (- 101m 16s) (9000 12%) 5.3562\n","15m 20s (- 99m 43s) (10000 13%) 5.2231\n","16m 51s (- 98m 4s) (11000 14%) 5.2994\n","18m 25s (- 96m 41s) (12000 16%) 5.5430\n","19m 57s (- 95m 11s) (13000 17%) 5.3556\n","21m 32s (- 93m 53s) (14000 18%) 5.6556\n","23m 7s (- 92m 31s) (15000 20%) 5.5668\n","24m 43s (- 91m 11s) (16000 21%) 5.5586\n","26m 21s (- 89m 54s) (17000 22%) 5.5855\n","27m 55s (- 88m 25s) (18000 24%) 5.4495\n","29m 32s (- 87m 5s) (19000 25%) 5.5233\n","31m 10s (- 85m 43s) (20000 26%) 5.6082\n","32m 48s (- 84m 21s) (21000 28%) 5.5658\n","34m 26s (- 82m 57s) (22000 29%) 5.4808\n","36m 3s (- 81m 32s) (23000 30%) 5.5435\n","37m 42s (- 80m 7s) (24000 32%) 5.5301\n","39m 19s (- 78m 38s) (25000 33%) 5.4095\n","40m 55s (- 77m 8s) (26000 34%) 5.4757\n","42m 29s (- 75m 31s) (27000 36%) 5.4458\n","44m 6s (- 74m 2s) (28000 37%) 5.5054\n","45m 45s (- 72m 35s) (29000 38%) 5.5707\n","47m 23s (- 71m 4s) (30000 40%) 5.4658\n","48m 59s (- 69m 32s) (31000 41%) 5.5145\n","50m 41s (- 68m 6s) (32000 42%) 5.5973\n","52m 18s (- 66m 33s) (33000 44%) 5.4496\n","53m 56s (- 65m 2s) (34000 45%) 5.3775\n","55m 35s (- 63m 31s) (35000 46%) 5.4307\n","57m 13s (- 61m 59s) (36000 48%) 5.4466\n","58m 50s (- 60m 25s) (37000 49%) 5.4627\n","60m 26s (- 58m 50s) (38000 50%) 5.4612\n","62m 5s (- 57m 19s) (39000 52%) 5.4781\n","63m 40s (- 55m 43s) (40000 53%) 5.3911\n","65m 19s (- 54m 10s) (41000 54%) 5.4721\n","66m 58s (- 52m 37s) (42000 56%) 5.4376\n","68m 36s (- 51m 3s) (43000 57%) 5.3710\n","70m 15s (- 49m 30s) (44000 58%) 5.4335\n","71m 52s (- 47m 55s) (45000 60%) 5.3860\n","73m 30s (- 46m 20s) (46000 61%) 5.4463\n","75m 8s (- 44m 46s) (47000 62%) 5.4853\n","76m 44s (- 43m 10s) (48000 64%) 5.3397\n","78m 24s (- 41m 36s) (49000 65%) 5.4218\n","80m 2s (- 40m 1s) (50000 66%) 5.3469\n","81m 38s (- 38m 25s) (51000 68%) 5.2878\n","83m 16s (- 36m 50s) (52000 69%) 5.4343\n","84m 54s (- 35m 14s) (53000 70%) 5.3632\n","86m 28s (- 33m 37s) (54000 72%) 5.3928\n","88m 4s (- 32m 1s) (55000 73%) 5.5059\n","89m 42s (- 30m 26s) (56000 74%) 5.3677\n","91m 18s (- 28m 50s) (57000 76%) 5.3060\n","92m 56s (- 27m 14s) (58000 77%) 5.3900\n","94m 34s (- 25m 38s) (59000 78%) 5.2638\n","96m 13s (- 24m 3s) (60000 80%) 5.3922\n","97m 48s (- 22m 26s) (61000 81%) 5.3340\n","99m 25s (- 20m 50s) (62000 82%) 5.2880\n","101m 3s (- 19m 14s) (63000 84%) 5.3186\n","102m 40s (- 17m 38s) (64000 85%) 5.3161\n","104m 14s (- 16m 2s) (65000 86%) 5.3907\n","105m 50s (- 14m 25s) (66000 88%) 5.3116\n","107m 24s (- 12m 49s) (67000 89%) 5.2732\n","109m 0s (- 11m 13s) (68000 90%) 5.3176\n","110m 33s (- 9m 36s) (69000 92%) 5.2809\n","112m 9s (- 8m 0s) (70000 93%) 5.2265\n","113m 42s (- 6m 24s) (71000 94%) 5.2389\n","115m 18s (- 4m 48s) (72000 96%) 5.3052\n","116m 56s (- 3m 12s) (73000 97%) 5.3118\n","118m 34s (- 1m 36s) (74000 98%) 5.3362\n","120m 8s (- 0m 0s) (75000 100%) 5.2098\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are  [0.1768012452062267, 0.05163763584436174, 0.01700792816963742]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8X7TtXWDvQCS"},"source":["###Fold2"]},{"cell_type":"code","metadata":{"id":"zTgC4HZSt6XD","executionInfo":{"status":"ok","timestamp":1615747384582,"user_tz":-480,"elapsed":8271572,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 171\r\n","class AttnDecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","\r\n","        attn_weights = F.softmax(\r\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang2, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang2, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs2))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xj4EasFzvVmP","executionInfo":{"status":"ok","timestamp":1615747384889,"user_tz":-480,"elapsed":8271877,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang2, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang2.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang2, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang2.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang2.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs2)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs2:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs2:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ab6RRAYUvcdZ","executionInfo":{"status":"ok","timestamp":1615755320129,"user_tz":-480,"elapsed":16207114,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"59f2d45c-138f-43f5-c32a-c87d53f59c2b"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang2.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang2.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["1m 39s (- 122m 56s) (1000 1%) 5.9565\n","3m 8s (- 114m 36s) (2000 2%) 5.6229\n","4m 34s (- 109m 58s) (3000 4%) 5.4487\n","6m 3s (- 107m 38s) (4000 5%) 5.3216\n","7m 36s (- 106m 29s) (5000 6%) 5.4073\n","9m 6s (- 104m 42s) (6000 8%) 5.3419\n","10m 34s (- 102m 40s) (7000 9%) 5.2339\n","12m 2s (- 100m 52s) (8000 10%) 5.3764\n","13m 30s (- 99m 5s) (9000 12%) 5.3237\n","15m 3s (- 97m 52s) (10000 13%) 5.5272\n","16m 37s (- 96m 41s) (11000 14%) 5.5317\n","18m 11s (- 95m 30s) (12000 16%) 5.5646\n","19m 44s (- 94m 8s) (13000 17%) 5.5076\n","21m 21s (- 93m 5s) (14000 18%) 5.6294\n","22m 59s (- 91m 57s) (15000 20%) 5.6396\n","24m 32s (- 90m 28s) (16000 21%) 5.5951\n","26m 5s (- 89m 0s) (17000 22%) 5.6049\n","27m 40s (- 87m 39s) (18000 24%) 5.5751\n","29m 10s (- 86m 0s) (19000 25%) 5.5098\n","30m 45s (- 84m 35s) (20000 26%) 5.5915\n","32m 23s (- 83m 17s) (21000 28%) 5.5432\n","33m 57s (- 81m 48s) (22000 29%) 5.5457\n","35m 33s (- 80m 24s) (23000 30%) 5.5360\n","37m 10s (- 79m 0s) (24000 32%) 5.4750\n","38m 44s (- 77m 28s) (25000 33%) 5.3914\n","40m 19s (- 75m 59s) (26000 34%) 5.5024\n","41m 51s (- 74m 25s) (27000 36%) 5.4533\n","43m 28s (- 72m 58s) (28000 37%) 5.5032\n","45m 3s (- 71m 28s) (29000 38%) 5.4511\n","46m 38s (- 69m 57s) (30000 40%) 5.4539\n","48m 12s (- 68m 26s) (31000 41%) 5.4949\n","49m 44s (- 66m 50s) (32000 42%) 5.3491\n","51m 21s (- 65m 21s) (33000 44%) 5.5092\n","52m 55s (- 63m 49s) (34000 45%) 5.4471\n","54m 29s (- 62m 16s) (35000 46%) 5.3417\n","56m 4s (- 60m 44s) (36000 48%) 5.3742\n","57m 39s (- 59m 12s) (37000 49%) 5.3343\n","59m 12s (- 57m 39s) (38000 50%) 5.3783\n","60m 48s (- 56m 7s) (39000 52%) 5.4721\n","62m 25s (- 54m 37s) (40000 53%) 5.3524\n","64m 3s (- 53m 7s) (41000 54%) 5.4492\n","65m 38s (- 51m 34s) (42000 56%) 5.3751\n","67m 11s (- 49m 59s) (43000 57%) 5.4174\n","68m 48s (- 48m 28s) (44000 58%) 5.3893\n","70m 25s (- 46m 56s) (45000 60%) 5.3656\n","71m 57s (- 45m 22s) (46000 61%) 5.3934\n","73m 31s (- 43m 48s) (47000 62%) 5.4474\n","75m 8s (- 42m 15s) (48000 64%) 5.3955\n","76m 45s (- 40m 43s) (49000 65%) 5.3175\n","78m 23s (- 39m 11s) (50000 66%) 5.2931\n","80m 0s (- 37m 39s) (51000 68%) 5.3952\n","81m 40s (- 36m 7s) (52000 69%) 5.4291\n","83m 21s (- 34m 35s) (53000 70%) 5.4276\n","84m 57s (- 33m 2s) (54000 72%) 5.3241\n","86m 34s (- 31m 28s) (55000 73%) 5.2903\n","88m 11s (- 29m 55s) (56000 74%) 5.2204\n","89m 48s (- 28m 21s) (57000 76%) 5.3056\n","91m 26s (- 26m 47s) (58000 77%) 5.2087\n","93m 3s (- 25m 14s) (59000 78%) 5.2823\n","94m 37s (- 23m 39s) (60000 80%) 5.2191\n","96m 12s (- 22m 4s) (61000 81%) 5.3521\n","97m 49s (- 20m 30s) (62000 82%) 5.3561\n","99m 23s (- 18m 55s) (63000 84%) 5.2589\n","100m 57s (- 17m 21s) (64000 85%) 5.3032\n","102m 33s (- 15m 46s) (65000 86%) 5.2074\n","104m 7s (- 14m 11s) (66000 88%) 5.2511\n","105m 41s (- 12m 37s) (67000 89%) 5.2722\n","107m 16s (- 11m 2s) (68000 90%) 5.3017\n","108m 49s (- 9m 27s) (69000 92%) 5.2001\n","110m 22s (- 7m 53s) (70000 93%) 5.2412\n","112m 1s (- 6m 18s) (71000 94%) 5.3359\n","113m 40s (- 4m 44s) (72000 96%) 5.2419\n","115m 19s (- 3m 9s) (73000 97%) 5.2526\n","116m 58s (- 1m 34s) (74000 98%) 5.2885\n","118m 38s (- 0m 0s) (75000 100%) 5.2090\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are  [0.16423533754007744, 0.049721334882000694, 0.017637536703326705]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_1_JxzKvxF5N"},"source":["###Fold 3"]},{"cell_type":"code","metadata":{"id":"WeLVXQOhxCMM","executionInfo":{"status":"ok","timestamp":1615755320462,"user_tz":-480,"elapsed":16207445,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 171\r\n","class AttnDecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","\r\n","        attn_weights = F.softmax(\r\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang3, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang3, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs3))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"9bSwRykXxK_K","executionInfo":{"status":"ok","timestamp":1615755320795,"user_tz":-480,"elapsed":16207776,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang3, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang3.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang3, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang3.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang3.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs3)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs3:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs3:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"aDUlbFWuxLFl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615763669088,"user_tz":-480,"elapsed":24556066,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"e601b156-6abc-4fd3-afcb-f6a26582dae1"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang3.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang3.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["1m 40s (- 123m 29s) (1000 1%) 6.0392\n","3m 12s (- 116m 48s) (2000 2%) 5.6738\n","4m 40s (- 112m 17s) (3000 4%) 5.3470\n","6m 10s (- 109m 39s) (4000 5%) 5.3848\n","7m 39s (- 107m 16s) (5000 6%) 5.2301\n","9m 12s (- 105m 48s) (6000 8%) 5.2539\n","10m 44s (- 104m 20s) (7000 9%) 5.2574\n","12m 13s (- 102m 19s) (8000 10%) 5.0526\n","13m 44s (- 100m 48s) (9000 12%) 5.2312\n","15m 19s (- 99m 34s) (10000 13%) 5.3521\n","16m 52s (- 98m 11s) (11000 14%) 5.4534\n","18m 29s (- 97m 4s) (12000 16%) 5.5194\n","20m 5s (- 95m 51s) (13000 17%) 5.6494\n","21m 44s (- 94m 41s) (14000 18%) 5.5978\n","23m 22s (- 93m 28s) (15000 20%) 5.6650\n","24m 58s (- 92m 5s) (16000 21%) 5.5339\n","26m 35s (- 90m 43s) (17000 22%) 5.5611\n","28m 14s (- 89m 27s) (18000 24%) 5.6435\n","29m 53s (- 88m 5s) (19000 25%) 5.5604\n","31m 30s (- 86m 39s) (20000 26%) 5.4393\n","33m 9s (- 85m 15s) (21000 28%) 5.5880\n","34m 46s (- 83m 47s) (22000 29%) 5.5409\n","36m 26s (- 82m 24s) (23000 30%) 5.6192\n","38m 4s (- 80m 54s) (24000 32%) 5.5647\n","39m 44s (- 79m 29s) (25000 33%) 5.5424\n","41m 20s (- 77m 54s) (26000 34%) 5.5184\n","42m 57s (- 76m 21s) (27000 36%) 5.5832\n","44m 34s (- 74m 49s) (28000 37%) 5.4772\n","46m 12s (- 73m 17s) (29000 38%) 5.4669\n","47m 49s (- 71m 44s) (30000 40%) 5.4787\n","49m 26s (- 70m 10s) (31000 41%) 5.5244\n","51m 4s (- 68m 37s) (32000 42%) 5.4266\n","52m 42s (- 67m 4s) (33000 44%) 5.4815\n","54m 17s (- 65m 28s) (34000 45%) 5.5037\n","55m 56s (- 63m 56s) (35000 46%) 5.3550\n","57m 35s (- 62m 23s) (36000 48%) 5.4461\n","59m 11s (- 60m 47s) (37000 49%) 5.5053\n","60m 47s (- 59m 11s) (38000 50%) 5.3647\n","62m 22s (- 57m 35s) (39000 52%) 5.3693\n","64m 1s (- 56m 1s) (40000 53%) 5.4071\n","65m 38s (- 54m 26s) (41000 54%) 5.3723\n","67m 13s (- 52m 49s) (42000 56%) 5.2573\n","68m 49s (- 51m 12s) (43000 57%) 5.3800\n","70m 26s (- 49m 37s) (44000 58%) 5.2959\n","72m 6s (- 48m 4s) (45000 60%) 5.4586\n","73m 43s (- 46m 28s) (46000 61%) 5.4251\n","75m 20s (- 44m 52s) (47000 62%) 5.3174\n","76m 57s (- 43m 17s) (48000 64%) 5.4138\n","78m 34s (- 41m 41s) (49000 65%) 5.3183\n","80m 9s (- 40m 4s) (50000 66%) 5.3722\n","81m 45s (- 38m 28s) (51000 68%) 5.3550\n","83m 20s (- 36m 51s) (52000 69%) 5.2717\n","84m 59s (- 35m 16s) (53000 70%) 5.3560\n","86m 34s (- 33m 40s) (54000 72%) 5.4119\n","88m 12s (- 32m 4s) (55000 73%) 5.3342\n","89m 51s (- 30m 29s) (56000 74%) 5.2660\n","91m 28s (- 28m 53s) (57000 76%) 5.4051\n","93m 4s (- 27m 16s) (58000 77%) 5.2843\n","94m 42s (- 25m 41s) (59000 78%) 5.3534\n","96m 23s (- 24m 5s) (60000 80%) 5.5040\n","98m 2s (- 22m 30s) (61000 81%) 5.3530\n","99m 41s (- 20m 54s) (62000 82%) 5.3075\n","101m 18s (- 19m 17s) (63000 84%) 5.3901\n","102m 54s (- 17m 41s) (64000 85%) 5.4006\n","104m 32s (- 16m 4s) (65000 86%) 5.2745\n","106m 9s (- 14m 28s) (66000 88%) 5.2692\n","107m 45s (- 12m 52s) (67000 89%) 5.2955\n","109m 22s (- 11m 15s) (68000 90%) 5.2435\n","110m 59s (- 9m 39s) (69000 92%) 5.3700\n","112m 36s (- 8m 2s) (70000 93%) 5.2479\n","114m 13s (- 6m 26s) (71000 94%) 5.2633\n","115m 53s (- 4m 49s) (72000 96%) 5.3394\n","117m 30s (- 3m 13s) (73000 97%) 5.3113\n","119m 7s (- 1m 36s) (74000 98%) 5.3132\n","120m 44s (- 0m 0s) (75000 100%) 5.1962\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are  [0.16610257214986976, 0.049626392945869416, 0.01617602061221242]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"34QQDEirydMQ"},"source":["###Fold 4"]},{"cell_type":"code","metadata":{"id":"zCnOu5OXyPVu","executionInfo":{"status":"ok","timestamp":1615763669494,"user_tz":-480,"elapsed":24556469,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 171\r\n","class AttnDecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","\r\n","        attn_weights = F.softmax(\r\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang4, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang4, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs4))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"avak6eD9yXww","executionInfo":{"status":"ok","timestamp":1615763669793,"user_tz":-480,"elapsed":24556766,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang4, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang4.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang4, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang4.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang4.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs4)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs4:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs4:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVOKFdzNyYXX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615771915652,"user_tz":-480,"elapsed":32802622,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"ea7d5e8b-fff1-466a-d19a-a61bd02590c0"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang4.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang4.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["1m 42s (- 127m 0s) (1000 1%) 6.1550\n","3m 15s (- 118m 43s) (2000 2%) 5.6642\n","4m 45s (- 114m 15s) (3000 4%) 5.4732\n","6m 17s (- 111m 43s) (4000 5%) 5.5142\n","7m 44s (- 108m 28s) (5000 6%) 5.3026\n","9m 14s (- 106m 15s) (6000 8%) 5.1554\n","10m 46s (- 104m 39s) (7000 9%) 5.2266\n","12m 18s (- 103m 5s) (8000 10%) 5.3825\n","13m 46s (- 101m 1s) (9000 12%) 5.3107\n","15m 23s (- 100m 3s) (10000 13%) 5.4961\n","16m 58s (- 98m 46s) (11000 14%) 5.5642\n","18m 31s (- 97m 14s) (12000 16%) 5.5043\n","20m 8s (- 96m 3s) (13000 17%) 5.5714\n","21m 43s (- 94m 37s) (14000 18%) 5.5069\n","23m 18s (- 93m 14s) (15000 20%) 5.5685\n","24m 52s (- 91m 44s) (16000 21%) 5.4671\n","26m 26s (- 90m 12s) (17000 22%) 5.4313\n","28m 2s (- 88m 48s) (18000 24%) 5.4769\n","29m 39s (- 87m 23s) (19000 25%) 5.5002\n","31m 15s (- 85m 56s) (20000 26%) 5.5580\n","32m 48s (- 84m 21s) (21000 28%) 5.4067\n","34m 22s (- 82m 47s) (22000 29%) 5.4812\n","35m 58s (- 81m 19s) (23000 30%) 5.5648\n","37m 37s (- 79m 56s) (24000 32%) 5.4660\n","39m 11s (- 78m 22s) (25000 33%) 5.3084\n","40m 48s (- 76m 54s) (26000 34%) 5.4263\n","42m 25s (- 75m 24s) (27000 36%) 5.4665\n","44m 2s (- 73m 56s) (28000 37%) 5.4829\n","45m 39s (- 72m 25s) (29000 38%) 5.4846\n","47m 16s (- 70m 54s) (30000 40%) 5.5247\n","48m 53s (- 69m 24s) (31000 41%) 5.4610\n","50m 29s (- 67m 50s) (32000 42%) 5.4706\n","52m 8s (- 66m 21s) (33000 44%) 5.4338\n","53m 46s (- 64m 50s) (34000 45%) 5.4401\n","55m 22s (- 63m 17s) (35000 46%) 5.3564\n","56m 58s (- 61m 43s) (36000 48%) 5.4535\n","58m 36s (- 60m 11s) (37000 49%) 5.4626\n","60m 14s (- 58m 38s) (38000 50%) 5.3849\n","61m 53s (- 57m 8s) (39000 52%) 5.4117\n","63m 29s (- 55m 33s) (40000 53%) 5.3315\n","65m 4s (- 53m 57s) (41000 54%) 5.4174\n","66m 40s (- 52m 23s) (42000 56%) 5.3744\n","68m 18s (- 50m 50s) (43000 57%) 5.3060\n","69m 55s (- 49m 16s) (44000 58%) 5.3406\n","71m 31s (- 47m 41s) (45000 60%) 5.3229\n","73m 6s (- 46m 5s) (46000 61%) 5.3370\n","74m 42s (- 44m 30s) (47000 62%) 5.3819\n","76m 20s (- 42m 56s) (48000 64%) 5.2714\n","77m 59s (- 41m 23s) (49000 65%) 5.3280\n","79m 36s (- 39m 48s) (50000 66%) 5.3804\n","81m 12s (- 38m 13s) (51000 68%) 5.3875\n","82m 51s (- 36m 38s) (52000 69%) 5.3617\n","84m 29s (- 35m 4s) (53000 70%) 5.3315\n","86m 6s (- 33m 29s) (54000 72%) 5.2647\n","87m 41s (- 31m 53s) (55000 73%) 5.3068\n","89m 20s (- 30m 18s) (56000 74%) 5.3687\n","90m 57s (- 28m 43s) (57000 76%) 5.3672\n","92m 36s (- 27m 8s) (58000 77%) 5.3636\n","94m 14s (- 25m 33s) (59000 78%) 5.3291\n","95m 52s (- 23m 58s) (60000 80%) 5.3784\n","97m 30s (- 22m 22s) (61000 81%) 5.3257\n","99m 7s (- 20m 47s) (62000 82%) 5.2044\n","100m 42s (- 19m 10s) (63000 84%) 5.2849\n","102m 16s (- 17m 34s) (64000 85%) 5.2527\n","103m 56s (- 15m 59s) (65000 86%) 5.3225\n","105m 32s (- 14m 23s) (66000 88%) 5.3108\n","107m 12s (- 12m 48s) (67000 89%) 5.2909\n","108m 51s (- 11m 12s) (68000 90%) 5.2505\n","110m 30s (- 9m 36s) (69000 92%) 5.2989\n","112m 3s (- 8m 0s) (70000 93%) 5.1869\n","113m 40s (- 6m 24s) (71000 94%) 5.1647\n","115m 20s (- 4m 48s) (72000 96%) 5.2765\n","117m 0s (- 3m 12s) (73000 97%) 5.3157\n","118m 42s (- 1m 36s) (74000 98%) 5.2401\n","120m 20s (- 0m 0s) (75000 100%) 5.1965\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are  [0.17593041538842216, 0.05460391262906831, 0.018418297618813837]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DtGbDe1GzSK9"},"source":["###Fold 5"]},{"cell_type":"code","metadata":{"id":"rM5o8g5vzQE7","executionInfo":{"status":"ok","timestamp":1615771916173,"user_tz":-480,"elapsed":32803140,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 171\r\n","class AttnDecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","\r\n","        attn_weights = F.softmax(\r\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","\r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang5, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang5, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs5))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"JP78TY53zYHd","executionInfo":{"status":"ok","timestamp":1615771916571,"user_tz":-480,"elapsed":32803536,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang5, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang5.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang5, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang5.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang5.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs5)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs5:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs5:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"6u-YKVdSzaVV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615780214528,"user_tz":-480,"elapsed":41101490,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"7d9292f0-5dac-4404-cfbd-c1e411c2046a"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang5.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang5.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["1m 42s (- 126m 32s) (1000 1%) 6.0198\n","3m 11s (- 116m 38s) (2000 2%) 5.6477\n","4m 43s (- 113m 19s) (3000 4%) 5.4361\n","6m 11s (- 109m 53s) (4000 5%) 5.3919\n","7m 40s (- 107m 26s) (5000 6%) 5.1607\n","9m 12s (- 105m 58s) (6000 8%) 5.2654\n","10m 40s (- 103m 40s) (7000 9%) 5.2607\n","12m 9s (- 101m 45s) (8000 10%) 5.1938\n","13m 39s (- 100m 8s) (9000 12%) 5.2493\n","15m 8s (- 98m 26s) (10000 13%) 5.2322\n","16m 42s (- 97m 11s) (11000 14%) 5.3696\n","18m 13s (- 95m 39s) (12000 16%) 5.4692\n","19m 47s (- 94m 25s) (13000 17%) 5.5107\n","21m 23s (- 93m 12s) (14000 18%) 5.6448\n","23m 1s (- 92m 7s) (15000 20%) 5.5721\n","24m 38s (- 90m 50s) (16000 21%) 5.5813\n","26m 14s (- 89m 30s) (17000 22%) 5.5862\n","27m 52s (- 88m 17s) (18000 24%) 5.5926\n","29m 30s (- 86m 57s) (19000 25%) 5.6454\n","31m 7s (- 85m 36s) (20000 26%) 5.5560\n","32m 42s (- 84m 6s) (21000 28%) 5.5169\n","34m 16s (- 82m 33s) (22000 29%) 5.5233\n","35m 51s (- 81m 4s) (23000 30%) 5.4890\n","37m 28s (- 79m 38s) (24000 32%) 5.5277\n","39m 6s (- 78m 12s) (25000 33%) 5.4980\n","40m 43s (- 76m 44s) (26000 34%) 5.5182\n","42m 19s (- 75m 13s) (27000 36%) 5.4696\n","43m 54s (- 73m 42s) (28000 37%) 5.4987\n","45m 30s (- 72m 11s) (29000 38%) 5.5347\n","47m 5s (- 70m 37s) (30000 40%) 5.3960\n","48m 38s (- 69m 1s) (31000 41%) 5.4494\n","50m 11s (- 67m 27s) (32000 42%) 5.3973\n","51m 46s (- 65m 53s) (33000 44%) 5.3620\n","53m 23s (- 64m 22s) (34000 45%) 5.3640\n","54m 58s (- 62m 49s) (35000 46%) 5.3876\n","56m 35s (- 61m 18s) (36000 48%) 5.4592\n","58m 12s (- 59m 46s) (37000 49%) 5.4241\n","59m 44s (- 58m 10s) (38000 50%) 5.3674\n","61m 18s (- 56m 35s) (39000 52%) 5.4038\n","62m 53s (- 55m 1s) (40000 53%) 5.3663\n","64m 27s (- 53m 27s) (41000 54%) 5.4694\n","66m 4s (- 51m 54s) (42000 56%) 5.3791\n","67m 40s (- 50m 21s) (43000 57%) 5.3331\n","69m 19s (- 48m 50s) (44000 58%) 5.3741\n","70m 54s (- 47m 16s) (45000 60%) 5.4043\n","72m 30s (- 45m 42s) (46000 61%) 5.3743\n","74m 6s (- 44m 8s) (47000 62%) 5.3194\n","75m 45s (- 42m 36s) (48000 64%) 5.3971\n","77m 26s (- 41m 5s) (49000 65%) 5.3829\n","79m 3s (- 39m 31s) (50000 66%) 5.3177\n","80m 41s (- 37m 58s) (51000 68%) 5.3899\n","82m 19s (- 36m 24s) (52000 69%) 5.3071\n","83m 56s (- 34m 50s) (53000 70%) 5.3626\n","85m 33s (- 33m 16s) (54000 72%) 5.3726\n","87m 11s (- 31m 42s) (55000 73%) 5.3579\n","88m 47s (- 30m 7s) (56000 74%) 5.3372\n","90m 22s (- 28m 32s) (57000 76%) 5.3313\n","92m 0s (- 26m 58s) (58000 77%) 5.3239\n","93m 39s (- 25m 23s) (59000 78%) 5.4041\n","95m 15s (- 23m 48s) (60000 80%) 5.2946\n","96m 53s (- 22m 14s) (61000 81%) 5.4001\n","98m 32s (- 20m 39s) (62000 82%) 5.4014\n","100m 4s (- 19m 3s) (63000 84%) 5.3618\n","101m 40s (- 17m 28s) (64000 85%) 5.3604\n","103m 19s (- 15m 53s) (65000 86%) 5.3178\n","104m 58s (- 14m 18s) (66000 88%) 5.4179\n","106m 33s (- 12m 43s) (67000 89%) 5.3618\n","108m 12s (- 11m 8s) (68000 90%) 5.3702\n","109m 48s (- 9m 32s) (69000 92%) 5.2361\n","111m 26s (- 7m 57s) (70000 93%) 5.3736\n","113m 3s (- 6m 22s) (71000 94%) 5.2953\n","114m 41s (- 4m 46s) (72000 96%) 5.2501\n","116m 15s (- 3m 11s) (73000 97%) 5.2221\n","117m 49s (- 1m 35s) (74000 98%) 5.2521\n","119m 26s (- 0m 0s) (75000 100%) 5.3022\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are  [0.17488621844466876, 0.050364358352426204, 0.01666713090400781]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P8qMVNHB402u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615780215039,"user_tz":-480,"elapsed":41101998,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"c217f293-649a-47a8-8a06-0a1bbb14f512"},"source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["> Фундаментальный принцип финансовой теории – «диверсификация» или «распространение риска» – подразумевает, что интерес к новым контрактам будет достаточно высоким .\n","\n","= a fundamental principle of financial theory diversification or risk spreading implies that interest in the new contracts will be high .\n","< the is is is is is is that is is is or or . . . . . . . . <EOS>\n","\n","> И в этот раз японские официальные лица подняли вопрос об Азиатском МВФ – альтернативной стратегии без боли от суровости МВФ и непривычной прозрачности .\n","\n","= once again japanese officials made their case for an asian imf an alternative strategy without the pain of imf austerity and the unaccustomed transparency .\n","< so the imf is is to to to to to to to to . . . . . . . . . . . . . . . . . . . . . . . . . <EOS>\n","\n","> Саммит ЕС в декабре 2004 года имеет значение для новейшей истории по ряду причин .\n","\n","= few moments in history hold the promise of the eu summit of december .\n","< the eu has the to to the the to the the . . . . . . . . . . <EOS>\n","\n","> Однако такой аргумент представляется наивным, поскольку не надо быть гением, чтобы сравнить цену на автомобиль в Германии с ценой на аналогичный автомобиль во Франции .\n","\n","= that argument however is naive for it does not take a genius to compare the price of a car in germany with the price of the same car in france .\n","< but this is is is is is is is to to to to to to to to to to . . . . . . . . . . . . . . . . <EOS>\n","\n","> Однако нам следует приспособиться к этой ситуации .\n","\n","= however we need to adapt to this situation .\n","< but we should to to to to to . . . . <EOS>\n","\n","> Однако эта основа правил оказалась иллюзией: принципы всегда нуждаются в поддержке власти; в противном случае они не могут выдержать испытание реальностью .\n","\n","= but this foundation of rules turned out to be an illusion principles always need the support of power otherwise they cannot stand the test of reality .\n","< but this is this is is is is is is is not . . . . . . . . . . . . . . . <EOS>\n","\n","> Также будет нанесён больший урон окружающей среде и увеличится количество сердечных заболеваний и рака пищеварительной системы .\n","\n","= if this continues the result will be animal suffering on an even greater scale than now exists in the west as well as more environmental damage and a rise in heart disease and cancers of the digestive system .\n","< the would be would be and and and and and and and and and and . . . . . . . . . . . <EOS>\n","\n","> Немецкие власти были досадно терпимы к причастности коммерческого банка к сложным инвестиционным ценным бумагам под обеспечение активов, которые держались вдали от их бухгалтерских балансов через так называемые операционные \"каналы\" в Ирландии . \n","\n","= german authorities have been deplorably tolerant of commercial bank involvement in complex asset backed securities investments which were kept off their balance sheets via so called conduit operations in ireland .\n","< the s of to to to to to to to to to to to to to to to to to . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <EOS>\n","\n","> В соответствии с исследованиями общественного мнения, около 90% румын выступали за присоединение к НАТО .\n","\n","= indeed up to the outbreak of this war joining nato was not only official romanian policy but enjoyed massive public and media support .\n","< in the of the the the of the the . . . . . . . . . . <EOS>\n","\n","> Мир, к которому призывала Европа, приближается, и он может потерпеть страшную неудачу без ЕС или крайне улучшиться благодаря ему .\n","\n","= the world that europe has called for is coming closer and it can fail abysmally without the eu or improve at the margin thanks to it .\n","< the eu is to to to to the to the to the the to to . . . . . . . <EOS>\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iOxOnZcrSz9B","executionInfo":{"status":"ok","timestamp":1615780215040,"user_tz":-480,"elapsed":41101997,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}}},"source":[""],"execution_count":24,"outputs":[]}]}