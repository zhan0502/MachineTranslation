{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"AS2_QB_CS_M.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uT-lrh1Xe3ry","executionInfo":{"elapsed":1150,"status":"ok","timestamp":1615650370155,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"},"user_tz":-480},"outputId":"8847b676-0607-4523-8775-9ded37788d5d"},"source":["import sys,os\r\n","if 'google.colab' in sys.modules:\r\n","  from google.colab import drive\r\n","  drive.mount('/content/gdrive')\r\n","  path_to_file = '/content/gdrive/My Drive/AI Sem II/NLP/A2'\r\n","  print(path_to_file)\r\n","  os.chdir(path_to_file)\r\n","  !pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/My Drive/AI Sem II/NLP/A2\n","/content/gdrive/My Drive/AI Sem II/NLP/A2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sUm8xUsPjECA"},"source":["from __future__ import unicode_literals, print_function, division\r\n","from io import open\r\n","import unicodedata\r\n","import string\r\n","import re\r\n","import random\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","from torch import optim\r\n","import torch.nn.functional as F\r\n","\r\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjR9yaPeIEDs","executionInfo":{"elapsed":8195,"status":"ok","timestamp":1615650377215,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"},"user_tz":-480},"outputId":"eb9c2a46-c343-433c-84a6-f73901a92d37"},"source":["data_cs = 'data/training/news-commentary-v9.cs-en.cs'\r\n","data_en = 'data/training/news-commentary-v9.cs-en.en'\r\n","\r\n","with open(data_cs, 'rb') as cs: \r\n","  sents_cs = [line.decode(\"utf-8\") for line in cs]      \r\n"," # sents_cs = [value for value in sents_cs if value != '']   \r\n","with open(data_en, 'rb') as en: \r\n","  sents_en = [line.decode(\"utf-8\") for line in en]\r\n"," # sents_en = [value for value in sents_en if value != '']\r\n","len(sents_en), len(sents_cs)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(146549, 146549)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08DjJdxvxuAW","executionInfo":{"elapsed":8190,"status":"ok","timestamp":1615650377216,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"},"user_tz":-480},"outputId":"60b88f18-9606-4501-f75e-0d3dfde7f985"},"source":["#max length of string \r\n","length_cs = [len(i.split()) for i in sents_cs]\r\n","max(length_cs)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["117"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrrJEeffxuEB","executionInfo":{"elapsed":8559,"status":"ok","timestamp":1615650377591,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"},"user_tz":-480},"outputId":"0278b6b8-8e6c-432c-9832-f1a5ec137927"},"source":["length_en = [len(i.split()) for i in sents_en]\r\n","max(length_en)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["164"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"lXnu1aePaT6s"},"source":["SOS_token = 0\r\n","EOS_token = 1\r\n","\r\n","class Lang:\r\n","  def __init__(self, name):\r\n","    self.name = name\r\n","    self.word2index = {}\r\n","    self.word2count = {}\r\n","    self.index2word = {0: \"SOS\", 1: \"EOS\"}\r\n","    self.n_words = 2\r\n","\r\n","  def addSentence(self, sentence):\r\n","    \r\n","    for word in sentence.split(' '):\r\n","      self.addWord(word)\r\n","  \r\n","  def addWord(self, word):\r\n","    if word not in self.word2index:\r\n","      self.word2index[word] = self.n_words\r\n","      self.word2count[word] = 1\r\n","      self.index2word[self.n_words] = word \r\n","      self.n_words += 1\r\n","    else:\r\n","      self.word2count[word] += 1\r\n","\r\n","# Turn a Unicode string to plain ASCII, thanks to\r\n","# https://stackoverflow.com/a/518232/2809427\r\n","def unicodeToAscii(s):\r\n","    return ''.join(\r\n","        c for c in unicodedata.normalize('NFD', s)\r\n","        if unicodedata.category(c) != 'Mn'\r\n","    )\r\n","\r\n","# Lowercase, trim, and remove non-letter characters\r\n","\r\n","\r\n","def normalizeString(s):\r\n","    s = unicodeToAscii(s.lower().strip())\r\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\r\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\r\n","    return s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaTNz04wdqKa"},"source":["def sent_pairs(lang1=sents_cs, lang2=sents_en):\r\n","  pairs = []\r\n","  for i, (cs_sent, en_sent) in enumerate(zip(lang1, lang2)):\r\n","    #if i < 100:\r\n","      pairs.append([cs_sent, en_sent])\r\n","   # print(i)\r\n","  pairs = [[normalizeString(s) for s in line] for line in pairs]\r\n","  input_lang1 = Lang('cs')\r\n","  output_lang1 = Lang('en')\r\n","\r\n","  input_lang2 = Lang('cs')\r\n","  output_lang2 = Lang('en')\r\n","\r\n","  input_lang3 = Lang('cs')\r\n","  output_lang3 = Lang('en')\r\n","\r\n","  input_lang4 = Lang('cs')\r\n","  output_lang4 = Lang('en')\r\n","\r\n","  input_lang5 = Lang('cs')\r\n","  output_lang5 = Lang('en')\r\n","\r\n","     \r\n","  return input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs\r\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TvQxz_O6IMm8"},"source":["The full process for preparing the data is:\r\n","\r\n","-  Read text file and split into lines, split lines into pairs\r\n","-  Normalize text, filter by length and content\r\n","-  Make word lists from sentences in pairs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ll3A_tPrdF8","executionInfo":{"elapsed":34467,"status":"ok","timestamp":1615650403507,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"},"user_tz":-480},"outputId":"12c96405-1749-45ac-a39a-ed122f4a7ced"},"source":[" def prepareData(lang1=sents_cs, lang2=sents_en):\r\n","    input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, pairs = sent_pairs(lang1, lang2)\r\n","    print(\"Read %s sentence pairs\" % len(pairs))\r\n","\r\n","    #Assumption: as the dataset is news commentary on different topics, there is highly unlikely exactly the same sentences \r\n","    # collect test pairs\r\n","    num_test = int(len(pairs)*0.2)\r\n","    print(\"Number of test pairs:\", num_test)\r\n","    random.seed(1)\r\n","    random.shuffle(pairs)\r\n","    \r\n","    #fold 1\r\n","    test_pairs1 = pairs[:num_test]\r\n","     # collect train pairs\r\n","    train_pairs1 = pairs[num_test:]\r\n","    print(\"Number of train pairs:\", len(train_pairs1))\r\n","    print(\"Counting words...\")\r\n","\r\n","    for pair in train_pairs1:      \r\n","      input_lang1.addSentence(pair[0])\r\n","      output_lang1.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang1.name, input_lang1.n_words)\r\n","    print(output_lang1.name, output_lang1.n_words)\r\n","\r\n","    #fold 2\r\n","    test_pairs2 = pairs[num_test:num_test*2]\r\n","     # collect train pairs\r\n","    train_pairs2 = pairs[:num_test]\r\n","    for x in pairs[num_test*2:]:\r\n","      train_pairs2.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs2))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs2:      \r\n","      input_lang2.addSentence(pair[0])\r\n","      output_lang2.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang2.name, input_lang2.n_words)\r\n","    print(output_lang2.name, output_lang2.n_words)\r\n","\r\n","    #fold 3\r\n","    test_pairs3 = pairs[num_test*2:num_test*3]\r\n","     # collect train pairs\r\n","    train_pairs3 = pairs[:num_test*2]\r\n","    for x in pairs[num_test*3:]:\r\n","      train_pairs3.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs3))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs3:      \r\n","      input_lang3.addSentence(pair[0])\r\n","      output_lang3.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang3.name, input_lang3.n_words)\r\n","    print(output_lang3.name, output_lang3.n_words)\r\n","\r\n","\r\n","    #fold 4\r\n","    test_pairs4 = pairs[num_test*3:num_test*4]\r\n","     # collect train pairs\r\n","    train_pairs4 = pairs[:num_test*3]\r\n","    for x in pairs[num_test*4:]:\r\n","      train_pairs4.append(x)\r\n","    print(\"Number of train pairs:\", len(train_pairs4))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs4:      \r\n","      input_lang4.addSentence(pair[0])\r\n","      output_lang4.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang4.name, input_lang4.n_words)\r\n","    print(output_lang4.name, output_lang4.n_words)\r\n","\r\n","    #fold 5\r\n","    test_pairs5 = pairs[num_test*4:]\r\n","     # collect train pairs\r\n","    train_pairs5 = pairs[:num_test*4]\r\n","    print(\"Number of train pairs:\", len(train_pairs5))\r\n","    print(\"Counting words...\")\r\n","\r\n","\r\n","    for pair in train_pairs5:      \r\n","      input_lang5.addSentence(pair[0])\r\n","      output_lang5.addSentence(pair[1])\r\n","    print(\"Counted words:\")\r\n","    print(input_lang5.name, input_lang5.n_words)\r\n","    print(output_lang5.name, output_lang5.n_words)\r\n","\r\n","\r\n","    return (input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4,input_lang5, output_lang5,train_pairs1, \r\n","            test_pairs1, train_pairs2, test_pairs2, train_pairs3, test_pairs3,train_pairs4, test_pairs4,train_pairs5, test_pairs5)\r\n","\r\n","\r\n","(input_lang1, output_lang1, input_lang2, output_lang2, input_lang3, output_lang3, input_lang4, output_lang4, input_lang5, output_lang5, train_pairs1, test_pairs1, train_pairs2,\r\n"," test_pairs2,train_pairs3, test_pairs3, train_pairs4, test_pairs4,train_pairs5, test_pairs5) = prepareData(sents_cs, sents_en)\r\n","print(random.choice(train_pairs1))\r\n","print(random.choice(train_pairs2))\r\n","print(random.choice(train_pairs3))\r\n","print(random.choice(train_pairs4))\r\n","print(random.choice(train_pairs5))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Read 146549 sentence pairs\n","Number of test pairs: 29309\n","Number of train pairs: 117240\n","Counting words...\n","Counted words:\n","cs 116132\n","en 39006\n","Number of train pairs: 117240\n","Counting words...\n","Counted words:\n","cs 116449\n","en 39121\n","Number of train pairs: 117240\n","Counting words...\n","Counted words:\n","cs 116331\n","en 39085\n","Number of train pairs: 117240\n","Counting words...\n","Counted words:\n","cs 116442\n","en 39107\n","Number of train pairs: 117236\n","Counting words...\n","Counted words:\n","cs 116273\n","en 39139\n","['dozvedela jsem se o tom o dva dny pozdeji prostrednictvim e mailu od sveho bratra ktery se to doslechl od kamarada .', 'i heard about it two days later from my brother by e mail who heard from a friend of his .']\n","['snad se mu to podari znovu .', 'it may do so again .']\n","['proc tedy nezkusit neco podobneho v nemecku zeptali se tamejsi socialni demokrate .', 'so why not try something of this sort in germany social democrat politicians asked ?']\n","['prvnim krokem by melo byt ze zeme ktere v afghanistanu maji jednotky akceptuji ze jako strany zucastnene konfliktu musi byt take stranami zucastnenymi na miru a ze kazda vojenska operace ma dalekosahle a nekdy nevratne politicke dusledky .', 'as a first step countries with forces in afghanistan should accept that as parties to the conflict they need to be parties to the peace as well and that every military operation has far reaching and sometimes irreversible political implications .']\n","['nastroje k uskutecneni fiskalni korekce by tedy mely upevnovat ekonomickou efektivitu nebo ji prinejmensim neposkozovat .', 'thus the tools used to carry out fiscal adjustment should boost economic efficiency or at least not damage it .']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"npNTNDUOOwoC"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 164\r\n","# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN4(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN4, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\r\n","        ##################\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        x=self.fc(hidden)\r\n","        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\r\n","            #################################\r\n","       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        \r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","        \r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang1, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang1, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs1))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjoCFY3nTmBG"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang1, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang1.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang1, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang1.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang1.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs1)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs1:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs1:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"08M4DvfPToJk","outputId":"93b30e51-b30f-4eb6-ddd5-fa7a742d82fd"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang1.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang1.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0m 57s (- 70m 51s) (1000 1%) 6.1901\n","1m 47s (- 65m 11s) (2000 2%) 5.6949\n","2m 37s (- 63m 11s) (3000 4%) 5.5240\n","3m 28s (- 61m 49s) (4000 5%) 5.4729\n","4m 19s (- 60m 28s) (5000 6%) 5.4348\n","5m 8s (- 59m 6s) (6000 8%) 5.3730\n","6m 0s (- 58m 18s) (7000 9%) 5.4697\n","6m 49s (- 57m 8s) (8000 10%) 5.2857\n","7m 41s (- 56m 21s) (9000 12%) 5.5493\n","8m 33s (- 55m 38s) (10000 13%) 5.4635\n","9m 28s (- 55m 6s) (11000 14%) 5.5829\n","10m 19s (- 54m 11s) (12000 16%) 5.4578\n","11m 13s (- 53m 30s) (13000 17%) 5.6443\n","12m 6s (- 52m 45s) (14000 18%) 5.6059\n","13m 0s (- 52m 2s) (15000 20%) 5.6687\n","13m 56s (- 51m 24s) (16000 21%) 5.6622\n","14m 52s (- 50m 44s) (17000 22%) 5.7177\n","15m 46s (- 49m 56s) (18000 24%) 6.4098\n","16m 38s (- 49m 2s) (19000 25%) 7.5012\n","17m 30s (- 48m 8s) (20000 26%) 8.1077\n","18m 21s (- 47m 13s) (21000 28%) 7.5459\n","19m 11s (- 46m 13s) (22000 29%) 7.4910\n","20m 2s (- 45m 19s) (23000 30%) 7.7106\n","20m 54s (- 44m 25s) (24000 32%) 7.9080\n","21m 43s (- 43m 27s) (25000 33%) 7.6437\n","22m 36s (- 42m 37s) (26000 34%) 8.2459\n","23m 29s (- 41m 45s) (27000 36%) 8.4088\n","24m 20s (- 40m 51s) (28000 37%) 8.2333\n","25m 13s (- 40m 0s) (29000 38%) 8.4784\n","26m 6s (- 39m 9s) (30000 40%) 8.4187\n","26m 57s (- 38m 16s) (31000 41%) 7.9717\n","27m 49s (- 37m 23s) (32000 42%) 7.8947\n","28m 39s (- 36m 28s) (33000 44%) 7.5682\n","29m 29s (- 35m 33s) (34000 45%) 7.5678\n","30m 19s (- 34m 39s) (35000 46%) 7.6684\n","31m 9s (- 33m 45s) (36000 48%) 7.5756\n","31m 59s (- 32m 51s) (37000 49%) 7.4884\n","32m 50s (- 31m 58s) (38000 50%) 7.7617\n","33m 40s (- 31m 4s) (39000 52%) 7.5561\n","34m 29s (- 30m 11s) (40000 53%) 7.2676\n","35m 21s (- 29m 19s) (41000 54%) 7.7047\n","36m 12s (- 28m 26s) (42000 56%) 7.6423\n","37m 6s (- 27m 37s) (43000 57%) 7.9777\n","38m 1s (- 26m 47s) (44000 58%) 8.2822\n","38m 53s (- 25m 55s) (45000 60%) 7.6352\n","39m 45s (- 25m 3s) (46000 61%) 7.9547\n","40m 35s (- 24m 10s) (47000 62%) 7.1048\n","41m 24s (- 23m 17s) (48000 64%) 7.2491\n","42m 15s (- 22m 25s) (49000 65%) 7.6217\n","43m 10s (- 21m 35s) (50000 66%) 7.7721\n","44m 1s (- 20m 42s) (51000 68%) 7.5966\n","44m 52s (- 19m 50s) (52000 69%) 7.8319\n","45m 43s (- 18m 58s) (53000 70%) 7.9584\n","46m 35s (- 18m 7s) (54000 72%) 8.2789\n","47m 28s (- 17m 15s) (55000 73%) 7.9804\n","48m 21s (- 16m 24s) (56000 74%) 7.7431\n","49m 14s (- 15m 32s) (57000 76%) 7.9648\n","50m 6s (- 14m 41s) (58000 77%) 8.0147\n","50m 58s (- 13m 49s) (59000 78%) 7.7266\n","51m 49s (- 12m 57s) (60000 80%) 7.5916\n","52m 41s (- 12m 5s) (61000 81%) 7.7595\n","53m 31s (- 11m 13s) (62000 82%) 7.4506\n","54m 24s (- 10m 21s) (63000 84%) 7.7145\n","55m 17s (- 9m 30s) (64000 85%) 7.5484\n","56m 9s (- 8m 38s) (65000 86%) 7.7945\n","57m 2s (- 7m 46s) (66000 88%) 8.0790\n","57m 54s (- 6m 54s) (67000 89%) 7.8239\n","58m 46s (- 6m 3s) (68000 90%) 7.3511\n","59m 38s (- 5m 11s) (69000 92%) 7.6770\n","60m 30s (- 4m 19s) (70000 93%) 8.0494\n","61m 22s (- 3m 27s) (71000 94%) 7.9110\n","62m 13s (- 2m 35s) (72000 96%) 7.5521\n","63m 7s (- 1m 43s) (73000 97%) 8.2701\n","64m 0s (- 0m 51s) (74000 98%) 8.0415\n","64m 53s (- 0m 0s) (75000 100%) 7.9339\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":["Fold 1 Bleu-1, Bleu-2, Bleu-3 scores are  [0.014115098708109675, 0.0009035145956276068, 0.007148332825598325]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8X7TtXWDvQCS"},"source":["###Fold2"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"zTgC4HZSt6XD"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 164\r\n","# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN4(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN4, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\r\n","        ##################\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        x=self.fc(hidden)\r\n","        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\r\n","            #################################\r\n","       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        \r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang2, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang2, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs2))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Xj4EasFzvVmP"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang2, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang2.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang2, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang2.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang2.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs2)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs2:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs2:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"ab6RRAYUvcdZ","outputId":"dc68fb2d-4c5f-4a45-d2ff-8e3af77cf5cf"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang2.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang2.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0m 54s (- 67m 3s) (1000 1%) 5.9628\n","1m 46s (- 64m 44s) (2000 2%) 5.7981\n","2m 38s (- 63m 13s) (3000 4%) 5.6769\n","3m 31s (- 62m 34s) (4000 5%) 5.4452\n","4m 22s (- 61m 13s) (5000 6%) 5.3759\n","5m 14s (- 60m 17s) (6000 8%) 5.4112\n","6m 5s (- 59m 7s) (7000 9%) 5.3845\n","6m 57s (- 58m 15s) (8000 10%) 5.3536\n","7m 49s (- 57m 23s) (9000 12%) 5.4443\n","8m 42s (- 56m 35s) (10000 13%) 5.5067\n","9m 34s (- 55m 41s) (11000 14%) 5.3671\n","10m 28s (- 54m 57s) (12000 16%) 5.5480\n","11m 21s (- 54m 8s) (13000 17%) 5.5620\n","12m 15s (- 53m 23s) (14000 18%) 5.5825\n","13m 9s (- 52m 37s) (15000 20%) 5.6435\n","14m 2s (- 51m 47s) (16000 21%) 5.4682\n","14m 57s (- 51m 0s) (17000 22%) 5.6234\n","15m 54s (- 50m 21s) (18000 24%) 5.6910\n","16m 50s (- 49m 38s) (19000 25%) 5.6357\n","17m 45s (- 48m 49s) (20000 26%) 5.5685\n","18m 40s (- 48m 1s) (21000 28%) 5.6676\n","19m 35s (- 47m 11s) (22000 29%) 5.6018\n","20m 30s (- 46m 22s) (23000 30%) 5.5700\n","21m 26s (- 45m 33s) (24000 32%) 5.6287\n","22m 20s (- 44m 41s) (25000 33%) 5.5320\n","23m 15s (- 43m 50s) (26000 34%) 5.6002\n","24m 12s (- 43m 1s) (27000 36%) 5.5347\n","25m 8s (- 42m 11s) (28000 37%) 5.5323\n","26m 5s (- 41m 22s) (29000 38%) 5.5634\n","26m 59s (- 40m 29s) (30000 40%) 5.5666\n","27m 54s (- 39m 36s) (31000 41%) 5.5615\n","28m 50s (- 38m 45s) (32000 42%) 5.4935\n","29m 46s (- 37m 53s) (33000 44%) 5.5120\n","30m 41s (- 37m 0s) (34000 45%) 5.5244\n","31m 37s (- 36m 8s) (35000 46%) 5.5137\n","32m 33s (- 35m 16s) (36000 48%) 5.5270\n","33m 29s (- 34m 23s) (37000 49%) 5.5149\n","34m 25s (- 33m 30s) (38000 50%) 5.5883\n","35m 18s (- 32m 35s) (39000 52%) 5.6185\n","36m 11s (- 31m 40s) (40000 53%) 5.4589\n","37m 5s (- 30m 45s) (41000 54%) 5.4135\n","38m 0s (- 29m 51s) (42000 56%) 5.4531\n","38m 54s (- 28m 57s) (43000 57%) 5.4241\n","39m 48s (- 28m 2s) (44000 58%) 5.4410\n","40m 43s (- 27m 8s) (45000 60%) 5.4091\n","41m 37s (- 26m 14s) (46000 61%) 5.3962\n","42m 30s (- 25m 19s) (47000 62%) 5.3847\n","43m 25s (- 24m 25s) (48000 64%) 5.4120\n","44m 19s (- 23m 31s) (49000 65%) 5.2916\n","45m 13s (- 22m 36s) (50000 66%) 5.3847\n","46m 6s (- 21m 41s) (51000 68%) 5.3846\n","47m 2s (- 20m 48s) (52000 69%) 5.3752\n","47m 58s (- 19m 54s) (53000 70%) 5.3413\n","48m 52s (- 19m 0s) (54000 72%) 5.4065\n","49m 46s (- 18m 5s) (55000 73%) 5.3021\n","50m 41s (- 17m 11s) (56000 74%) 5.3180\n","51m 35s (- 16m 17s) (57000 76%) 5.3351\n","52m 30s (- 15m 23s) (58000 77%) 5.3860\n","53m 23s (- 14m 28s) (59000 78%) 5.3671\n","54m 18s (- 13m 34s) (60000 80%) 5.3518\n","55m 13s (- 12m 40s) (61000 81%) 5.2750\n","56m 6s (- 11m 45s) (62000 82%) 5.2237\n","57m 0s (- 10m 51s) (63000 84%) 5.3510\n","57m 55s (- 9m 57s) (64000 85%) 5.2338\n","58m 50s (- 9m 3s) (65000 86%) 5.3583\n","59m 45s (- 8m 8s) (66000 88%) 5.3192\n","60m 40s (- 7m 14s) (67000 89%) 5.2644\n","61m 33s (- 6m 20s) (68000 90%) 5.2584\n","62m 28s (- 5m 25s) (69000 92%) 5.1885\n","63m 21s (- 4m 31s) (70000 93%) 5.2521\n","64m 16s (- 3m 37s) (71000 94%) 5.2988\n","65m 10s (- 2m 42s) (72000 96%) 5.2854\n","66m 5s (- 1m 48s) (73000 97%) 5.2825\n","67m 0s (- 0m 54s) (74000 98%) 5.2341\n","67m 54s (- 0m 0s) (75000 100%) 5.2440\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","Fold 2 Bleu-1, Bleu-2, Bleu-3 scores are  [0.12985607666411358, 0.04152403151997156, 0.014391852502871035]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_1_JxzKvxF5N"},"source":["###Fold 3"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"WeLVXQOhxCMM"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 164\r\n","# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN4(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN4, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\r\n","        ##################\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        x=self.fc(hidden)\r\n","        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\r\n","            #################################\r\n","       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        \r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang3, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang3, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs3))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"9bSwRykXxK_K"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang3, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang3.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang3, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang3.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang3.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs3)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs3:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs3:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"aDUlbFWuxLFl","outputId":"74353db5-7a57-4f7a-a201-4e122263146b"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang3.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang3.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0m 55s (- 68m 41s) (1000 1%) 5.9187\n","1m 45s (- 64m 4s) (2000 2%) 5.6584\n","2m 34s (- 61m 47s) (3000 4%) 5.5204\n","3m 24s (- 60m 30s) (4000 5%) 5.5322\n","4m 14s (- 59m 24s) (5000 6%) 5.4370\n","5m 4s (- 58m 19s) (6000 8%) 5.4765\n","5m 56s (- 57m 47s) (7000 9%) 5.5478\n","6m 48s (- 56m 58s) (8000 10%) 5.3960\n","7m 41s (- 56m 25s) (9000 12%) 5.5397\n","8m 33s (- 55m 39s) (10000 13%) 5.4553\n","9m 26s (- 54m 55s) (11000 14%) 5.5478\n","10m 20s (- 54m 20s) (12000 16%) 5.6803\n","11m 14s (- 53m 36s) (13000 17%) 5.6295\n","12m 9s (- 52m 58s) (14000 18%) 5.6485\n","13m 3s (- 52m 15s) (15000 20%) 5.7023\n","13m 59s (- 51m 34s) (16000 21%) 5.7028\n","14m 55s (- 50m 55s) (17000 22%) 5.7342\n","15m 50s (- 50m 8s) (18000 24%) 5.6548\n","16m 45s (- 49m 22s) (19000 25%) 5.6973\n","17m 40s (- 48m 35s) (20000 26%) 5.6049\n","18m 33s (- 47m 44s) (21000 28%) 5.6773\n","19m 29s (- 46m 56s) (22000 29%) 5.6207\n","20m 23s (- 46m 5s) (23000 30%) 5.5892\n","21m 18s (- 45m 15s) (24000 32%) 5.5750\n","22m 12s (- 44m 25s) (25000 33%) 5.5728\n","23m 7s (- 43m 35s) (26000 34%) 5.6113\n","24m 2s (- 42m 44s) (27000 36%) 5.5167\n","24m 57s (- 41m 53s) (28000 37%) 5.5660\n","25m 53s (- 41m 4s) (29000 38%) 5.5727\n","26m 47s (- 40m 11s) (30000 40%) 5.4552\n","27m 41s (- 39m 18s) (31000 41%) 5.5329\n","28m 36s (- 38m 26s) (32000 42%) 5.5026\n","29m 31s (- 37m 34s) (33000 44%) 5.5039\n","30m 25s (- 36m 41s) (34000 45%) 5.4805\n","31m 20s (- 35m 48s) (35000 46%) 5.4973\n","32m 17s (- 34m 58s) (36000 48%) 5.4877\n","33m 14s (- 34m 8s) (37000 49%) 5.5472\n","34m 10s (- 33m 16s) (38000 50%) 5.4386\n","35m 7s (- 32m 25s) (39000 52%) 5.4283\n","36m 1s (- 31m 31s) (40000 53%) 5.4223\n","36m 58s (- 30m 39s) (41000 54%) 5.5177\n","37m 53s (- 29m 46s) (42000 56%) 5.4139\n","38m 47s (- 28m 51s) (43000 57%) 5.3901\n","39m 42s (- 27m 58s) (44000 58%) 5.4028\n","40m 38s (- 27m 5s) (45000 60%) 5.4058\n","41m 34s (- 26m 12s) (46000 61%) 5.4587\n","42m 30s (- 25m 19s) (47000 62%) 5.3847\n","43m 26s (- 24m 25s) (48000 64%) 5.4276\n","44m 20s (- 23m 31s) (49000 65%) 5.4473\n","45m 17s (- 22m 38s) (50000 66%) 5.3963\n","46m 13s (- 21m 45s) (51000 68%) 5.4506\n","47m 10s (- 20m 51s) (52000 69%) 5.4620\n","48m 7s (- 19m 58s) (53000 70%) 5.5015\n","49m 0s (- 19m 3s) (54000 72%) 5.6395\n","49m 55s (- 18m 9s) (55000 73%) 5.4657\n","50m 49s (- 17m 14s) (56000 74%) 5.3141\n","51m 45s (- 16m 20s) (57000 76%) 5.4280\n","52m 40s (- 15m 26s) (58000 77%) 5.4030\n","53m 35s (- 14m 31s) (59000 78%) 5.3565\n","54m 30s (- 13m 37s) (60000 80%) 5.4049\n","55m 26s (- 12m 43s) (61000 81%) 5.3811\n","56m 20s (- 11m 48s) (62000 82%) 5.3407\n","57m 14s (- 10m 54s) (63000 84%) 5.3680\n","58m 10s (- 9m 59s) (64000 85%) 5.4013\n","59m 7s (- 9m 5s) (65000 86%) 5.4196\n","60m 2s (- 8m 11s) (66000 88%) 5.3263\n","60m 56s (- 7m 16s) (67000 89%) 5.3409\n","61m 51s (- 6m 22s) (68000 90%) 5.2684\n","62m 47s (- 5m 27s) (69000 92%) 5.3193\n","63m 42s (- 4m 33s) (70000 93%) 5.3067\n","64m 37s (- 3m 38s) (71000 94%) 5.3150\n","65m 31s (- 2m 43s) (72000 96%) 5.2878\n","66m 23s (- 1m 49s) (73000 97%) 5.2427\n","67m 17s (- 0m 54s) (74000 98%) 5.2814\n","68m 12s (- 0m 0s) (75000 100%) 5.2964\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","Fold 3 Bleu-1, Bleu-2, Bleu-3 scores are  [0.20628612996961418, 0.06878122246373435, 0.023445994329268915]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"34QQDEirydMQ"},"source":["###Fold 4"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"zCnOu5OXyPVu"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 164\r\n","# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN4(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN4, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\r\n","        ##################\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        x=self.fc(hidden)\r\n","        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\r\n","            #################################\r\n","       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        \r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang4, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang4, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs4))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"avak6eD9yXww"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang4, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang4.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang4, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang4.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang4.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs4)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs4:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs4:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"rVOKFdzNyYXX","outputId":"d7bd8d79-d1c4-4838-e39f-1ddc7a0a7379"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang4.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang4.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0m 56s (- 69m 36s) (1000 1%) 5.9459\n","1m 44s (- 63m 20s) (2000 2%) 5.3991\n","2m 33s (- 61m 31s) (3000 4%) 5.5823\n","3m 22s (- 59m 51s) (4000 5%) 5.3424\n","4m 14s (- 59m 17s) (5000 6%) 5.4934\n","5m 2s (- 58m 3s) (6000 8%) 5.4074\n","5m 50s (- 56m 47s) (7000 9%) 5.3742\n","6m 40s (- 55m 57s) (8000 10%) 5.4675\n","7m 31s (- 55m 11s) (9000 12%) 5.3532\n","8m 23s (- 54m 29s) (10000 13%) 5.5558\n","9m 14s (- 53m 48s) (11000 14%) 5.5474\n","10m 8s (- 53m 14s) (12000 16%) 5.5779\n","11m 0s (- 52m 31s) (13000 17%) 5.6139\n","11m 54s (- 51m 54s) (14000 18%) 5.6139\n","12m 48s (- 51m 14s) (15000 20%) 5.6825\n","13m 41s (- 50m 28s) (16000 21%) 5.6023\n","14m 33s (- 49m 40s) (17000 22%) 5.6195\n","15m 27s (- 48m 57s) (18000 24%) 5.6431\n","16m 23s (- 48m 18s) (19000 25%) 5.6506\n","17m 18s (- 47m 35s) (20000 26%) 5.6447\n","18m 12s (- 46m 50s) (21000 28%) 5.6051\n","19m 5s (- 45m 59s) (22000 29%) 5.5960\n","20m 1s (- 45m 15s) (23000 30%) 5.7047\n","20m 55s (- 44m 28s) (24000 32%) 5.5788\n","21m 50s (- 43m 41s) (25000 33%) 5.6852\n","22m 45s (- 42m 54s) (26000 34%) 5.6024\n","23m 40s (- 42m 5s) (27000 36%) 5.6114\n","24m 36s (- 41m 18s) (28000 37%) 5.6472\n","25m 32s (- 40m 30s) (29000 38%) 5.5839\n","26m 28s (- 39m 43s) (30000 40%) 5.6112\n","27m 24s (- 38m 53s) (31000 41%) 5.5202\n","28m 19s (- 38m 3s) (32000 42%) 5.4931\n","29m 13s (- 37m 11s) (33000 44%) 5.5209\n","30m 9s (- 36m 22s) (34000 45%) 5.5165\n","31m 4s (- 35m 30s) (35000 46%) 5.3343\n","31m 56s (- 34m 36s) (36000 48%) 5.1645\n","32m 50s (- 33m 44s) (37000 49%) 5.4035\n","33m 46s (- 32m 52s) (38000 50%) 5.4763\n","34m 40s (- 32m 0s) (39000 52%) 5.4870\n","35m 36s (- 31m 9s) (40000 53%) 5.4590\n","36m 32s (- 30m 18s) (41000 54%) 5.4438\n","37m 28s (- 29m 26s) (42000 56%) 5.4442\n","38m 22s (- 28m 33s) (43000 57%) 5.4140\n","39m 19s (- 27m 42s) (44000 58%) 5.4364\n","40m 15s (- 26m 50s) (45000 60%) 5.4849\n","41m 11s (- 25m 58s) (46000 61%) 5.4308\n","42m 6s (- 25m 5s) (47000 62%) 5.4118\n","43m 2s (- 24m 12s) (48000 64%) 5.3848\n","43m 57s (- 23m 19s) (49000 65%) 5.4409\n","44m 51s (- 22m 25s) (50000 66%) 5.3445\n","45m 47s (- 21m 32s) (51000 68%) 5.4003\n","46m 43s (- 20m 39s) (52000 69%) 5.3422\n","47m 38s (- 19m 46s) (53000 70%) 5.3737\n","48m 33s (- 18m 52s) (54000 72%) 5.3496\n","49m 28s (- 17m 59s) (55000 73%) 5.4081\n","50m 23s (- 17m 5s) (56000 74%) 5.3427\n","51m 16s (- 16m 11s) (57000 76%) 5.3209\n","52m 13s (- 15m 18s) (58000 77%) 5.3507\n","53m 9s (- 14m 24s) (59000 78%) 5.3359\n","54m 6s (- 13m 31s) (60000 80%) 5.3313\n","55m 0s (- 12m 37s) (61000 81%) 5.3032\n","55m 57s (- 11m 43s) (62000 82%) 5.3639\n","56m 51s (- 10m 49s) (63000 84%) 5.1939\n","57m 47s (- 9m 55s) (64000 85%) 5.2594\n","58m 43s (- 9m 2s) (65000 86%) 5.2906\n","59m 39s (- 8m 8s) (66000 88%) 5.2799\n","60m 34s (- 7m 13s) (67000 89%) 5.2291\n","61m 29s (- 6m 19s) (68000 90%) 5.2808\n","62m 25s (- 5m 25s) (69000 92%) 5.2854\n","63m 20s (- 4m 31s) (70000 93%) 5.2501\n","64m 15s (- 3m 37s) (71000 94%) 5.2656\n","65m 12s (- 2m 43s) (72000 96%) 5.2580\n","66m 10s (- 1m 48s) (73000 97%) 5.3072\n","67m 7s (- 0m 54s) (74000 98%) 5.2792\n","68m 1s (- 0m 0s) (75000 100%) 5.2876\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","Fold 4 Bleu-1, Bleu-2, Bleu-3 scores are  [0.1866673369037296, 0.05700495662596755, 0.01916746441813148]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DtGbDe1GzSK9"},"source":["###Fold 5"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"rM5o8g5vzQE7"},"source":["class EncoderRNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size):\r\n","        super(EncoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(input_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        output = embedded\r\n","        output, hidden = self.gru(output, hidden)\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","class DecoderRNN(nn.Module):\r\n","    def __init__(self, hidden_size, output_size):\r\n","        super(DecoderRNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","\r\n","        self.embedding = nn.Embedding(output_size, hidden_size)\r\n","        self.gru = nn.GRU(hidden_size, hidden_size)\r\n","        self.out = nn.Linear(hidden_size, output_size)\r\n","        self.softmax = nn.LogSoftmax(dim=1)\r\n","\r\n","    def forward(self, input, hidden):\r\n","        output = self.embedding(input).view(1, 1, -1)\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","        output = self.softmax(self.out(output[0]))\r\n","        return output, hidden\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","MAX_LENGTH = 164\r\n","# Multiplicative attention https://blog.floydhub.com/attention-mechanism/\r\n","class AttnDecoderRNN4(nn.Module):\r\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\r\n","        super(AttnDecoderRNN4, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.output_size = output_size\r\n","        self.dropout_p = dropout_p\r\n","        self.max_length = max_length\r\n","\r\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n","        #################\r\n","        self.fc = nn.Linear(hidden_size, hidden_size, bias=False) #  Multiplicative\r\n","        ##################\r\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n","        self.dropout = nn.Dropout(self.dropout_p)\r\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n","\r\n","    def forward(self, input, hidden, encoder_outputs):\r\n","        embedded = self.embedding(input).view(1, 1, -1)\r\n","        embedded = self.dropout(embedded)\r\n","        \r\n","        x=self.fc(hidden)\r\n","        #print(x.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape )\r\n","        attn_weights = F.softmax(\r\n","            #################################\r\n","             encoder_outputs.unsqueeze(0).bmm(x.view(1,-1,1)).view(1,-1), dim=1)\r\n","            #################################\r\n","       # print(attn_weights.view(1,-1,1).shape,encoder_outputs.unsqueeze(0).shape)\r\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\r\n","                                 encoder_outputs.unsqueeze(0))\r\n","        \r\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n","        output = self.attn_combine(output).unsqueeze(0)\r\n","\r\n","        output = F.relu(output)\r\n","        output, hidden = self.gru(output, hidden)\r\n","\r\n","        output = F.log_softmax(self.out(output[0]), dim=1)\r\n","        return output, hidden, attn_weights\r\n","\r\n","    def initHidden(self):\r\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n","\r\n","def indexesFromSentence(lang, sentence):\r\n","    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\r\n","\r\n","\r\n","def tensorFromSentence(lang, sentence):\r\n","    indexes = indexesFromSentence(lang, sentence)\r\n","    indexes.append(EOS_token)\r\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n","\r\n","\r\n","def tensorsFromPair(pair):\r\n","    input_tensor = tensorFromSentence(input_lang5, pair[0])\r\n","    target_tensor = tensorFromSentence(output_lang5, pair[1])\r\n","    return (input_tensor, target_tensor)\r\n","\r\n","teacher_forcing_ratio = 0.5\r\n","\r\n","\r\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\r\n","    encoder_hidden = encoder.initHidden()\r\n","\r\n","    encoder_optimizer.zero_grad()\r\n","    decoder_optimizer.zero_grad()\r\n","\r\n","    input_length = input_tensor.size(0)\r\n","    target_length = target_tensor.size(0)\r\n","\r\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","    loss = 0\r\n","\r\n","    for ei in range(input_length):\r\n","        encoder_output, encoder_hidden = encoder(\r\n","            input_tensor[ei], encoder_hidden)\r\n","        encoder_outputs[ei] = encoder_output[0, 0]\r\n","\r\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\r\n","\r\n","    decoder_hidden = encoder_hidden\r\n","\r\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\r\n","\r\n","    if use_teacher_forcing:\r\n","        # Teacher forcing: Feed the target as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            decoder_input = target_tensor[di]  # Teacher forcing\r\n","\r\n","    else:\r\n","        # Without teacher forcing: use its own predictions as the next input\r\n","        for di in range(target_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            topv, topi = decoder_output.topk(1)\r\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\r\n","\r\n","            loss += criterion(decoder_output, target_tensor[di])\r\n","            if decoder_input.item() == EOS_token:\r\n","                break\r\n","\r\n","    loss.backward()\r\n","\r\n","    encoder_optimizer.step()\r\n","    decoder_optimizer.step()\r\n","\r\n","    return loss.item() / target_length\r\n","\r\n","import time\r\n","import math\r\n","\r\n","\r\n","def asMinutes(s):\r\n","    m = math.floor(s / 60)\r\n","    s -= m * 60\r\n","    return '%dm %ds' % (m, s)\r\n","\r\n","\r\n","def timeSince(since, percent):\r\n","    now = time.time()\r\n","    s = now - since\r\n","    es = s / (percent)\r\n","    rs = es - s\r\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\r\n","\r\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\r\n","    start = time.time()\r\n","    plot_losses = []\r\n","    print_loss_total = 0  # Reset every print_every\r\n","    plot_loss_total = 0  # Reset every plot_every\r\n","\r\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\r\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\r\n","    training_pairs = [tensorsFromPair(random.choice(train_pairs5))\r\n","                      for i in range(n_iters)]\r\n","    criterion = nn.NLLLoss()\r\n","\r\n","    for iter in range(1, n_iters + 1):\r\n","        training_pair = training_pairs[iter - 1]\r\n","        input_tensor = training_pair[0]\r\n","        target_tensor = training_pair[1]\r\n","\r\n","        loss = train(input_tensor, target_tensor, encoder,\r\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n","        print_loss_total += loss\r\n","        plot_loss_total += loss\r\n","\r\n","        if iter % print_every == 0:\r\n","            print_loss_avg = print_loss_total / print_every\r\n","            print_loss_total = 0\r\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\r\n","                                         iter, iter / n_iters * 100, print_loss_avg))\r\n","\r\n","        if iter % plot_every == 0:\r\n","            plot_loss_avg = plot_loss_total / plot_every\r\n","            plot_losses.append(plot_loss_avg)\r\n","            plot_loss_total = 0\r\n","\r\n","    showPlot(plot_losses)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","plt.switch_backend('agg')\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","\r\n","\r\n","def showPlot(points):\r\n","    plt.figure()\r\n","    fig, ax = plt.subplots()\r\n","    # this locator puts ticks at regular intervals\r\n","    loc = ticker.MultipleLocator(base=0.2)\r\n","    ax.yaxis.set_major_locator(loc)\r\n","    plt.plot(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"JP78TY53zYHd"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang5, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        decoded_words = []\r\n","        decoder_attentions = torch.zeros(max_length, max_length)\r\n","\r\n","        for di in range(max_length):\r\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\r\n","                decoder_input, decoder_hidden, encoder_outputs)\r\n","            decoder_attentions[di] = decoder_attention.data\r\n","            topv, topi = decoder_output.data.topk(1)\r\n","            if topi.item() == EOS_token:\r\n","                decoded_words.append('<EOS>')\r\n","                break\r\n","            else:\r\n","                decoded_words.append(output_lang5.index2word[topi.item()])\r\n","\r\n","            decoder_input = topi.squeeze().detach()\r\n","\r\n","        return decoded_words, decoder_attentions[:di + 1]\r\n","\r\n","class BeamSearchNode(object):\r\n","    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\r\n","        '''\r\n","        :param hiddenstate:\r\n","        :param previousNode:\r\n","        :param wordId:\r\n","        :param logProb:\r\n","        :param length:\r\n","        '''\r\n","        self.h = hiddenstate\r\n","        self.prevNode = previousNode\r\n","        self.wordid = wordId\r\n","        self.logp = logProb\r\n","        self.leng = length\r\n","\r\n","    def eval(self, alpha=1.0):\r\n","        reward = 0\r\n","        # Add here a function for shaping a reward\r\n","\r\n","        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward\r\n","    \r\n","    def __lt__(self, other):\r\n","        return self.eval() < other.eval()\r\n","    \r\n","    \r\n","from queue import PriorityQueue\r\n","\r\n","def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\r\n","    with torch.no_grad():\r\n","        input_tensor = tensorFromSentence(input_lang5, sentence)\r\n","        input_length = input_tensor.size()[0]\r\n","        encoder_hidden = encoder.initHidden()\r\n","\r\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\r\n","\r\n","        for ei in range(input_length):\r\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\r\n","                                                     encoder_hidden)\r\n","            encoder_outputs[ei] += encoder_output[0, 0]\r\n","\r\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\r\n","\r\n","        decoder_hidden = encoder_hidden\r\n","\r\n","        # Number of sentence to generate\r\n","        endnodes = []\r\n","        number_required = 1\r\n","        \r\n","        # starting node -  hidden vector, previous node, word id, logp, length\r\n","        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\r\n","        nodes = PriorityQueue()\r\n","\r\n","        # start the queue\r\n","        nodes.put((-node.eval(), node))\r\n","        qsize = 1\r\n","        \r\n","        # start beam search\r\n","        while True:\r\n","            # give up when decoding takes too long\r\n","            if qsize > 2000: break\r\n","\r\n","            # fetch the best node\r\n","            score, n = nodes.get()\r\n","            decoder_input = n.wordid\r\n","            decoder_hidden = n.h\r\n","\r\n","            if n.wordid.item() == EOS_token and n.prevNode != None:\r\n","                endnodes.append((score, n))\r\n","                # if we reached maximum # of sentences required\r\n","                if len(endnodes) >= number_required:\r\n","                    break\r\n","                else:\r\n","                    continue\r\n","            #elif n.leng > max_length:\r\n","            #    continue\r\n","\r\n","            # decode for one step using decoder\r\n","            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n","\r\n","            # PUT HERE REAL BEAM SEARCH OF TOP\r\n","            log_prob, indexes = torch.topk(decoder_output, beam_size)\r\n","            nextnodes = []\r\n","\r\n","            for new_k in range(beam_size):\r\n","                decoded_t = indexes[0][new_k].view(1, -1)\r\n","                log_p = log_prob[0][new_k].item()\r\n","\r\n","                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\r\n","                score = -node.eval()\r\n","                nextnodes.append((score, node))\r\n","\r\n","            # put them into queue\r\n","            for i in range(len(nextnodes)):\r\n","                score, nn = nextnodes[i]\r\n","                nodes.put((score, nn))\r\n","                \r\n","            # increase qsize\r\n","            qsize += len(nextnodes) - 1\r\n","            \r\n","        # choose nbest paths, back trace them\r\n","        if len(endnodes) == 0:\r\n","            endnodes = [nodes.get() for _ in range(number_required)]\r\n","\r\n","        _, n = endnodes[0]\r\n","        utterance = []\r\n","        utterance.append(output_lang5.index2word[n.wordid.item()])\r\n","        \r\n","        # back trace\r\n","        while n.prevNode != None:\r\n","            n = n.prevNode\r\n","            utterance.append(output_lang5.index2word[n.wordid.item()])\r\n","\r\n","        utterance = utterance[::-1]\r\n","            \r\n","    return utterance, None\r\n","\r\n","def evaluateRandomly(encoder, decoder, n=10):\r\n","    for i in range(n):\r\n","        pair = random.choice(test_pairs5)\r\n","        print('>', pair[0])\r\n","        print('=', pair[1])\r\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\r\n","        output_sentence = ' '.join(output_words)\r\n","        print('<', output_sentence)\r\n","        print('')\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu(encoder, decoder):\r\n","    references, candidates = [], []\r\n","    i= 0\r\n","    for sent_eng, sents_fre in test_pairs5:\r\n","        i=i+1\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate(encoder, decoder, sent_eng)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","        if i%1000==0:\r\n","          print(i)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores\r\n","\r\n","from nltk.translate.bleu_score import corpus_bleu\r\n","\r\n","def evaluateBleu_beam_search(encoder, decoder, beam_size):\r\n","    references, candidates = [], []\r\n","    for sent_eng, sents_fre in test_pairs5:\r\n","        sents_fre = [sent_fre.split(' ') for sent_fre in [sents_fre]]\r\n","        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\r\n","        references.append(sents_fre)\r\n","        candidates.append(output_words)\r\n","    #return bleu 1, bleu 2, bleu 3\r\n","    score1 = corpus_bleu(references, candidates, weights=(1.0, 0, 0))\r\n","    score2 = corpus_bleu(references, candidates, weights=(0.5, 0.5, 0))\r\n","    score3 = corpus_bleu(references, candidates, weights=(0.33, 0.33, 0.33))\r\n","    #print (references,  candidates)\r\n","    scores = [score1, score2, score3]\r\n","    return scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"6u-YKVdSzaVV","outputId":"a12f00ed-c571-4aeb-8bd4-a5f3cd3aebdd"},"source":["hidden_size = 256\r\n","encoder1 = EncoderRNN(input_lang5.n_words, hidden_size).to(device)\r\n","attn_decoder1 = AttnDecoderRNN4(hidden_size, output_lang5.n_words, dropout_p=0.1).to(device)\r\n","\r\n","trainIters(encoder1, attn_decoder1, 75000, print_every=1000) #reduce number of epoch\r\n","print(\"Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are \",evaluateBleu(encoder1, attn_decoder1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0m 55s (- 69m 2s) (1000 1%) 6.1648\n","1m 46s (- 64m 54s) (2000 2%) 5.7357\n","2m 38s (- 63m 18s) (3000 4%) 5.5187\n","3m 28s (- 61m 35s) (4000 5%) 5.4091\n","4m 18s (- 60m 20s) (5000 6%) 5.4127\n","5m 10s (- 59m 25s) (6000 8%) 5.5309\n","6m 1s (- 58m 27s) (7000 9%) 5.5098\n","6m 52s (- 57m 35s) (8000 10%) 5.4472\n","7m 44s (- 56m 44s) (9000 12%) 5.3376\n","8m 35s (- 55m 53s) (10000 13%) 5.3439\n","9m 28s (- 55m 8s) (11000 14%) 5.5107\n","10m 20s (- 54m 18s) (12000 16%) 5.5121\n","11m 15s (- 53m 41s) (13000 17%) 5.6604\n","12m 9s (- 52m 59s) (14000 18%) 5.5966\n","13m 2s (- 52m 10s) (15000 20%) 5.5642\n","13m 58s (- 51m 32s) (16000 21%) 5.7258\n","14m 52s (- 50m 44s) (17000 22%) 5.6425\n","15m 45s (- 49m 54s) (18000 24%) 5.6491\n","16m 40s (- 49m 8s) (19000 25%) 5.5798\n","17m 35s (- 48m 21s) (20000 26%) 5.5908\n","18m 29s (- 47m 32s) (21000 28%) 5.6508\n","19m 22s (- 46m 39s) (22000 29%) 5.6057\n","20m 17s (- 45m 52s) (23000 30%) 5.6454\n","21m 12s (- 45m 3s) (24000 32%) 5.5496\n","22m 8s (- 44m 16s) (25000 33%) 5.6128\n","23m 3s (- 43m 26s) (26000 34%) 5.6053\n","23m 59s (- 42m 38s) (27000 36%) 5.6006\n","24m 54s (- 41m 48s) (28000 37%) 5.5087\n","25m 49s (- 40m 57s) (29000 38%) 5.6557\n","26m 43s (- 40m 4s) (30000 40%) 5.5327\n","27m 38s (- 39m 13s) (31000 41%) 5.5599\n","28m 33s (- 38m 22s) (32000 42%) 5.5091\n","29m 27s (- 37m 30s) (33000 44%) 5.5210\n","30m 21s (- 36m 36s) (34000 45%) 5.4563\n","31m 17s (- 35m 45s) (35000 46%) 5.5294\n","32m 12s (- 34m 53s) (36000 48%) 5.5131\n","33m 8s (- 34m 2s) (37000 49%) 5.4984\n","34m 4s (- 33m 10s) (38000 50%) 5.4726\n","34m 58s (- 32m 16s) (39000 52%) 5.4459\n","35m 54s (- 31m 24s) (40000 53%) 5.4735\n","36m 49s (- 30m 32s) (41000 54%) 5.4830\n","37m 44s (- 29m 39s) (42000 56%) 5.4935\n","38m 39s (- 28m 46s) (43000 57%) 5.4992\n","39m 36s (- 27m 54s) (44000 58%) 5.4685\n","40m 30s (- 27m 0s) (45000 60%) 5.3955\n","41m 26s (- 26m 7s) (46000 61%) 5.4149\n","42m 23s (- 25m 15s) (47000 62%) 5.4725\n","43m 19s (- 24m 22s) (48000 64%) 5.3903\n","44m 14s (- 23m 28s) (49000 65%) 5.3340\n","45m 9s (- 22m 34s) (50000 66%) 5.3965\n","46m 3s (- 21m 40s) (51000 68%) 5.3127\n","46m 59s (- 20m 46s) (52000 69%) 5.3756\n","47m 54s (- 19m 53s) (53000 70%) 5.3189\n","48m 49s (- 18m 59s) (54000 72%) 5.3587\n","49m 45s (- 18m 5s) (55000 73%) 5.3854\n","50m 40s (- 17m 11s) (56000 74%) 5.4162\n","51m 39s (- 16m 18s) (57000 76%) 5.3767\n","52m 36s (- 15m 25s) (58000 77%) 5.4509\n","53m 32s (- 14m 31s) (59000 78%) 5.2782\n","54m 27s (- 13m 36s) (60000 80%) 5.3286\n","55m 23s (- 12m 42s) (61000 81%) 5.3216\n","56m 19s (- 11m 48s) (62000 82%) 5.3192\n","57m 15s (- 10m 54s) (63000 84%) 5.2751\n","58m 10s (- 10m 0s) (64000 85%) 5.3133\n","59m 7s (- 9m 5s) (65000 86%) 5.3214\n","60m 1s (- 8m 11s) (66000 88%) 5.2810\n","60m 58s (- 7m 16s) (67000 89%) 5.2572\n","61m 55s (- 6m 22s) (68000 90%) 5.3050\n","62m 51s (- 5m 27s) (69000 92%) 5.2997\n","63m 47s (- 4m 33s) (70000 93%) 5.2847\n","64m 41s (- 3m 38s) (71000 94%) 5.2790\n","65m 37s (- 2m 44s) (72000 96%) 5.3342\n","66m 33s (- 1m 49s) (73000 97%) 5.3180\n","67m 26s (- 0m 54s) (74000 98%) 5.2173\n","68m 21s (- 0m 0s) (75000 100%) 5.2133\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","Fold 5 Bleu-1, Bleu-2, Bleu-3 scores are  [0.19094653801642456, 0.06056145873557052, 0.020428868843959447]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P8qMVNHB402u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615686942187,"user_tz":-480,"elapsed":886,"user":{"displayName":"Ning Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRCnmT8mmairzuShAibDId7kDGmrCXjp8yIjrCOw=s64","userId":"12536691088853738123"}},"outputId":"9e1130c9-4645-4736-cdb4-e4464c6bca9f"},"source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["> na domaci scene se asaduv rezim take ocita v potizich .\n","= at home assad s regime also finds itself in a bind .\n","< at the same time the same time to the the . <EOS>\n","\n","> v nasledujicim roce byl teng rehabilitovan a po maove smrti koncem sedmdesatych let se kontroly nad rezimem ujali tengovi pragmatici .\n","= deng was rehabilitated the following year and in the late s after mao s death deng s pragmatists seized control of the regime .\n","< in was was a was and the was the was the the was a the . . <EOS>\n","\n","> bylo spravne povzbudit novou ekonomiku aby rostla mimo tyto ztuhle struktury .\n","= it was right to encourage a new economy to grow outside these congealed structures .\n","< it was a of to the the to the the the to the the <EOS>\n","\n","> nicmene evropane se vseobecne shoduji ze jejich spolecnosti rodi nejlepsi zpusoby zivota trebaze jejich ekonomiky jsou v darwinovskem smyslu mene efektivni nez ekonomika americka .\n","= nevertheless europeans generally agree that their societies produce the best lifestyles even if their economies are less efficient than america s in a darwinian sense .\n","< but the of the that of the that in the of the the of than . . . . <EOS>\n","\n","> nejvetsi skody na legitimite osn napachala tato organizace sama .\n","= the greatest damage to the un s legitimacy has been self inflicted .\n","< the un s un has been the the . . <EOS>\n","\n","> pred valkou mohla amerika predstavovat drtivou silu .\n","= before the war america could project overwhelming force .\n","< the years ago ago the ago the . . . . <EOS>\n","\n","> francie si zajistila rozsahly trh pro sve vyrobky stabilni dodavky levnych surovin repatriaci lviho podilu mistnich uspor bezkonkurencni politicky vliv strategickou pritomnost ve zdarma vyuzivanych vojenskych zakladnach a jistotu ze se muze spolehnout na diplomatickou podporu africkych spojencu .\n","= france has secured a vast market for its products a steady supply of cheap raw materials repatriation of the lion s share of local savings unrivaled political influence a strategic presence with military bases occupied free of charge and the certainty that it can rely on its african allies diplomatic support .\n","< france france has a of of of of the a the the the to the the the the the the to the the the the the to the . <EOS>\n","\n","> otazka zni jaky bude jejich pristi krok .\n","= the question is what their next step will be .\n","< the will will be to to <EOS>\n","\n","> pri definovani zapadni politiky vuci rusku je treba rysovat jemnou linii .\n","= a fine line must be drawn in defining western policy towards russia .\n","< by a new is is is a of . . . . . <EOS>\n","\n","> prvnim cilem zpravodajske cinnosti je vyhledavat teroristy branit jim v akci a dopadat je pokud presto zautoci .\n","= the first objective of intelligence is to find terrorists prevent them from acting and track them after they do attack .\n","< the is is of and and and of the and the and the and the . . <EOS>\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EMVa5t_3cjo9"},"source":[""],"execution_count":null,"outputs":[]}]}